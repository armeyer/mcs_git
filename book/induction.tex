\chapter{Induction}
%\coursecopyright

%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Induction is by far the most powerful and commonly-used proof technique in
Discrete Mathematics and Computer Science.  In fact, the use of induction
is a defining characteristic of \emph{discrete} ---as opposed to
\emph{continuous} ---Mathematics.
%
To understand how it works, suppose there is a professor who brings
to class a bottomless bag of assorted miniature candy bars.  She offers to
share the candy in the following way.  First, she lines the students up in
order.  Now she states two rules:

\begin{enumerate}
\item The student at the beginning of the line gets a candy bar.
\item If a student gets candy bar, then the following student in line
  also gets a candy bar, for every student in the line.
\end{enumerate}
%
Let's number the students by their order in line, starting the count with
0, as usual in Computer Science.  Now we can understand the second rule as
a short description of a whole sequence of statements:
%
\begin{itemize}
\item If student 0 gets a candy bar, then student 1 also gets one.
\item If student 1 gets a candy bar, then student 2 also gets one.
\item If student 2 gets a candy bar, then student 3 also gets one.

\hspace{1.2in} \vdots
\end{itemize}
%
Of course this sequence has a more concise mathematical description:
\begin{quote}
  If student $n$ gets a candy bar, then student $n+1$ gets a
  candy bar, for all nonnegative integers $n$.
\end{quote}
So suppose you are student 17.  By these rules, are you entitled to a
miniature candy bar?  Well, student 0 gets a candy bar by the first rule.
Therefore, by the second rule, student 1 also gets one, which means
student 2 gets one, which means student 3 gets one as well, and so on.  By
17 applications of the professor's second rule, you get your candy bar!
Of course the rules actually guarantee a candy bar to \emph{every}
student, no matter how far back in line they may be.


%% Ordinary Induction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hyperdef{in}{duction}{\section{Ordinary Induction}}

The reasoning that led us to conclude every student gets a candy bar is 
essentially all there is to induction.
\textbox{ 
\noindent \textbf{The Principle of Induction.}

\noindent Let $P(n)$ be a predicate.  If
%
\noindent \begin{itemize}
\item $P(0)$ is true, and
\item $P(n) \QIMPLIES P(n+1)$ for all nonnegative integers, $n$,
\end{itemize}
%
\noindent then
\noindent \begin{itemize}
\item $P(m)$ is true for all nonnegative integers, $m$.
\end{itemize}
}
\iffalse
So our claim that all the Professor's students get a candy bar was simply
an application of the Induction Rule with $P(n)$ defined to be the
predicate, ``student $n$ gets a candy bar.''
\fi

Since we're going to consider several useful variants of induction in
later sections, we'll refer to the induction method described above as
\term{ordinary induction} when we need to distinguish it.  Formulated as 
a proof rule, this would be
\begin{rul*} \textbf{Induction Rule}
\Rule{P(0), \quad \forall n \in \naturals\, [P(n) \QIMPLIES P(n+1)]}
{\forall m \in \naturals.\, P(m)}
\end{rul*}

This general induction rule works for the same intuitive reason that all
the students get candy bars, and we hope the explanation using candy bars
makes it clear why the soundness of the ordinary induction can be taken
for granted.  In fact, the rule is so obvious that it's hard to see what
more basic principle could be used to justify it.\footnote{But see
section~\ref{CP0303:versusWO}.}  What's not so obvious is how much mileage 
we get by using it.

\subsection{Using Ordinary Induction}

Ordinary induction often works directly in proving that some statement
about nonnegative integers holds for all of them.  For example, here is a
classic formula:

\begin{theorem}
\label{C0301:sum-to-n}
For all $n \in \naturals$,
\begin{equation}\label{C0301:hyp}
1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}
\end{equation}
\end{theorem}

The left side of equation~\eqref{C0301:hyp} represents the sum of all the
numbers from 1 to $n$.  Here the dots ($\cdots$) indicate a pattern you're
supposed to be able to guess so you can mentally fill in the remaining
terms. However, the meaning of this sum is not so obvious in a couple of 
special cases:
%
\begin{itemize}
%
\item If $n = 1$, then there is only one term in the summation, and so
$1 + 2 + 3 + \cdots + n = 1$.  Don't be misled by the appearance of 2
and 3 and the suggestion that $1$ and $n$ are distinct terms!
%
\item If $n \leq 0$, then there are no terms at all in the summation.  By
convention, the sum in this case is 0.
%
\end{itemize}
%
So while the dots notation is convenient, you have to watch out for these
special cases where the notation is misleading!  (In fact, whenever you
see the dots, you should be on the lookout to be sure you understand the
pattern.)

We could eliminate the need for guessing by rewriting the left side
of~\eqref{C0301:hyp} with \term{summation notation}:
\[
\sum_{i=1}^n i
\qquad \text{or} \qquad
\sum_{1 \leq i \leq n} i.
\]
Both of these expressions denote the sum of all values taken on by the
expression to the right of the sigma as the variable, $i$, ranges from 
1 to $n$.  Both these summation expressions make it clear 
what~\eqref{C0301:hyp} means when $n=1$.  The second expression makes 
it clear that when $n=0$, there are no terms in the sum, though you 
still have to know the convention that a sum of no numbers equals 0 
(the \emph{product} of no numbers is 1, by the way).

Now let's use the induction principle to prove Theorem~\ref{C0301:sum-to-n}.
Suppose that we define predicate $P(n)$ to be ``$1 + 2 + 3 + \cdots + n =
n(n+1)/2$''.  Recast in terms of this predicate, the theorem claims that
$P(n)$ is true for all $n \in \naturals$.  This is great, because the
induction principle lets us reach precisely that conclusion, provided we
establish two simpler facts:
%
\begin{itemize}
\item $P(0)$ is true.
\item For all $n \in \naturals$, $P(n) \QIMPLIES P(n+1)$.
\end{itemize}

So now our job is reduced to proving these two statements.  The first
is true because $P(0)$ asserts that a sum of zero terms is equal to
$0(0+1)/2 = 0$.
%
The second statement is more complicated.  But remember the basic plan
for proving the validity of any implication: \textit{assume} the
statement on the left and then \textit{prove} the statement on the
right.  In this case, we assume $P(n)$:
\begin{equation}\label{C0301:Pn}
1 + 2 + 3 + \cdots + n  = \frac{n(n+1)}{2}
\end{equation}
in order to prove $P(n+1)$:
\begin{equation}\label{C0301:Pn1}
1 + 2 + 3 + \cdots + n + (n+1) = \frac{(n+1)(n+2)}{2}
\end{equation}
These two equations are quite similar; in fact, adding $(n+1)$ to both
sides of equation~\eqref{C0301:Pn} and simplifying the right side 
gives the equation~\eqref{C0301:Pn1}:
\begin{align*}
1 + 2 + 3 + \cdots + n + (n+1)
    & = \frac{n(n+1)}{2} + (n+1) \\
    & = \frac{(n+2)(n+1)}{2}
\end{align*}
Thus, if $P(n)$ is true, then so is $P(n+1)$.  This argument is valid
for every nonnegative integer $n$, so this establishes the second fact
required by the induction principle.  Therefore, the induction principle
says that the predicate $P(n)$ is true for all nonnegative $n$, so the 
theorem is proved.

\iffalse
In effect, we've just proved
that $P(0)$ implies $P(1)$, $P(1)$ implies $P(2)$, $P(2)$ implies
$P(3)$, etc., all in one fell swoop.
\fi

\iffalse
\begin{notesproblem}
Prove by induction on $n$ that
\hyperdef{geometric}{sum}{\begin{equation}\label{geometric-n}
1+r+r^2+\cdots+r^n = \frac{r^{n+1}-1}{r-1}
\end{equation}}
for all $n \in \naturals$ and numbers $r\neq 1$.
\end{notesproblem}
\fi

\subsection{A Template for Induction Proofs}
\label{C0301:templ-induct-proofs}

The proof of Theorem~\ref{C0301:sum-to-n} was relatively simple, but even
the most complicated induction proof follows exactly the same
template.  There are five components:

\begin{enumerate}

\item \textbf{State that the proof uses induction.}  This immediately
conveys the overall structure of the proof, which helps the reader
understand your argument.

\item \textbf{Define an appropriate predicate $P(n)$.}  The eventual
conclusion of the induction argument will be that $P(n)$ is true for all
nonnegative $n$.  Thus, you should define the predicate $P(n)$ so that your
theorem is equivalent to (or follows from) this conclusion.  Often the
predicate can be lifted straight from the claim, as in the example above.
The predicate $P(n)$ is called the ``induction hypothesis''.  Sometimes
the induction hypothesis will involve several variables, in which case you
should indicate which variable serves as $n$.

\item \textbf{Prove that $P(0)$ is true.}  This is usually easy, as in the
example above.  This part of the proof is called the ``base case'' or
``basis step''.  (Sometimes the base case will be $n=1$ or even some
larger number, in which case the starting value of $n$ also should be
stated.)

\item \textbf{Prove that $P(n)$ implies $P(n+1)$ for every nonnegative
integer $n$.}  This is called the ``inductive step'' or ``induction step''.
The basic plan is always the same: assume that $P(n)$ is true and then use
this assumption to prove that $P(n+1)$ is true.  These two statements
should be fairly similar, but bridging the gap may require some ingenuity.
Whatever argument you give must be valid for every nonnegative integer $n$,
since the goal is to prove the implications $P(0) \rightarrow P(1)$, $P(1)
\rightarrow P(2)$, $P(2) \rightarrow P(3)$, etc. all at once.

\item \textbf{Invoke induction.}  Given these facts, the induction
  principle allows you to conclude that $P(n)$ is true for all nonnegative
  $n$.  This is the logical capstone to the whole argument, but many
  writers leave this step implicit.

\end{enumerate}
%
Explicitly labeling the \textit{base case} and \textit{inductive step} may
make your proofs clearer.

\subsection{A Clean Writeup}

The proof of Theorem~\ref{C0301:sum-to-n} given above is perfectly valid;
however, it contains a lot of extraneous explanation that you won't
usually see in induction proofs.  The writeup below is closer to what
you might see in print and should be prepared to produce yourself.

\begin{proof}
We use induction.  The induction hypothesis, $P(n)$, will be
equation~\eqref{C0301:hyp}.

\textbf{Base case:} $P(0)$ is true, because both sides of
equation~\eqref{C0301:hyp} equal zero when $n=0$.

\textbf{Inductive step:} Assume that $P(n)$ is true, where
$n$ is any nonnegative integer.  Then
\begin{align*}
1 + 2 + 3 + \cdots + n + (n+1)
    & = \frac{n(n+1)}{2} + (n+1) & \text{(by induction hypothesis)}\\
    & = \frac{(n+1)(n+2)}{2}  & \text{(by simple algebra)}
\end{align*}
which proves $P(n+1)$.

So it follows by induction that $P(n)$ is true for all nonnegative $n$.
\end{proof}

Induction was helpful for \textit{proving the correctness} of this
summation formula, but not helpful for \textit{discovering} it in the
first place.  We'll show you some tricks for finding such formulas in a
few weeks.

\subsection{Powers of Odd Numbers}

\begin{fact*}
The $n$th power of an odd number is odd, for all nonnegative integers, $n$.
\end{fact*}
The proof in Chapter~\ref{C01} that $\sqrt[n]{2}$ is irrational used this 
``obvious'' fact.  Instead of taking it for granted, we can prove this fact
by induction.
The proof will require a simple Lemma.
\begin{lemma*}
The product of two odd numbers is odd.
\end{lemma*}
To prove the Lemma, note that the odd numbers are, by definition, the
numbers of the form $2k+1$ where $k$ is an integer.  But
\[
(2k+1)(2k'+1) = 2(2kk' + k + k')+1,
\]
so the product of two odd numbers also has the form of an odd number,
which proves the Lemma.

Now we will prove the Fact using the induction hypothesis
\[
P(n) \eqdef \text{if $a$ is an odd integer, then so is $a^{n}$}.
\]

The base case $P(0)$ holds because $a^{0} =1$, and 1 is odd.

For the inductive step, suppose $n\geq 0$, $a$ is an odd number and $P(n)$
holds.  So $a^n$ is an odd number.  Therefore, $a^{n+1} = a^{n}a$ is a
product of odd numbers, and by the Lemma $a^{n+1}$ is also odd.  This
proves $P(n+1)$, and we conclude by induction that $P(n)$ holds for
nonnegative integers $n$.

\iffalse
An alternative proof of Lemma~\ref{finmin} that every partial order on a
nonempty finite set has a minimal element can be based on induction.  This
time there is no $n$ mentioned, so we better find one.

We'll use the induction hypothesis
\[
P(n) \eqdef \text{a strict partial order on a set of size $n$ has a minimal
  element}.
\]

As a base case, we'll use $n=1$.  Now $P(1)$ holds because in a
one-element partial order, the element is minimal (and maximal) by
definition.

For the inductive step, assume $P(n)$ holds and consider a strict partial
order, $R$, on a set, $A$, of size $n+1$ for $n \geq 1$.  We will prove
that $A$ has a minimal element.

Now $A$ has 2 or more elements, so pick one and call it $a_0$.  If $a_0$
is a minimal element, then we are done.  Otherwise, let $A'$ be the set $A
- \set{a_0}$ and $R'$ be the relation $R$ restricted to $A'$.

Now it's easy to check that $R'$ is a strict partial order on set $A'$
whose size is $n$.  So by induction, there is an $R'$-minimal element, $m
\in A'$.  We claim that $m$ is also a minimal element of $A$.

Now there is no element $a' \in A'$ such that $a'\,R\,m$, so to prove
$m$ is minimal in $A$,  as long as it is not true that $a_0\,R\, m$

This element $m$ will also be minimal in $A$ unless

Since $a_0$ is not minimal, there is an element $a_1 \in A'$ such that
$a_1\,R\,a_0$.

\fi

\subsection{Courtyard Tiling}

Induction served purely as a proof technique in the preceding examples.
But induction sometimes can serve as a more general reasoning tool.

MIT recently constructed the Stata Center which houses the Computer
Science and AI Laboratory.  During development, the project went further
and further over budget, and there were some radical fundraising ideas.
One rumored plan was to install a big courtyard with dimensions $2^n
\times 2^n$:

\begin{center}
\begin{picture}(100,100)(-20,-20)
\put(40,-10){\makebox(0,0){$2^n$}}
\put(-10,40){\makebox(0,0){$2^n$}}
\put(0,0){\line(1,0){80}}
\put(0,10){\line(1,0){80}}
\put(0,20){\line(1,0){80}}
\put(0,30){\line(1,0){80}}
\put(0,40){\line(1,0){80}}
\put(0,50){\line(1,0){80}}
\put(0,60){\line(1,0){80}}
\put(0,70){\line(1,0){80}}
\put(0,80){\line(1,0){80}}
\put(0,0){\line(0,1){80}}
\put(10,0){\line(0,1){80}}
\put(20,0){\line(0,1){80}}
\put(30,0){\line(0,1){80}}
\put(40,0){\line(0,1){80}}
\put(50,0){\line(0,1){80}}
\put(60,0){\line(0,1){80}}
\put(70,0){\line(0,1){80}}
\put(80,0){\line(0,1){80}}
\end{picture}
\end{center}

One of the central squares would be occupied by a statue of a wealthy
potential donor.  Let's call him ``Bill''.  (In the special case $n = 0$,
the whole courtyard consists of a single central square; otherwise, there
are four central squares.)  A complication was that the building's
unconventional architect, Frank Gehry, supposedly insisted that only
special L-shaped tiles be used:

\begin{center}
\thicklines
\begin{picture}(50,50)
\put(0,0){\line(1,0){50}}
\put(50,0){\line(0,1){50}}
\put(50,50){\line(-1,0){25}}
\put(25,50){\line(0,-1){25}}
\put(25,25){\line(-1,0){25}}
\put(0,25){\line(0,-1){25}}
\thinlines
\put(25,25){\line(1,0){25}}
\put(25,25){\line(0,-1){25}}
\end{picture}
\end{center}

A courtyard meeting these constraints exists, at least for $n = 2$:

\begin{center}
\begin{picture}(100,100)
\thicklines
\put(0,0){\line(1,0){100}}
\put(25,25){\line(1,0){50}}
\put(25,75){\line(1,0){50}}
\put(0,100){\line(1,0){100}}
\put(0,50){\line(1,0){25}}
\put(75,50){\line(1,0){25}}
\put(0,0){\line(0,1){100}}
\put(25,25){\line(0,1){50}}
\put(75,25){\line(0,1){50}}
\put(100,0){\line(0,1){100}}
\put(50,50){\line(0,1){25}}
\put(50,50){\line(1,0){25}}
\put(50,0,){\line(0,1){25}}
\put(50,75){\line(0,1){25}}
\put(62.5,62.5){\makebox(0,0){\textbf{B}}}
\end{picture}
\end{center}

For larger values of $n$, is there a way to tile a $2^n
\times 2^n$ courtyard with L-shaped tiles and a statue in the center?
Let's try to prove that this is so.

\begin{theorem}\label{bill}
For all $n \geq 0$ there exists a tiling of a $2^n \times 2^n$
courtyard with Bill in a central square.
\end{theorem}

\begin{proof}
{\em (doomed attempt)} The proof is by induction.  Let $P(n)$ be the
proposition that there exists a tiling of a $2^n \times 2^n$ courtyard
with Bill in the center.

\textbf{Base case:} $P(0)$ is true because Bill fills the whole courtyard.

\textbf{Inductive step:} Assume that there is a tiling of a
$2^n \times 2^n$ courtyard with Bill in the center for some $n \geq
0$.  We must prove that there is a way to tile a $2^{n+1} \times
2^{n+1}$ courtyard with Bill in the center \dots.
\end{proof}

Now we're in trouble!  The ability to tile a smaller courtyard with Bill
in the center isn't much help in tiling a larger courtyard with Bill in
the center.  We haven't figured out how to bridge the gap between $P(n)$
and $P(n+1)$.

So if we're going to prove Theorem~\ref{bill} by induction, we're going to
need some \emph{other} induction hypothesis than simply the statement
about $n$ that we're trying to prove.

%Hide after lecture:

%We'll describe some hypotheses that do work in class this week.

%end hide

%\iffalse  %Unhide after lecture:

When this happens, your first fallback should be to look for a
\textit{stronger} induction hypothesis; that is, one which implies
your previous hypothesis.  For example, we could make $P(n)$ the
proposition that for \textit{every} location of Bill in a $2^n \times
2^n$ courtyard, there exists a tiling of the remainder.

This advice may sound bizarre: ``If you can't prove something, try to
prove something grander!''  But for induction arguments, this makes sense.
In the inductive step, where you have to prove $P(n) \implies P(n+1)$,
you're in better shape because you can {\em assume} $P(n)$, which is now a
more powerful statement.  Let's see how this plays out in the case of
courtyard tiling.

\begin{proof}
{\em (successful attempt)} The proof is by induction.  Let $P(n)$ be
the proposition that for every location of Bill in a $2^n \times 2^n$
courtyard, there exists a tiling of the remainder.

\textbf{Base case:} $P(0)$ is true because Bill fills the
whole courtyard.

\textbf{Inductive step:} Assume that $P(n)$ is true for some
$n \geq 0$; that is, for every location of Bill in a $2^n \times 2^n$
courtyard, there exists a tiling of the remainder.  Divide the
$2^{n+1} \times 2^{n+1}$ courtyard into four quadrants, each $2^n
\times 2^n$.  One quadrant contains Bill (\textbf{B} in the diagram
below).  Place a temporary Bill (\textbf{X} in the diagram) in each of
the three central squares lying outside this quadrant:

\begin{center}
\begin{picture}(148,148)(-20,-20)
\thinlines
\put(0,0){\line(1,0){128}}
\put(0,0){\line(0,1){128}}
\put(128,128){\line(-1,0){128}}
\put(128,128){\line(0,-1){128}}
\put(64,0){\line(0,1){128}}
\put(0,64){\line(1,0){128}}
\put(56,72){\makebox(0,0){\textbf{X}}}
\put(56,56){\makebox(0,0){\textbf{X}}}
\put(72,56){\makebox(0,0){\textbf{X}}}
\put(48,80){\line(1,0){16}}
\put(48,48){\line(1,0){32}}
\put(80,48){\line(0,1){16}}
\put(48,48){\line(0,1){32}}
\put(96,96){\framebox(16,16){\textbf{B}}}
\put(32,-10){\makebox(0,0){$2^n$}}
\put(96,-10){\makebox(0,0){$2^n$}}
\put(-10,32){\makebox(0,0){$2^n$}}
\put(-10,96){\makebox(0,0){$2^n$}}
\end{picture}
\end{center}

Now we can tile each of the four quadrants by the induction
assumption.  Replacing the three temporary Bills with a single
L-shaped tile completes the job.  This proves that $P(n)$ implies
$P(n+1)$ for all $n \geq 0$.  The theorem follows as a special case.
\end{proof}

This proof has two nice properties.  First, not only does the argument
guarantee that a tiling exists, but also it gives an algorithm for
finding such a tiling.  Second, we have a stronger result: if Bill
wanted a statue on the edge of the courtyard, away from the pigeons,
we could accommodate him!

Strengthening the induction hypothesis is often a good move when an
induction proof won't go through.  But keep in mind that the stronger
assertion must actually be \textit{true}; otherwise, there isn't much
hope of constructing a valid proof!  Sometimes finding just the right
induction hypothesis requires trial, error, and insight.  For example,
mathematicians spent almost twenty years trying to prove or disprove
the conjecture that ``Every planar graph is
5-choosable''\footnote{5-choosability is a slight generalization of
5-colorability.  Although every planar graph is 4-colorable and
therefore 5-colorable, not every planar graph is 4-choosable.  If this
all sounds like nonsense, don't panic.  We'll discuss graphs,
planarity, and coloring in two weeks.}.  Then, in 1994, Carsten
Thomassen gave an induction proof simple enough to explain on a
napkin.  The key turned out to be finding an extremely clever
induction hypothesis; with that in hand, completing the argument is
easy!

%\fi  %end UnHide after lecture

\subsection{A Faulty Induction Proof}

\begin{falsethm*}
All horses are the same color.
\end{falsethm*}

Notice that no $n$ is mentioned in this assertion, so we're going to have
to reformulate it in a way that makes an $n$ explicit.  In particular,
we'll (falsely) prove that

\begin{falsethm}\label{horses}
In every set of $n \geq 1$ horses, all are the same color.
\end{falsethm}

This a statement about all integers $n \geq 1$ rather $\geq 0$, so it's
natural to use a slight variation on induction: prove $P(1)$ in the base
case and then prove that $P(n)$ implies $P(n+1)$ for all $n \geq 1$ in the
inductive step.  This is a perfectly valid variant of induction and is
{\em not} the problem with the proof below.

\begin{falseproof}

The proof is by induction on $n$.  The induction hypothesis, $P(n)$, will be
\begin{equation}\label{horsehyp}
\text{In every set of $n$ horses, all are the same color.}
\end{equation}

\textbf{Base case:} ($n=1$).  $P(1)$ is true, because in a set of horses
of size 1, there's only one horse, and this horse is definitely the same
color as itself.

\textbf{Inductive step:} Assume that $P(n)$ is true for some $n \geq 1$.
that is, assume that in every set of $n$ horses, all are the same color.
Now consider a set of $n+1$ horses:
%
\[
h_1,\ h_2,\ \dots,\ h_n,\ h_{n+1}
\]
%
By our assumption, the first $n$ horses are the same color:
%
\[
\underbrace{h_1,\ h_2,\ \dots,\ h_n,}_{\text{same color}}\ h_{n+1}
\]
%
Also by our assumption, the last $n$ horses are the same color:
%
\[
h_1,\ \underbrace{h_2,\ \dots,\ h_n,\ h_{n+1}}_{\text{same color}}
\]
%
So $h_1$ is the same color as the remaining horses besides $h_{n+1}$, and
likewise $h_{n+1}$ is the same color as the remaining horses besides
$h_1$.  So $h_1$ and $h_{n+1}$ are the same color.  That is, horses $h_1,
h_2, \dots, h_{n+1}$ must all be the same color, and so $P(n+1)$ is true.
Thus, $P(n)$ implies $P(n+1)$.

By the principle of induction, $P(n)$ is true for all $n \geq 1$.
\end{falseproof}
We've proved something false!  Is Math broken?  Should we all become
poets?  No, this proof has a mistake.
%hide after lecture:
% We'll explain where in class.
%end hide

%\iffalse %UNHIDE after lecture

The error in this argument is in the sentence that begins, ``So $h_1$ and
$h_{n+1}$ are the same color.''  The ``$\dots$'' notation creates the
impression that there are some remaining horses besides $h_1$ and
$h_{n+1}$.  However, this is not true when $n = 1$.  In that case, the
first set is just $h_1$ and the second is $h_2$, and there are no
remaining horses besides them.  So $h_1$ and $h_2$ need not be the same
color!

This mistake knocks a critical link out of our induction argument.  We
proved $P(1)$ and we \emph{correctly} proved $P(2) \implies P(3)$, $P(3)
\implies P(4)$, etc.  But we failed to prove $P(1) \implies P(2)$, and so
everything falls apart: we can not conclude that $P(2)$, $P(3)$, etc., are
true.  And, of course, these propositions are all false; there are horses
of a different color.

%\fi %end unhide

Students sometimes claim that the mistake in the proof is because $P(n)$
is false for $n \geq 2$, and the proof assumes something false, namely,
$P(n)$, in order to prove $P(n+1)$.  You should think about how to explain
to such a student why this claim would get no credit on a 6.042 exam.

%% Ordinary Induction Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\startclassproblems
\pinput{CP_cubic_series}
\pinput{CP_courtyard_tiling}
\pinput{CP_box_unstacking}
\pinput{CP_false_geometric_series_proof}


%% Strong Induction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hyperdef{strong}{induction}{\section{Strong Induction}}

%\subsection*{The Strong Induction Principle}

A useful variant of induction is called {\em strong induction}.  Strong
Induction and Ordinary Induction are used for exactly the same thing:
proving that a predicate $P(n)$ is true for all $n \in \naturals$.

\textbox{
\textbf{Principle of Strong Induction. }  Let $P(n)$ be a predicate.  If

\begin{itemize}
\item $P(0)$ is true, and
\item for all $n \in \naturals$, $P(0)$, $P(1)$, \dots, $P(n)$
\emph{together} imply $P(n+1)$,
\end{itemize}

then $P(n)$ is true for all $n \in \naturals$.
}

The only change from the ordinary induction principle is that strong
induction allows you to assume more stuff in the inductive step of your
proof!  In an ordinary induction argument, you assume that $P(n)$ is true
and try to prove that $P(n+1)$ is also true.  In a strong induction
argument, you may assume that $P(0)$, $P(1)$, \dots, and $P(n)$ are
\textit{all} true when you go to prove $P(n+1)$.  These extra assumptions
can only make your job easier.

\subsection{Products of Primes}

As a first example, we'll use strong induction to prove one of those
familiar facts that is almost, but maybe not entirely, obvious:
\begin{lemma}\label{prim}
Every integer greater than 1 is a product of primes.
\end{lemma}
Note that, by convention, any number is considered to be a product
consisting of one term, namely itself.  In particular, every prime is
considered to be a product whose terms are all primes.

\begin{proof}

We will prove Lemma~\ref{prim} by strong induction, letting the induction
hypothesis, $P(n)$, be
\[
n+2 \text{ is a product of primes}.
\]
So Lemma~\ref{prim} will follow if we prove that $P(n)$ holds for all $n
\geq 0$.

\textbf{Base Case:} $P(0)$ is true because $0+2$ is prime, and so is a
product of primes by convention.

\textbf{Inductive step:} Suppose that $n \geq 0$ and that $i+2$ is a
product of primes for every nonnegative integer $i < n+1$.  We must show that
$P(n+1)$ holds, namely, that $n+3$ is also a product of primes.  We argue
by cases:

If $n+3$ is itself prime, then it is a product of primes by convention, so
$P(n+1)$ holds in this case.

Otherwise, $n + 3$ is not prime, which by definition means $n+3 = km$ for
some integers $k,m$ such that $2 \leq k,m < n+3$.  Now $0 \leq k-2 < n+1$,
so by strong induction hypothesis, we know that $(k-2)+2=k$ is a product of
primes.  Likewise, $m$ is a product of primes.  it follows immediately that
$km = n+3$ is also a product of primes.  Therefore, $P(n+1)$ holds in this
case as well.

So $P(n+1)$ holds in any case, which completes the proof by strong
induction that $P(n)$ holds for all nonnegative integers, $n$.

\end{proof}

Despite the name, strong induction is technically no more powerful than
ordinary induction, though it makes some proofs easier to follow.  But any
theorem that can be proved with strong induction could also be proved with
ordinary induction (using a slightly more complicated induction
hypothesis).  On the other hand, announcing that a proof uses ordinary
rather than strong induction highlights the fact that $P(n+1)$ follows
directly from $P(n)$, which is generally good to know.

\subsection{Making Change}

The country Inductia, whose unit of currency is the Strong, has coins
worth 3\sg\ (3 Strongs) and 5\sg.  Although the Inductians have some
trouble making small change like 4\sg\ or 7\sg, it turns out that they can
collect coins to make change for any number at least 8 Strongs.

Strong induction makes this easy to prove for $n+1 \ge 11$, because then
$(n+1)-3 \ge 8$, so by strong induction the Inductians can make change for
exactly $(n+1)-3$ Strongs, and then they can add a 3\sg\ coin to get
$(n+1)\sg)$.  So the only thing to do is check that they can make change
for all the amounts from 8 to 10\sg, which is not too hard to do.

Here's a detailed writeup using the official format:

\begin{proof}

  We prove by strong induction that the Inductians can make change for any
  amount of at least 8\sg.  The induction hypothesis, $P(n)$ will be:
\begin{quote}
If $n \geq 8$, then there is a collection of coins whose value is $n$
Strongs.
\end{quote}

Notice that $P(n)$ is an implication.  When the hypothesis of an
implication is false, we know the whole implication is true.  In this
situation, the implication is said to be \emph{vacuously} true.  So $P(n)$
will be vacuously true whenever $n < 8$.\footnote{Another approach that
avoids these vacuous cases is to define
\[
P'(n) \eqdef \text{there is a collection of coins whose value is $n+8$
Strongs}
\]
and prove that $P'(n)$ holds for all $n \geq 0$.
\iffalse
The solution to
\href{http://courses.csail.mit.edu/6.042/spring06/solutions/cp3fsol.pdf}
{Class Problem 1 from Spring '06, Friday, Feb. 24} uses this approach.\fi
}

We now proceed with the induction proof:

\textbf{Base case:} $P(0)$ is vacuously true.

\textbf{Inductive step:}  We assume $P(i)$ holds for all $i \leq n$, and
prove that $P(n+1)$ holds.  We argue by cases:

\textbf{Case} ($n+1 < 8$): $P(n+1)$ is vacuously true in this case.

\textbf{Case} ($n+1$ = 8): $P(8)$ holds because the Inductians can use one
3\sg\ coin and one five\sg\ coins.

\textbf{Case} ($n+1$ = 9): Use a three 3\sg\ coins.

\textbf{Case} ($n+1$ = 10): Use two 5\sg\ coins.

\textbf{Case} ($n+1 \geq 11$): Then $n \geq (n+1) -3 \geq 8$, so by the
strong induction hypothesis, the Inductians can make change for $(n+1)-3$
Strong.  Now by adding a 3\sg\ coin, they can make change for $(n+1)\sg$.

So in any case, $P(n+1)$ is true, and we conclude by strong induction that
for all $n \geq 8$, the Inductians can make change for $n$ Strong.

\end{proof}


\subsection{Unstacking}

Here is another exciting 6.042 game that's surely about to sweep the
nation!

\hyperdef{stack}{game}{You} begin with a stack of $n$ boxes.  Then you
make a sequence of moves.  In each move, you divide one stack of boxes
into two nonempty stacks.  The game ends when you have $n$ stacks, each
containing a single box.  You earn points for each move; in particular, if
you divide one stack of height $a + b$ into two stacks with heights $a$
and $b$, then you score $ab$ points for that move.  Your overall score is
the sum of the points that you earn for each move.  What strategy should
you use to maximize your total score?

As an example, suppose that we begin with a stack of $n = 10$ boxes.
Then the game might proceed as follows:
%
\[
\begin{array}{cccccccccccl}
\multicolumn{10}{c}{\textbf{Stack Heights}} & \quad & \textbf{Score} \\
\underline{10}&&&&&&&&& && \\
5&\underline{5}&&&&&&&& && 25 \text{ points} \\
\underline{5}&3&2&&&&&&& && 6 \\
\underline{4}&3&2&1&&&&&& && 4 \\
2&\underline{3}&2&1&2&&&&& && 4 \\
\underline{2}&2&2&1&2&1&&&& && 2 \\
1&\underline{2}&2&1&2&1&1&&& && 1 \\
1&1&\underline{2}&1&2&1&1&1&& && 1 \\
1&1&1&1&\underline{2}&1&1&1&1& && 1 \\
1&1&1&1&1&1&1&1&1&1 && 1 \\ \hline
\multicolumn{10}{r}{\textbf{Total Score}} & = & 45 \text{ points}
\end{array}
\]
%
On each line, the underlined stack is divided in the next step.  Can
you find a better strategy?

\subsubsection{Analyzing the Game}

%Hide in full version
%You will see in class how to use strong induction to analyze this game of
%blocks.
%end Hide

%\iffalse  %unHide after Friday lecture:

Let's use strong induction to analyze the unstacking game.  We'll prove
that your score is determined entirely by the number of boxes ---your
strategy is irrelevant!

\begin{theorem}\label{stacking}
Every way of unstacking $n$ blocks gives a score of $n(n-1)/2$ points.
\end{theorem}

There are a couple technical points to notice in the proof:

\begin{itemize}

\item The template for a strong induction proof is exactly the same as
for ordinary induction.

\item As with ordinary induction, we have some freedom to adjust indices.
In this case, we prove $P(1)$ in the base case and prove that $P(1),
\dots, P(n)$ imply $P(n+1)$ for all $n \geq 1$ in the inductive step.

\end{itemize}

\begin{proof}
The proof is by strong induction.  Let $P(n)$ be the proposition that
every way of unstacking $n$ blocks gives a score of $n(n-1)/2$.

\textbf{Base case:} If $n = 1$, then there is only one
block.  No moves are possible, and so the total score for the game is
$1(1 - 1)/2 = 0$.  Therefore, $P(1)$ is true.

\textbf{Inductive step:} Now we must show that $P(1)$, \dots, $P(n)$ imply
$P(n+1)$ for all $n \geq 1$.  So assume that $P(1)$, \dots, $P(n)$ are all
true and that we have a stack of $n+1$ blocks.  The first move must split
this stack into substacks with positive sizes $a$ and $b$ where $a+b =
n+1$ and $0<a,b\leq n$.  Now the total score for the game is the sum of
points for this first move plus points obtained by unstacking the two
resulting substacks:
%
\begin{align*}
\text{total score}
    & = \text{(score for 1st move)} \\
    & \quad + \text{(score for unstacking $a$ blocks)} \\
    & \quad + \text{(score for unstacking $b$ blocks)} \\
    & = ab + \frac{a(a-1)}{2} + \frac{b(b-1)}{2} & \text{by $P(a)$ and $P(b)$}\\
    & = \frac{(a+b)^2-(a+b)}{2} = \frac{(a+b)((a+b)-1)}{2}\\
    & = \frac{(n+1)n}{2}
\end{align*}
%
This shows that $P(1)$, $P(2)$, \dots, $P(n)$ imply $P(n+1)$.

Therefore, the claim is true by strong induction.
\end{proof}
%\fi  %end unHide

\begin{notesproblem}
%TBA   %Hide after Friday lecture

%\iffalse %unhide after Friday lecture:
Define the \term{potential}, $p(S)$, of a stack, $S$, of blocks to be
$k(k+1)/2$ where $k$ is the number of blocks in $S$.  Define the
potential, $p(A)$, of a set, $A$, of stacks to be the sum of the
potentials of the stacks in $A$.

Generalize Theorem~\ref{stacking} to show that for any set, $A$, of
stacks, if a sequence of moves starting with $A$ leads to another set,
$B$, of stacks, then the score for this sequence of moves is $p(A)-p(B)$.
%\fi  %end friday unHide
\end{notesproblem}

%% Strong Induction Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\startclassproblems


%% Induction versus Well Ordering %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Induction versus Well Ordering}\label{versusWO}

The induction axiom looks nothing like the Well Ordering Principle, but
these two proof methods are closely related.  In fact, we can take any
Induction proof and reformat it into a Well Ordering proof.

Here's how: suppose that we have a proof by Induction with induction
hypothesis $P(n)$.  Then we start a Well Ordering proof by assuming the
set of counterexamples to $P$ is nonempty.  Then by Well Ordering there is
a smallest counterexample, $s$, that is, a smallest $s$ such that $P(s)$
is false.

Now we use the proof of $P(0)$ that was part of the Induction proof to
conclude that $s$ must be greater than 0.  Also since $s$ is the smallest
counterexample, we can conclude that $P(s-1)$ must be true.  At this point
we reuse the proof of the inductive step in the Induction proof, which
shows that since $P(s-1)$ true, then $P(s)$ is also true.  This
contradicts the assumption that $P(s)$ is false, so we have the
contradiction needed to complete the Well Ordering Proof that $P(n)$ holds
for all $n \in \naturals$.

\begin{notesproblem}
  Conversely, use Strong Induction to prove the Well Ordering Principle.
  \hint Prove that if a set of nonnegative integers contains an integer,
  $n$, then it has a smallest element.
\end{notesproblem}

\iffalse
Now check how this template is followed as we prove again
Theorem~\ref{th:sum-to-n}. 

\begin{theorem*}
For all $n\in\mathbb{N}$:\quad
$
1 + 2 + 3 + \cdots + n = n(n+1)/2
$.
\end{theorem*}

\begin{proof}
By contradiction. Assume that the theorem is
\emph{false}. Then, some nonnegative integers serve as
\emph{counterexamples} to it. Let's collect them in a set: 
$$
C =     \bigl\{\: 
        n\in\mathbb{N} 
        \:\:\mid\:\:
        1 + 2 + 3 + \cdots + n \neq \frac{n(n+1)}{2}
        \:\bigr\}.
$$
By our assumption that the theorem admits counterexamples, $C$ is a
nonempty set of nonnegative integers. So, by the Well Ordering Principle,
$C$ has a minimum element, call it~$c$. That is, $c$ is the
\emph{smallest counterexample} to the theorem.  

\noindent
Since $c$ is a counterexample ($c\in C$), we know that 
$$
        1 + 2 + 3 + \cdots + c \neq \frac{c(c+1)}{2}.
$$
Since $c$ is the smallest counterexample ($c$ minimum of $C$), we
know the theorem holds for all nonnegative integers smaller than
$c$. (Otherwise, at least one of them would also be in $C$ and would
therefore prevent $c$ from being the minimum of $C$.) [$\ast$] In
particular, the theorem is true for $c-1$. That is, 
$$
        1 + 2 + 3 + \cdots + (c-1) = \frac{(c-1)c}{2}.
$$
But then, adding $c$ to both sides we get
$$
1 + 2 + 3 + \cdots + (c-1) + c 
        = \frac{(c-1)c}{2} + c \\\qquad
        = \frac{c^2 - c + 2c}{2} \\
        = \frac{c(c+1)}{2},
$$
which means the theorem does hold for $c$, after all! That is, $c$ is
not a counterexample. But this is a contradiction. And we are done.

\noindent
Well, almost. Our argument contains a bug. Everything we said
after~[$\ast$] bases on the fact that $c-1$ actually exists. That is,
that there is indeed some nonnegative integer smaller than $c$. How do we
know that? How do we know that $c$ is not~0? Fortunately, this can be
fixed. We know $c\neq 0$ because $c$ is a counterexample whereas $0$
is not, as $0=0(0+1)/2$.
\end{proof}
\fi

Mathematicians commonly use the Well Ordering Principle because it can
lead to shorter proofs than induction.  On the other hand, well ordering
proofs typically involve proof by contradiction, so using it is not always
the best approach.  The choice of method is really a matter of style---but
style does matter.

%% Induction versus Well Ordering Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\startclassproblems

\endinput
