\chapter{Conditional Probability}\label{chap:cond_prob}

\section{Definition}

Suppose that we pick a random person in the world.  Everyone has an
equal chance of being selected.  Let $A$ be the event that the person
is an MIT student, and let $B$ be the event that the person lives in
Cambridge.  What are the probabilities of these events?  Intuitively,
we're picking a random point in the big ellipse shown in
Figure~\ref{fig:15B1} and asking how likely that point is to fall into
region $A$ or $B$.

\begin{figure}[h]

\graphic{cambridge-conditional}

\caption{Selecting a random person.  $A$ is the event that the person
  is an MIT student.  $B$ is the even that the person lives in
  Cambridge.}

\label{fig:15B1}

\end{figure}

The vast majority of people in the world neither live in Cambridge nor
are MIT students, so events $A$ and $B$ both have low probability.
But what about the probability that a person is an MIT student,
\emph{given} that the person lives in Cambridge?  This should be
much greater---but what is it exactly?

What we're asking for is called a \term{conditional probability}; that
is, the probability that one event happens, given that some other
event definitely happens.  Questions about conditional probabilities
come up all the time:
%
\begin{itemize}
\item What is the probability that it will rain this afternoon, given
that it is cloudy this morning?
\item What is the probability that two rolled dice sum to 10, given
that both are odd?
\item What is the probability that I'll get four-of-a-kind in Texas No
Limit Hold 'Em Poker, given that I'm initially dealt two queens?
\end{itemize}

There is a special notation for conditional probabilities.  In
general, $\prcond{A}{B}$ denotes the probability of event $A$, given
that event $B$ happens.  So, in our example, $\prcond{A}{B}$ is the
probability that a random person is an MIT student, given that he or
she is a Cambridge resident.

How do we compute $\prcond{A}{B}$?  Since we are \emph{given} that the
person lives in Cambridge, we can forget about everyone in the world
who does not.  Thus, all outcomes outside event $B$ are irrelevant.
So, intuitively, $\prcond{A}{B}$ should be the fraction of Cambridge
residents that are also MIT students; that is, the answer should be
the probability that the person is in set $A \intersect B$ (the darkly
shaded region in Figure~\ref{fig:15B1}) divided by the probability
that the person is in set $B$ (the lightly shaded region).  This
motivates the definition of conditional probability:
\begin{definition}\label{LN12:prcond}
\[
\prcond{A}{B} \eqdef \frac{\pr{A \intersect B}}{\pr{B}}
\]
\end{definition}
If $\pr{B} = 0$, then the conditional probability $\prcond{A}{B}$ is
undefined.

Pure probability is often counterintuitive, but conditional
probability is even worse!  Conditioning can subtly alter
probabilities and produce unexpected results in randomized algorithms
and computer systems as well as in betting games.  Yet, the
mathematical definition of conditional probability given above is very
simple and should give you no trouble---provided that you rely on
formal reasoning and not intuition.  The four-step method will also be
very helpful as we will see in the next examples.

\section{Using the Four-Step Method to Determine Conditional
  Probability}

\subsection{The ``Halting Problem''}

The \emph{Halting Problem} was the first example of a property that
could not be tested by any program.  It was introduced by Alan Turing
in his seminal 1936 paper.  The problem is to determine whether a
Turing machine halts on a given \dots yadda yadda yadda \dots more
importantly, it was the name of the MIT EECS department's famed
C-league hockey team.

In a best-of-three tournament, the Halting Problem wins the first game
with probability $1/2$.  In subsequent games, their
probability of winning is determined by the outcome of the previous
game.  If the Halting Problem won the previous game, then they are
invigorated by victory and win the current game with probability
$2/3$.  If they lost the previous game, then they are
demoralized by defeat and win the current game with probability only
$1/3$.  What is the probability that the Halting Problem wins
the tournament, given that they win the first game?


This is a question about a conditional probability.  Let $A$ be the
event that the Halting Problem wins the tournament, and let $B$ be the
event that they win the first game.  Our goal is then to determine the
conditional probability $\prcond{A}{B}$.

We can tackle conditional probability questions just like ordinary
probability problems: using a tree diagram and the four step method.
A complete tree diagram is shown in Figure~\ref{fig:15B2}.

\begin{figure}[h]

\graphic{hockey}

\caption{The tree diagram for computing the probability that the
  ``Halting Problem'' wins two out of three games given that they won
  the first game.}

\label{fig:15B2}

\end{figure}

\paragraph{Step 1:  Find the Sample Space}

Each internal vertex in the tree diagram has two children, one
corresponding to a win for the Halting Problem (labeled~$W$) and one
corresponding to a loss (labeled~$L$).  The complete sample space is:
%
\[
    \sspace = \set{ WW, \, WLW,\, WLL,\, LWW,\, LWL,\, LL }.
\]

\paragraph{Step 2:  Define Events of Interest}

The event that the Halting Problem wins the whole tournament is:
%
\[
    T = \set{WW,\, WLW,\, LWW}.
\]
%
And the event that the Halting Problem wins the first game is:
%
\[
    F = \set{WW,\, WLW,\, WLL }.
\]
%
The outcomes in these events are indicated with check marks in the tree
diagram in Figure~\ref{fig:15B2}.

\paragraph{Step 3:  Determine Outcome Probabilities}

Next, we must assign a probability to each outcome.  We begin by
labeling edges as specified in the problem statement.  Specifically,
The Halting Problem has a $1/2$ chance of winning the first game, so
the two edges leaving the root are each assigned probability $1/2$.
Other edges are labeled $1/3$ or $2/3$ based on the outcome of the
preceding game.  We then find the probability of each outcome by
multiplying all probabilities along the corresponding root-to-leaf
path.  For example, the probability of outcome $WLL$ is:
%
\[
    \frac{1}{2} \cdot \frac{1}{3} \cdot \frac{2}{3} = \frac{1}{9}.
\]

\subsubsection*{Step 4: Compute Event Probabilities}

We can now compute the probability that The Halting Problem wins the
tournament, given that they win the first game:
%
\begingroup
\openup2pt
\begin{align*}
\prcond{A}{B}
    & = \frac{\pr{A \intersect B}}{\pr{B}} \\
    & = \frac{\pr{\set{WW, WLW}}}{\pr{\set{WW, WLW, WLL}}} \\
    & = \frac{1/3 + 1/18}{1/3 + 1/18 + 1/9} \\
    & = \frac{7}{9}.
\end{align*}
\endgroup
%
We're done!  If the Halting Problem wins the first game, then they win
the whole tournament with probability $7 / 9$.


\subsection{Why Tree Diagrams Work}\label{product_rule_subsec}

We've now settled into a routine of solving probability problems using
tree diagrams.  But we've left a big question unaddressed: what is the
mathematical justification behind those funny little pictures?  Why do
they work?

The answer involves conditional probabilities.  In fact, the
probabilities that we've been recording on the edges of tree diagrams
\emph{are} conditional probabilities.  For example, consider the
uppermost path in the tree diagram for the Halting Problem, which
corresponds to the outcome $WW$.  The first edge is labeled $1/2$,
which is the probability that the Halting Problem wins the first game.
The second edge is labeled $2 / 3$, which is the probability that the
Halting Problem wins the second game, \emph{given} that they won the
first---that's a conditional probability!  More generally, on each
edge of a tree diagram, we record the probability that the experiment
proceeds along that path, given that it reaches the parent vertex.

So we've been using conditional probabilities all along.  But why can
we multiply edge probabilities to get outcome probabilities?  For
example, we concluded that:
%
\begin{equation*}
\pr{WW} = \frac{1}{2} \cdot \frac{2}{3}
	= \frac{1}{3}.
\end{equation*}
%
Why is this correct?

The answer goes back to Definition~\ref{LN12:prcond} of conditional probability
which could be written in a form called the \term{Product Rule} for
probabilities:
%
\begin{rul*}[Product Rule for 2 Events]
If $\pr{E_1} \neq 0$, then:
%
\[
    \pr{E_1 \intersect E_2} = \pr{E_1} \cdot \prcond{E_2}{E_1}.
\]
\end{rul*}
%
Multiplying edge probabilities in a tree diagram amounts to evaluating
the right side of this equation.  For example:
%
\begin{align*}
\lefteqn{\pr{\text{win first game} \intersect \text{win second game}}}
		\hspace{0.5in} \\[2pt]
	& = \pr{\text{win first game}} \cdot
            \prcond{\text{win second game}}{\text{win first game}} \\[2pt]
	& = \frac{1}{2} \cdot \frac{2}{3}.
\end{align*}
%
So the Product Rule is the formal justification for multiplying edge
probabilities to get outcome probabilities!  Of course to justify
multiplying edge probabilities along longer paths, we need a Product Rule
for $n$ events.

% \dmj{I need to have another go at formatting this equation.}
\begin{rul*}[Product Rule for $n$ Events]
\begin{align*}
\pr{E_1 \intersect E_2 \intersect \dots \intersect E_n}
   =& \pr{E_1}
        \cdot \prcond{E_2}{E_1}
        \cdot \prcond{E_3}{E_1 \intersect E_2}
        \cdots \\
    &\quad\cdot
        \prcond{E_n}{E_1 \intersect E_2 \intersect \dots
          \intersect E_{n - 1}}
\end{align*}
provided that
\begin{equation*}
    \pr{E_1 \intersect E_2 \intersect \cdots \intersect E_{n - 1}}
    \neq 0.
\end{equation*}
\end{rul*}
This rule follows from the definition of conditional probability and
induction on~$n$.



\subsection{Medical Testing}\label{med_test-subsection}

\dmj{Honestly, is this the most dignified example you could come up
  with?}
\ftl{Good point.  Let's flag it to be changed.}
There is an unpleasant condition called \emph{BO} suffered by 10\% of the
population.  There are no prior symptoms; victims just suddenly start to
stink.  Fortunately, there is a test for latent \emph{BO} before things
start to smell.  The test is not perfect, however:
\begin{itemize}

\item If you have the condition, there is a 10\% chance
that the test will say you do not.  These are called ``false
negatives''.

\item If you do not have the condition, there is a 30\% chance that the test
will say you do.  These are ``false positives''.

\end{itemize}

Suppose a random person is tested for latent \emph{BO}.  If the test is
positive, then what is the probability that the person has the condition?

\subsubsection*{Step 1: Find the Sample Space}

The sample space is found with the tree diagram in
Figure~\ref{fig:15C1}.

\begin{figure}[h]

\graphic{BO}

\caption{The tree diagram for the BO problem.}

\label{fig:15C1}

\end{figure}

\subsubsection*{Step 2: Define Events of Interest}

Let $A$ be the event that the person has \emph{BO}.  Let $B$ be the
event that the test was positive.  The outcomes in each event are marked
in the tree diagram.  We want to find $\prcond{A}{B}$, the probability
that a person has \emph{BO}, given that the test was positive.

\subsubsection*{Step 3: Find Outcome Probabilities}

First, we assign probabilities to edges.  These probabilities are
drawn directly from the problem statement.  By the Product Rule, the
probability of an outcome is the product of the probabilities on the
corresponding root-to-leaf path.  All probabilities are shown in
Figure~\ref{fig:15C1}.

\subsubsection*{Step 4: Compute Event Probabilities}

From Definition~\ref{LN12:prcond}, we have
\begin{equation*}
\prcond{A}{B}	= \frac{\pr{A \intersect B}}{\pr{B}} %\\[2pt]
		= \frac{0.09}{0.09 + 0.27} %\\[2pt]
		= \frac{1}{4}.
\end{equation*}
%
So, if you test positive, then there is only a 25\% chance that you
have the condition!

This answer is initially surprising, but makes sense on reflection.
There are two ways you could test positive.  First, it could be that
you have the condition and the test is correct.  Second, it could be that you
are healthy and the test is incorrect.  The problem is that almost
everyone is healthy; therefore, most of the positive results arise
from incorrect tests of healthy people!

We can also compute the probability that the test is correct for a
random person.  This event consists of two outcomes.  The person could
have the condition and test positive (probability $0.09$), or the person
could be healthy and test negative (probability $0.63$).
Therefore, the test is correct with probability $0.09 + 0.63 = 0.72$.
This is a relief; the test is correct almost three-quarters of the
time.

But wait!  There is a simple way to make the test correct 90\% of the
time: always return a negative result!  This ``test'' gives the right
answer for all healthy people and the wrong answer only for the 10\%
that actually have the condition.  So a better strategy by this
measure is to completely ignore the test result!

There is a similar paradox in weather forecasting.  During winter,
almost all days in Boston are wet and overcast.  Predicting miserable
weather every day may be more accurate than really trying to get it
right!


\section{\emph{A Posteriori} Probabilities}\label{aposteriori_subsec}

If you think about it too much, the medical testing problem we just
considered could start to trouble you.  The concern would be that by
the time you take the test, you either have the BO condition or you
don't---you just don't know which it is.  So you may wonder if a
statement like ``If you tested positive, then you have the condition
with probability~25\%'' makes sense.

In fact, such a statement does make sense.  It means that 25\% of the
people who test positive actually have the condition.  It is true that
any particular person has it or they don't, but a \emph{randomly
  selected} person among those who test positive will have the
condition with probability~25\%.

Anyway, if the medical testing example bothers you, you will
definitely be worried by the following examples, which go even further
down this path.

\subsection{The ``Halting Problem,'' in Reverse}

Suppose that we turn the hockey question around: what is the
probability that the Halting Problem won their first game, given that
they won the series?

This seems like an absurd question!  After all, if the Halting Problem
won the series, then the winner of the first game has already been
determined.  Therefore, who won the first game is a question of fact,
not a question of probability.  However, our mathematical theory of
probability contains no notion of one event preceding another---there
is no notion of time at all.  Therefore, from a mathematical
perspective, this is a perfectly valid question.  And this is also a
meaningful question from a practical perspective.  Suppose that you're
told that the Halting Problem won the series, but not told the results
of individual games.  Then, from your perspective, it makes perfect
sense to wonder how likely it is that The Halting Problem won the
first game.

A conditional probability $\prcond{B}{A}$ is called  \term{a
posteriori} if event $B$ precedes event $A$ in time.  Here are some
other examples of a posteriori probabilities:
%
\begin{itemize}
\item The probability it was cloudy this morning, given that it rained
in the afternoon.
\item The probability that I was initially dealt two queens in Texas
No Limit Hold 'Em poker, given that I eventually got four-of-a-kind.
\end{itemize}
%
Mathematically, a posteriori probabilities are \emph{no different}
from ordinary probabilities; the distinction is only at a higher,
philosophical level.  Our only reason for drawing attention to them is
to say, ``Don't let them rattle you.''

Let's return to the original problem.  The probability that the
Halting Problem won their first game, given that they won the series
is $\prcond{B}{A}$.  We can compute this using the definition of
conditional probability and the tree diagram in Figure~\ref{fig:15B2}:
%
\begin{align*}
\prcond{B}{A}  = \frac{\pr{B \intersect A}}{\pr{A}} %\\[2pt]
               = \frac{1/3 + 1/18}{1/3 + 1/18 + 1/9} %\\[2pt]
               = \frac{7}{9}.
\end{align*}

This answer is suspicious!  In the preceding section, we showed that
$\prcond{A}{B}$ was also $7/9$.  Could it be true that $\prcond{A}{B}
= \prcond{B}{A}$ in general?  Some reflection suggests this is
unlikely.  For example, the probability that I feel uneasy, given that
I was abducted by aliens, is pretty large.  But the probability that I
was abducted by aliens, given that I feel uneasy, is rather small.

Let's work out the general conditions under which $\prcond{A}{B} =
\prcond{B}{A}$.  By the definition of conditional probability, this
equation holds if an only if:
%
\[
\frac{\pr{A \intersect B}}{\pr{B}} = \frac{\pr{A \intersect B}}{\pr{A}}
\]
%
This equation, in turn, holds only if the denominators are equal or
the numerator is~0; namely if
%
\[
\pr{B} = \pr{A}
\hspace{0.25in} \text{or} \hspace{0.25in}
\pr{A \intersect B} = 0.
\]
%
The former condition holds in the hockey example; the probability that
the Halting Problem wins the series (event~$A$) is equal to the
probability that it wins the first game (event~$B$) since both
probabilities are~$1/2$.

In general, such pairs of probabilities are related by \idx{Bayes'
  Rule}:
%
\begin{theorem}[Bayes' Rule]
If $\pr{A}$ and $\pr{B}$ are nonzero, then:
%
\begin{equation}\label{bayesrule}
    \prcond{B}{A} = \frac{\prcond{A}{B} \cdot \pr{B}}{\pr{A}}
\end{equation}
\end{theorem}

\begin{proof}
When $\pr{A}$ and $\pr{B}$ are nonzero, we have
\[
\prcond{A}{B} \cdot \pr{B} = \prob{A \intersect B} = \prcond{B}{A} \cdot \pr{A}
\]
by definition of conditional probability.  Dividing by $\prob{A}$
gives~\eqref{bayesrule}.
\end{proof}

Next, let's look at a problem that even bothers us.

%% Conditional Probability Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problems}
\practiceproblems
\pinput{TP_six_shooter_probability}

\classproblems
\pinput{CP_missing_card_probability}
\pinput{CP_conditional_prob_says_so_bug}

\homeworkproblems
\pinput{PS_conditional_probability_problem_errors}
\pinput{PS_coin_flip_sequences}
\pinput{PS_13_card_hand}
\pinput{PS_neighborhood_census}
\end{problems}

\subsection{A Coin Problem}

Suppose that someone hands you either a fair coin or a trick coin with
heads on both sides.  You flip the coin 100 times and see heads every
time.  What can you say about the probability that you flipped the
fair coin?  Remarkably, nothing!

In order to make sense out of this outrageous claim, let's formalize
the problem.  The sample space is worked out in the tree diagram shown
in Figure~\ref{fig:15C2}.  We do not know the probability~$p$ that you
were handed the fair coin initially---you were just given one coin or
the other.
%
\begin{figure}[h]

\graphic{trick-coin}

\caption{The tree diagram for the coin-flipping problem.}

\label{fig:15C2}

\end{figure}
%
Let $A$ be the event that you were handed the fair coin, and let $B$
be the event that you flipped 100 straight heads.  We're looking
for $\prcond{A}{B}$, the probability that you were handed the fair
coin, given that you flipped 100 heads.  The outcome probabilities are
worked out in Figure~\ref{fig:15C2}.  Plugging the results into the
definition of conditional probability gives:
%
\begin{align*}
\prcond{A}{B}	& = \frac{\pr{A \intersect B}}{\pr{B}} \\[2pt]
		& = \frac{p / 2^{100}}{1 - p + p / 2^{100}} \\[2pt]
		& = \frac{p}{2^{100} (1 - p) + p}.
\end{align*}
%
This expression is very small for moderate values of $p$ because of
the $2^{100}$ term in the denominator.  For example, if $p = 1/2$,
then the probability that you were given the fair coin is essentially
zero.

But we \emph{do not know} the probability $p$ that you were given
the fair coin.  And perhaps the value of $p$ is \emph{not} moderate;
in fact, maybe $p = 1 - 2^{-100}$.  Then there is nearly an even
chance that you have the fair coin, given that you flipped 100 heads.
In fact, maybe you were handed the fair coin with probability $p = 1$.
Then the probability that you were given the fair coin is, well,~1!

Of course, it is extremely unlikely that you would flip 100 straight
heads, but in this case, that is a given from the assumption of the
conditional probability.  And so if you really did see 100 straight
heads, it would be very tempting to also assume that $p$~is not close
to~1 and hence that you are very likely to have flipped the trick
coin.

We will encounter a very similar issue when we look at methods for
estimation by sampling in Section~\ref{sec:sampling}.

\section{Conditional Identities}

\subsection{The Law of Total Probability}\label{sec:total_probability}

Breaking a probability calculation into cases simplifies many
problems.  The idea is to calculate the probability of an event $A$ by
splitting into two cases based on whether or not another event $E$
occurs.  That is, calculate the probability of $A\nobreak
\intersect\nobreak E$ and $A \intersect \setcomp{E}$.  By the Sum
Rule, the sum of these probabilities equals $\pr{A}$.  Expressing the
intersection probabilities as conditional probabilities yields:
\begin{rul}[Law of Total Probability, single
    event]\label{total_prob_Ebar}
If $\prob{E}$ and $\prob{\setcomp{E}}$~are nonzero, then
\[
\pr{A} = \prcond{A}{E} \cdot \pr{E} +
         \prcond{A}{\setcomp{E}} \cdot \pr{\setcomp{E}}.
\]
\end{rul}

For example, suppose we conduct the following experiment.  First, we
flip a fair coin.  If heads comes up, then we roll one die and take the
result.  If tails comes up, then we roll two dice and take the sum of
the two results.  What is the probability that this process yields a
2?  Let $E$ be the event that the coin comes up heads, and let $A$ be
the event that we get a 2 overall.  Assuming that the coin is fair,
$\pr{E} = \pr{\setcomp{E}} = 1/2$.  There are now two cases. If we
flip heads, then we roll a 2 on a single die with probability
$\prcond{A}{E} = 1/6$.  On the other hand, if we flip tails, then we
get a sum of 2 on two dice with probability
$\prcond{A}{\setcomp{E}} = 1/36$.  Therefore, the probability that
the whole process yields a 2 is
\[
\pr{A} = \frac{1}{2} \cdot \frac{1}{6} + \frac{1}{2} \cdot \frac{1}{36} =
  \frac{7}{72}.
\]

There is also a form of the rule to handle more than two cases.
\begin{rul}[Law of Total Probability]
If $E_1, \dots, E_n$ are disjoint events whose union is the whole
sample space, then:
\[
\pr{A} = \sum_{i=1}^{n} \prcond{A}{E_i} \cdot \pr{E_i}.
\]
\end{rul}

\subsection{Conditioning on a Single Event}\label{cond_ident_subsec}

The probability rules that we derived in Chapter~\ref{probability_chap}
extend to probabilities conditioned on the same event.  For example,
the Inclusion-Exclusion formula for two sets holds when all
probabilities are conditioned on an event $C$:
\[
\prcond{A \cup B}{C} = \prcond{A}{C} + \prcond{B}{C} - \prcond{A \intersect B}{C}.
\]
This follows from the fact that if $\pr{C} \neq 0$, then
\begin{align*}
\prcond{A \union B}{C}
    &= \frac{\pr{(A \union B) \intersect C}}{\pr{C}} \\[3pt]
    &= \frac{\pr{(A \intersect C) \union (B \intersect C)}}{\pr{C}} \\[3pt]
    &= \frac{\pr{A \intersect C} + \pr{B \intersect C}
             - \pr{A \intersect B \intersect C}}
            {\pr{C}} \\[3pt]
    &= \prcond{A}{C} + \prcond{B}{C} - \prcond{A \intersect B}{C}.
\end{align*}

It is important not to mix up events before and after the conditioning
bar.  For example, the following is \emph{not} a valid identity:
%
\begin{falseclm*}
\begin{equation}\label{LN12:fc}
\prcond{A}{B \cup C} = \prcond{A}{B} + \prcond{A}{C} - \prcond{A}{B \intersect C}.
\end{equation}
\end{falseclm*}

A counterexample is shown in Figure~\ref{fig:15D2}.  In this case,
$\prcond{A}{B} = 1/2$, $\prcond{A}{C} = 1/2$, $\prcond{A}{B \intersect
  C} = 1$, and $\prcond{A}{B \union C} = 1/3$.  However, since
$1/3 \ne 1/2 + 1/2 - 1$, Equation~\ref{LN12:fc} does not hold.
%
\begin{figure}

\graphic{cx19}

\caption{A counterexample to Equation~\ref{LN12:fc}.  Event~$A$ is the
  gray rectangle, event~$B$ is the rectangle with vertical stripes,
  and event~$C$ is the rectangle with horizontal stripes.  $B
  \intersect C$ lies entirely within~$A$ while $B - C$ and $C - B$ are
  entirely outside of~$A$.}

\label{fig:15D2}

\end{figure}

So you're convinced that this equation is false in general, right?
Let's see if you \emph{really} believe that.

\subsection{Discrimination Lawsuit}\label{discrimination_subsec}

Several years ago there was a sex discrimination lawsuit against a
famous university.  A female math professor was denied tenure,
allegedly because she was a woman.  She argued that in every one of
the university's 22 departments, the percentage of male applicants
accepted was greater than the percentage of female applicants
accepted.  This sounds very suspicious!

However, the university's lawyers argued that across the university as
a whole, the percentage of male applicants accepted was actually
\emph{lower} than the percentage of female applicants accepted.  This
suggests that if there was any sex discrimination, then it was against
men!  Surely, at least one party in the dispute must be lying.

Let's simplify the problem and express both arguments in terms of
conditional probabilities.  To simplify matters, suppose that there
are only two departments, EE and CS, and consider the experiment where
we pick a random applicant.  Define the following events:
%
\begin{itemize}
\item Let $A$ be the event that the applicant is accepted.
\item Let $F_{EE}$ the event that the applicant is a female applying to EE.
\item Let $F_{CS}$ the event that the applicant is a female applying to CS.
\item Let $M_{EE}$ the event that the applicant is a male applying to EE.
\item Let $M_{CS}$ the event that the applicant is a male applying to
CS.
\end{itemize}
%
Assume that all applicants are either male or female, and that no
applicant applied to both departments.  That is, the events $F_{EE}$,
$F_{CS}$, $M_{EE}$, and $M_{CS}$ are all disjoint.

In these terms, the plaintiff is making the following argument:
%
\begin{align*}
\prcond{A}{F_{EE}} & < \prcond{A}{M_{EE}} \quad\text{and}\\
\prcond{A}{F_{CS}} & < \prcond{A}{M_{CS}}.
\end{align*}
%
That is, in both departments, the probability that a woman is accepted
for tenure is less than the probability that a man is accepted.  The
university retorts that overall, a woman applicant is \emph{more}
likely to be accepted than a man; namely that
%
\[
    \prcond{A}{F_{EE} \cup F_{CS}} > \prcond{A}{M_{EE} \cup M_{CS}}.
\]

It is easy to believe that these two positions are contradictory.  In
fact, we might even try to prove this by adding the plaintiff's two
inequalities and then arguing as follows:
%
\begin{align*}
&& \prcond{A}{F_{EE}} + \prcond{A}{F_{CS}} & <
	\prcond{A}{M_{EE}} + \prcond{A}{M_{CS}} \\
\Rightarrow &&
\prcond{A}{F_{EE} \cup F_{CS}} & <
	\prcond{A}{M_{EE} \cup M_{CS}}.
\end{align*}
%
The second line exactly contradicts the university's position!  But there
is a big problem with this argument; the second inequality follows from
the first only if we accept the false identity~\eqref{LN12:fc}.  This argument
is bogus!  Maybe the two parties do not hold contradictory positions after
all!

In fact, Table~\ref{fig:15D3} shows a set of application
statistics for which the assertions of both the plaintiff and the
university hold.  In this case, a higher percentage of males were
accepted in both departments, but overall a higher percentage of
females were accepted!  Bizarre!

\begin{table}

\begin{tabular}{crr}
CS & 0 females accepted, 1 applied      &   0\% \\
   & 50 males accepted, 100 applied     &  50\% \\
EE & 70 females accepted, 100 applied   &  70\% \\
   & 1 male accepted, 1 applied         & 100\% \\
\hline
Overall & 70 females accepted, 101 applied & $\approx 70\%$ \\
        & 51 males accepted, 101 applied   & $\approx 51\%$
\end{tabular}

\caption{A scenario where females are less likely to be admitted than
  males in each department, but more likely to be admitted overall.}

\label{fig:15D3}

\end{table}

\problemsection

\endinput
