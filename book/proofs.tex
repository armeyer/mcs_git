\chapter{What is a Proof?}\label{proofs_chap}

\section{Propositions}\label{prop_sec}

\begin{definition*}
  A \term{proposition} is a statement (communication) that is either
  true or false.
\end{definition*}

For example, both of the following statements are propositions.  The
first is true, and the second is false.
\begin{proposition}
2 + 3 = 5.
\end{proposition}

\begin{proposition}
1 + 1 = 3.
\end{proposition}

Being true or false doesn't sound like much of a limitation, but it does
exclude statements such as ``Wherefore art thou Romeo?'' and ``Give me an
\emph{A}!''  It also excludes statements whose truth varies with
circumstance such as, ``It's five o'clock,'' or ``the stock market will
rise tomorrow.''

\iffalse
Being ``mathematical'' is a more serious restriction.  For example,
``Albert's wife's name is `Irene'~'' is a true statement, and you
could prove it by presenting legal documents and the testimony of
their children.  But it isn't a proposition because it is not a
\emph{mathematical} statement.  There is no mathematical definition of
Albert or Irene, and statements about them are not part of
mathematics.  Propositions must be about well-defined mathematical
objects like numbers, sets, functions, relations, \etc, and they must
be stated using mathematically precise language.  We can illustrate
this with a few examples.
\fi

Unfortunately it is not always easy to decide if a claimed proposition
is true or false:
\begin{claim}\label{41form}
For every nonnegative integer $n$ the value of $n^2 + n + 41$ is prime.
\end{claim}
(A \emph{prime}%
\index{prime} 
is an integer greater than 1 that is not divisible by
any other integer greater than 1.  For example, 2, 3, 5, 7, 11, are
the first five primes.)  Let's try some numerical experimentation to
check this proposition.  Let

\begin{equation}\label{pn41}
p(n) \eqdef  n^2 + n + 41.\footnote{The symbol $\eqdef$ means
 ``equal by definition.''  It's always ok simply to write ``='' instead of
 $\eqdef$, but reminding the reader that an equality holds by definition
 can be helpful.}
\end{equation}
We begin with $p(0) = 41$, which is prime; then
\[
p(1) = 43, p(2) = 47, p(3)=53, \dots, p(20) = 461
\]
are each prime.  Hmmm, starts to look like a plausible claim.  In fact
we can keep checking through $n=39$ and confirm that $p(39)=1601$ is
prime.

But $p(40) = 40^2 + 40 + 41 = 41 \cdot 41$, which is not prime.  So
Claim~\ref{41form} is false since it's not true that $p(n)$ is prime
\emph{for all} nonnegative integers $n$.  In fact, it's not hard to
show that \emph{no} polynomial with integer coefficients can map all
nonnegative numbers into prime numbers, unless it's a constant (see
Problem~\ref{PS_prime_polynomial_41}).  But this example highlights
the point that, in general, you can't check a claim about an infinite
set by checking a finite sample of its elements, no matter how large
the sample.

By the way, propositions like this about \emph{all} numbers or all items
of some kind are so common that there is a special notation for them.
With this notation, Claim~\ref{41form} would be
\begin{equation}\label{pn}
\forall n \in \nngint.\; p(n) \text{ is prime}.
\end{equation}
Here the symbol $\forall$ is read ``for all.''  The symbol $\nngint$
stands for the set of {\em nonnegative integers}: 0, 1, 2, 3, \dots
(ask your instructor for the complete list).  The symbol ``$\in$'' is
read as ``is a member of,'' or ``belongs to,'' or simply as ``is in.''
The period after the $\nngint$ is just a separator between phrases.

Here are two even more extreme examples:
\begin{conject*}\label{a4}[Euler]
The equation
\[
a^4 + b^4 + c^4 = d^4
\]
has no solution when $a, b, c, d$ are positive integers.
\end{conject*}
\idx{Euler} (pronounced ``oiler'') conjectured this in 1769.  But the
conjecture was proved false 218 years later by Noam Elkies at a
liberal arts school up Mass Ave.  The solution he found was $a =
95800, b = 217519, c = 414560, d = 422481$.

In logical notation, Euler's Conjecture \iffalse
Proposition~\ref{a4}\fi could be written,
\[
\forall a \in \posints\, \forall b \in \posints\, \forall c \in \posints\, \forall
d \in \posints.\; a^4 + b^4 + c^4 \neq d^4.
\]
Here, $\posints$ is a symbol for the positive integers.
Strings of $\forall$'s like this are usually abbreviated for easier reading:
\[
\forall a, b, c, d \in \posints.\; a^4 + b^4 + c^4 \neq d^4.
\]

Here's another claim which would be hard to falsify by sampling: the
smallest possible $x,y,z$ that satisfy the equality each have more
than 1000 digits!
\begin{falseclm*}
$313 (x^3 + y^3) = z^3$ has no solution when $x, y, z\in\posints$.
\end{falseclm*}

It's worth mentioning a couple of further famous propositions whose
proofs were sought for centuries before finally being discovered:

\begin{proposition}[\idx{Four Color Theorem}]\label{4colorprop}
  Every map can be colored with 4 colors so that adjacent\footnote{Two
    regions are adjacent only when they share a boundary segment of
    positive length.  They are not considered to be adjacent if their
    boundaries meet only at a few points.} regions have different
  colors.
\end{proposition}

Several incorrect proofs of this theorem have been published,
including one that stood for 10 years in the late 19th century before
its mistake was found.  A laborious proof was finally found in 1976 by
mathematicians Appel and Haken, who used a complex computer program to
categorize the four-colorable maps.  The program left a few thousand
maps uncategorized, which were checked by hand by Haken and his
assistants---among them his 15-year-old daughter.  

There was reason to doubt whether this was a legitimate proof---the
proof was too big to be checked without a computer.  No one could
guarantee that the computer calculated correctly, nor was anyone
enthusiastic about exerting the effort to recheck the four-colorings
of thousands of maps that were done by hand.  Two decades later a
mostly
\href{http://www.math.gatech.edu/~thomas/FC/fourcolor.html}{intelligible
  proof} of the Four Color Theorem was found, though a computer is
still needed to check four-colorability of several hundred special
maps.\footnote{The story of the proof of the Four Color Theorem is
  told in a well-reviewed popular (non-technical) book: ``Four Colors
  Suffice.  How the Map Problem was Solved.'' \emph{Robin Wilson}.
  Princeton Univ. Press, 2003, 276pp. ISBN 0-691-11533-8.}

\begin{proposition}[\idx{Fermat's Last Theorem}]\label{fermatlast}
There are no positive integers $x$, $y$ and $z$ such that
\[
x^n + y^n = z^n
\]
for some integer $n > 2$.
\end{proposition}

In a book he was reading around 1630, \idx{Fermat} claimed to have a
proof for this proposition, but not enough space in the margin to
write it down.  Over the years, the Theorem was proved to hold for all
$n$ up to 4,000,000, but we've seen that this shouldn't necessarily
inspire confidence that it holds for \emph{all} $n$.  There is, after
all, a clear resemblance between Fermat's Last Theorem and Euler's
false Conjecture.  Finally, in 1994, British mathematician Andrew
Wiles gave a proof, after seven years of working in secrecy and
isolation in his attic.  His proof did not fit in any
margin.\footnote{In fact, Wiles' original proof was wrong, but he and
  several collaborators used his ideas to arrive at a correct proof a
  year later.  This story is the subject of the popular book,
  \emph{Fermat's Enigma} by Simon Singh, Walker \& Company, November,
  1997.}

Finally, let's mention another simply stated proposition whose truth
remains unknown.

\index{Goldbach's Conjecture|seealso{prime}}
\begin{conject}[\term{Goldbach}]\label{Goldbach}
Every even integer greater than 2 is the sum of two primes.
\end{conject}

Goldbach's Conjecture dates back to 1742.  It is known to hold for all
numbers up to $10^{18}$, but to this day, no one knows whether it's
true or false.

\vspace{0.3in} For a computer scientist, some of the most important
things to prove are the correctness of programs and systems---whether
a program or system does what it's supposed to.  Programs are
notoriously buggy, and there's a growing community of researchers and
practitioners trying to find ways to prove program correctness.  These
efforts have been successful enough in the case of CPU chips that they
are now routinely used by leading chip manufacturers to prove chip
correctness and avoid some notorious past mistakes.
\begin{editingnotes}
ref needed
\end{editingnotes}

Developing mathematical methods to verify programs and systems remains
an active research area.  We'll illustrate some of these methods in
Chapter~\ref{induction_chap}.

\begin{problems}
\classproblems
\pinput{CP_pythagorean}
\pinput{CP_bogus_1eqminus1_proof}
\pinput{CP_buggy_highschool_proofs}
\pinput{CP_bogus_arithmetic_mean_proof}
\pinput{CP_surprise_quiz_next_week}

%\practiceproblems
%\pinput{TP_surprise_philosophy}

\end{problems}

\section{Predicates}

A \term{predicate} can be understood as a proposition whose truth
depends on the value of one or more variables.  So ``$n$ is a perfect
square'' describes a predicate, since you can't say if it's true or
false until you know what the value of the variable $n$ happens to be.
Once you know, for example, that $n$ equals 4, the predicate becomes
the true proposition ``4 is a perfect square''.  Remember, nothing says
that the proposition has to be true: if the value of $n$ were 5, you
would get the false proposition ``5 is a perfect square.''


\begin{editingnotes}
\textcolor{red}{From Mairson: Sept '11}

A predicate is an expression that, when you replace all variables in
the expression with values, is a proposition.  So "n is a perfect
square" is a predicate because, upon replacing n with a number 4
(among an infinite number of such choices), you get the proposition "4
is a perfect square".  Remember, nothing says that the proposition has
to be true---replacing n with 5 would give "5 is a perfect square",
which is false.
\end{editingnotes}

\iffalse
Most of the propositions above were defined in terms of predicates.
For example,
%
\begin{center}
``$n$ is a perfect square''
\end{center}
%
is a predicate whose truth depends on the value of $n$.  The predicate is
true for $n = 4$ since four is a perfect square, but false for $n = 5$
since five is not a perfect square.  
\fi

Like other propositions, predicates are often named with a letter.
Furthermore, a function-like notation is used to denote a predicate
supplied with specific variable values.  For example, we might use the
name ``$P$'' for predicate above:
\[
P(n) \eqdef \text{``$n$ is a perfect square''},
\]
and repeat the remarks above by asserting that $P(4)$ is true, and
$P(5)$ is false.

This notation for predicates is confusingly similar to ordinary function
notation.  If $P$ is a predicate, then $P(n)$ is either \textit{true} or
\textit{false}, depending on the value of $n$.  On the other hand, if $p$
is an ordinary function, like $n^2 + 1$, then $p(n)$ is a
\textit{numerical quantity}.  \textbf{Don't confuse these two!}

\section{The Axiomatic Method}\label{axiom_method_sec}

The standard procedure for establishing truth in mathematics was
invented by \idx{Euclid}, a mathematician working in Alexandria, Egypt
around 300 BC.  His idea was to begin with five \textit{assumptions}
about geometry, which seemed undeniable based on direct experience.
(For example, ``There is a straight line segment between every pair of
points''.)  Propositions like these that are simply accepted as true are
called %
\index{axiom|textbf}% 
\emph{axioms}. 

Starting from these axioms, Euclid established the truth of many
additional propositions by providing ``proofs.''  A \term{proof} is a
sequence of logical deductions from axioms and previously proved
statements that concludes with the proposition in question.  You
probably wrote many proofs in high school geometry class, and you'll
see a lot more in this text.

There are several common terms for a proposition that has been proved.
The different terms hint at the role of the proposition within a
larger body of work.
%
\begin{itemize}
\item Important true propositions are called \emph{theorems}.%
\index{theorem|textbf}
\item A \term{lemma} is a preliminary proposition useful for proving
later propositions.
\item A \term{corollary} is a proposition that follows
in just a few logical steps from a theorem.  
\end{itemize}
These definitions are not precise.  In fact, sometimes a good lemma
turns out to be far more important than the theorem it was originally
used to prove.

Euclid's axiom-and-proof approach, now called the \emph{axiomatic
  method},%
\index{axiom!axiomatic method} remains the foundation for mathematics today.  In fact,
just a handful of axioms, called the Zermelo-Fraenkel with
Choice axioms (ZFC),%
\index{axiom!ZFC axioms} 
together with a few logical deduction rules, appear to be 
sufficient to derive essentially all of
mathematics.  We'll examine these in Chapter~\ref{infinite_chap}.

\section{Our Axioms}

The ZFC axioms are important in studying and justifying the foundations of
mathematics, but for practical purposes, they are much too primitive.
Proving theorems in ZFC is a little like writing programs in byte code
instead of a full-fledged programming language---by one reckoning, a
formal proof in ZFC that $2 + 2 = 4$ requires more than 20,000 steps!  So
instead of starting with ZFC, we're going to take a \textit{huge} set of
axioms as our foundation: we'll accept all familiar facts from high school
math.

This will give us a quick launch, but you may find this imprecise
specification of the axioms troubling at times.  For example, in the
midst of a proof, you may start to wonder, ``Must I prove this little
fact or can I take it as an axiom?''  There really is no absolute
answer, since what's reasonable to assume and what requires proof
depends on the circumstances and the audience.  A good general
guideline is simply to be up front about what you're assuming.
\begin{editingnotes} ---and
don't try to evade needed work by declaring everything an axiom!
\end{editingnotes}

\subsection{Logical Deductions }\label{logical_deductions_subsec}

Logical deductions, or \term{inference rules}, are used to prove new
propositions using previously proved ones.

A fundamental inference rule is \emph{modus ponens}.%
\index{modus ponens@\textit{modus ponens}|textbf}  This rule says that
a proof of $P$ together with a proof that $P \QIMPLIES Q$ is a proof of
$Q$.

Inference rules are sometimes written in a funny notation.  For example,
\emph{modus ponens} is written:
\begin{rul*}
\Rule{P, \quad P \QIMPLIES Q}{Q}
\end{rul*}

When the statements above the line, called the \emph{antecedents}, are
proved, then we can consider the statement below the line, called the
\emph{conclusion} or \emph{consequent}, to also be proved.

A key requirement of an inference rule is that it must be
\emph{sound}: an assignment of truth values to the letters $P$, $Q$,
\dots, that makes all the antecedents true must also make the
consequent true.  So if we start off with true axioms and apply sound
inference rules, everything we prove will also be true.

There are many other natural, sound inference rules, for example:
\begin{rul*}
  \Rule{P \QIMPLIES Q, \quad Q \QIMPLIES R}{P \QIMPLIES R}
\end{rul*}

\begin{editingnotes}

\begin{rul*}
\Rule{\QNOT(P) \QIMPLIES Q, \quad \QNOT(Q)}{P}
\end{rul*}

\end{editingnotes}

\begin{rul*}
  \Rule{\QNOT(P) \QIMPLIES \QNOT(Q)}{Q \QIMPLIES P}
\end{rul*}

On the other hand,
\begin{nonrul*}
\Rule{\QNOT(P) \QIMPLIES \QNOT(Q)}{P \QIMPLIES Q}
\end{nonrul*}
\noindent is not sound: if $P$ is assigned $\true$ and $Q$ is assigned
$\false$, then the antecedent is true and the consequent is not.

\begin{editingnotes}
NO NEED to NOTE THIS, and it's ponderous:

Note that a propositional inference rule is sound precisely when the conjunction
(AND) of all its antecedents implies its consequent.
\end{editingnotes}

As with axioms, we will not be too formal about the set of legal inference
rules.  Each step in a proof should be clear and ``logical''; in
particular, you should state what previously proved facts are used to
derive each new conclusion.

\subsection{Patterns of Proof}

In principle, a proof can be \textit{any} sequence of logical
deductions from axioms and previously proved statements that concludes
with the proposition in question.  This freedom in constructing a
proof can seem overwhelming at first.  How do you even \textit{start}
a proof?

Here's the good news: many proofs follow one of a handful of standard
templates.  Each proof has it own details, of course, but these
templates at least provide you with an outline to fill in.  We'll go
through several of these standard patterns, pointing out the basic
idea and common pitfalls and giving some examples.  Many of these
templates fit together; one may give you a top-level outline while
others help you at the next level of detail.  And we'll show you
other, more sophisticated proof techniques later on.

The recipes below are very specific at times, telling you exactly
which words to write down on your piece of paper.  You're certainly
free to say things your own way instead; we're just giving you
something you \textit{could} say so that you're never at a complete
loss.

\section{Proving an Implication}
\label{sec:prove_implies}

Propositions of the form ``If $P$, then $Q$'' are called%
\index{implication}
\emph{implications}.  This implication is often rephrased as ``$P
\QIMPLIES Q$.''

Here are some examples:
%
\begin{itemize}

\item (Quadratic Formula) If $a x^2 + b x + c = 0$ and $a \neq 0$,
then
\[
x = \paren{- b \pm \sqrt{b^2 - 4 a c}} / 2a.
\]

\item (Goldbach's Conjecture~\ref{Goldbach} rephrased) If $n$ is an
  even integer greater than $2$, then $n$ is a sum of two primes.

\item If $0 \leq x \leq 2$, then $-x^3 + 4x + 1 > 0$.

\end{itemize}
%
There are a couple of standard methods for proving an implication.

\subsection{Method \#1}

In order to prove that $P \QIMPLIES Q$:
%
\begin{enumerate}
\item Write, ``Assume $P$.''
\item Show that $Q$ logically follows.
\end{enumerate}

\subsection*{Example}

\begin{theorem}
If $0 \leq x \leq 2$, then $-x^3 + 4x + 1 > 0$.
\end{theorem}

Before we write a proof of this theorem, we have to do some
scratchwork to figure out why it is true.

The inequality certainly holds for $x = 0$; then the left side is
equal to 1 and $1 > 0$.  As $x$ grows, the $4x$ term (which is
positive) initially seems to have greater magnitude than $-x^3$ (which
is negative).  For example, when $x = 1$, we have $4x = 4$, but $-x^3
= -1$ only.  In fact, it looks like $-x^3$ doesn't begin to dominate
until $x > 2$.  So it seems the $-x^3 + 4x$ part should be nonnegative
for all $x$ between 0 and 2, which would imply that $-x^3 + 4x + 1$ is
positive.

So far, so good.  But we still have to replace all those ``seems
like'' phrases with solid, logical arguments.  We can get a better
handle on the critical $-x^3 + 4x$ part by factoring it, which is not
too hard:
%
\[
-x^3 + 4x = x (2 - x)(2 + x)
\]
%
Aha!  For $x$ between 0 and 2, all of the terms on the right side are
nonnegative.  And a product of nonnegative terms is also nonnegative.
Let's organize this blizzard of observations into a clean proof.

\begin{proof}
Assume $0 \leq x \leq 2$.  Then $x$, $2 - x$ and $2 + x$ are all
nonnegative.  Therefore, the product of these terms is also
nonnegative.  Adding 1 to this product gives a positive number, so:
%
\[
x (2 - x)(2 + x) + 1 > 0
\]
%
Multiplying out on the left side proves that
%
\[
-x^3 + 4x + 1 > 0
\]
%
as claimed.
\end{proof}

There are a couple points here that apply to all proofs:
%
\begin{itemize}

\item You'll often need to do some scratchwork while you're trying to
figure out the logical steps of a proof.  Your scratchwork can be as
disorganized as you like---full of dead-ends, strange diagrams,
obscene words, whatever.  But keep your scratchwork separate from your
final proof, which should be clear and concise.

\item Proofs typically begin with the word ``Proof'' and end with some
sort of delimiter like $\Box$ or ``QED.''  The only purpose for
these conventions is to clarify where proofs begin and end.

\end{itemize}

\subsection{Method \#2 - Prove the Contrapositive}

An \idx{implication} (``$P \QIMPLIES Q$'') is logically equivalent to its
\term{contrapositive}
\[
\QNOT(Q) \QIMPLIES \QNOT(P)\,.
\]
Proving one is as good as proving the other, and proving the
contrapositive is sometimes easier than proving the original statement.
If so, then you can proceed as follows:
%
\begin{enumerate}
\item Write, ``We prove the contrapositive:'' and then state the
contrapositive.
\item Proceed as in Method \#1.
\end{enumerate}

\subsection*{Example}

\begin{theorem}
If $r$ is irrational, then $\sqrt{r}$ is also irrational.
\end{theorem}

A number is \emph{rational} when it equals a quotient of integers
---that is, if it equals $m/n$ for some integers $m$ and $n$.  If it's
not rational, then it's called \emph{irrational}.  So we must show
that if $r$ is \textit{not} a ratio of integers, then $\sqrt{r}$ is
also \textit{not} a ratio of integers.  That's pretty convoluted!  We
can eliminate both \emph{not}'s and simplify the proof by using the
contrapositive instead.

\begin{proof}
We prove the contrapositive: if $\sqrt{r}$ is rational, then $r$ is
rational.

Assume that $\sqrt{r}$ is rational.  Then there exist integers $m$ and $n$
such that:
%
\[
\sqrt{r} = \frac{m}{n}
\]
%
Squaring both sides gives:
%
\[
r  = \frac{m^2}{n^2}
\]
%
Since $m^2$ and $n^2$ are integers, $r$ is also rational.
\end{proof}

\begin{problems}
\homeworkproblems
\pinput{PS_log7_not_in_QZ}
\end{problems}

\section{Proving an ``If and Only If''}
\label{sec:prove_iff}

Many mathematical theorems assert that two statements are logically
equivalent; that is, one holds if and only if the other does.  Here is an
example that has been known for several thousand years:
\begin{quote}
Two triangles have the same side lengths if and only if two
side lengths and the angle between those sides are the same.
\end{quote}

The phrase ``if and only if'' comes up so often that it is often
abbreviated ``iff.''

\subsection{Method \#1:  Prove Each Statement Implies the Other}

The statement ``$P \QIFF Q$'' is equivalent to the two statements ``$P
\QIMPLIES Q$'' and ``$Q \QIMPLIES P$.''  So you can prove an ``iff'' by
proving \textit{two} implications:
%
\begin{enumerate}
\item Write, ``We prove $P$ implies $Q$ and vice-versa.''
\item Write, ``First, we show $P$ implies $Q$.'' Do this by one
of the methods in Section~\ref{sec:prove_implies}.
\item Write, ``Now, we show $Q$ implies $P$.''  Again, do this by
one of the methods in Section~\ref{sec:prove_implies}.
\end{enumerate}

\subsection{Method \#2:  Construct a Chain of Iffs}
In order to prove that $P$ is true iff $Q$ is true:
%
\begin{enumerate}
\item Write, ``We construct a chain of if-and-only-if implications.''
\item Prove $P$ is equivalent to a second statement which is
equivalent to a third statement and so forth until you reach $Q$.
\end{enumerate}
%
This method sometimes requires more ingenuity than the first, but the
result can be a short, elegant proof.

\subsection*{Example}
The \textit{standard deviation} of a sequence of values $x_1, x_2,
\dots, x_n$ is defined to be:
%
\begin{equation}\label{sd}
\sqrt{\frac{(x_1 - \mu)^2 + (x_2 - \mu)^2 + \cdots + (x_n - \mu)^2}{n}}
\end{equation}
%
where $\mu$ is the average or \emph{mean} of the values:
%
\[
\mu \eqdef \frac{x_1 + x_2 + \cdots + x_n}{n}
\]

\begin{theorem}
The \idx{standard deviation} of a sequence of values $x_1, \dots, x_n$ is
zero iff all the values are equal to the mean.
\end{theorem}

For example, the standard deviation of test scores is zero if and only
if everyone scored exactly the class average.

\begin{proof}
We construct a chain of ``iff'' implications, starting with the
statement that the standard deviation~\eqref{sd} is zero:
%
\begin{equation}\label{sqrtis0}
\sqrt{\frac{(x_1 - \mu)^2 + (x_2 - \mu)^2 + \cdots + (x_n - \mu)^2}{n}} = 0.
\end{equation}
%
Now since zero is the only number whose square root is zero,
equation~\eqref{sqrtis0} holds iff
\begin{equation}\label{is0}
(x_1 - \mu)^2 + (x_2 - \mu)^2 + \cdots + (x_n - \mu)^2 = 0.
\end{equation}
Squares of real numbers are always nonnegative, so every term on the
left-hand side of equation~\eqref{is0} is nonnegative.  This means
that~\eqref{is0} holds iff
\begin{equation}\label{every}
\text{Every term on the left-hand side of~\eqref{is0} is zero.}
\end{equation}
But a term $(x_i - \mu)^2$ is zero iff $x_i=\mu$, so~\eqref{every} is true
iff
\[
\text{Every $x_i$ equals the mean.}
\]

\end{proof}

\iffalse

\begin{notesproblem}
Reformulate the proof of the Distributive Law for Sets as a chain of
if-and-only-if implications.
\end{notesproblem}
\fi

%\section{More Proof Techniques}

\section{Proof by Cases}
Breaking a complicated proof into cases and proving each case separately
is a common, useful proof strategy.  Here's an amusing example.

Let's agree that given any two people, either they have met or not.  If
every pair of people in a group has met, we'll call the group a
\term*{club}.  If every pair of people in a group has not met, we'll call
it a group of \term*{strangers}.

\begin{theorem*}
Every collection of 6 people includes a club of 3 people or a group of 3
strangers.
\end{theorem*}

\begin{proof}
The proof is by case analysis\footnote{Describing your approach at the
outset helps orient the reader.}.  Let $x$ denote one of the six
people.  There are two cases:

\begin{enumerate}
\item\label{3met} Among 5 other people besides $x$, at least 3 have met
  $x$.

\item \label{3notmet} Among the 5 other people, at least 3 have not met
  $x$.
\end{enumerate}

Now, we have to be sure that at least one of these two cases must
hold,\footnote{Part of a case analysis argument is showing that you've
  covered all the cases.  This is often obvious, because the two cases are
  of the form ``$P$'' and ``not $P$.''  However, the situation above is
  not stated quite so simply.} but that's easy: we've split the 5 people
into two groups, those who have shaken hands with $x$ and those who have
not, so one of the groups must have at least half the people.

\textbf{Case 1:}  Suppose that at least 3 people did meet $x$.

This case splits into two subcases:
\begin{quote}

\textbf{Case 1.1:} No pair among those people met each other.  Then these
people are a group of at least 3 strangers.  The theorem holds in this
subcase.

\textbf{Case 1.2:} Some pair among those people have met each other.
Then that pair, together with $x$, form a club of 3 people.  So the
theorem holds in this subcase.

\end{quote}
This implies that the theorem holds in Case 1.

\textbf{Case 2:} Suppose that at least 3 people did not meet $x$.

This case also splits into two subcases:
\begin{quote}

\textbf{Case 2.1}: Every pair among those people met each other.  Then these
people are a club of at least 3 people.   So the theorem holds in this subcase.

\textbf{Case 2.2:} Some pair among those people have not met each other.
Then that pair, together with $x$, form a group of at least 3 strangers.
So the theorem holds in this subcase.

\end{quote}
This implies that the theorem also holds in Case 2, and therefore holds in
all cases.
\end{proof}

\begin{problems}
\practiceproblems
\pinput{TP_maxminsum_by_cases}

\classproblems
\pinput{CP_irrational_raised_to_an_irrational}
\pinput{CP_absvalue_sum_by_cases}

\homeworkproblems
\pinput{PS_cases_sum_of_squares}

\examproblems
\pinput{MQ_irrational_raised_to_sqrt3}
%\pinput{FP_inequality_by_cases}  show after S18 final
\end{problems}

\section{Proof by Contradiction}\label{contradiction_sec}

In a \term{proof by contradiction}, or \emph{indirect proof},%
\index{indirect proof|see{proof by contradiction}} 
you show that if a proposition were false, then some false fact would be true.
Since a false fact by definition can't be true, the proposition must
be true.

\begin{editingnotes}
So proof by contradiction would be described by the inference rule
\begin{rul*}
\Rule{\neg P \implies \false}{P}
\end{rul*}

\end{editingnotes}

Proof by contradiction is \emph{always} a viable approach.  However,
as the name suggests, indirect proofs can be a little convoluted, so
direct proofs are generally preferable when they are available.

\textbf{Method}: In order to prove a proposition $P$ by contradiction:

\begin{enumerate}

\item Write, ``We use proof by contradiction.''

\item Write, ``Suppose $P$ is false.''

\item Deduce something known to be false (a logical contradiction).

\item Write, ``This is a contradiction.  Therefore, $P$ must be
true.''

\end{enumerate}

\subsection*{Example}
We'll prove by contradiction that $\sqrt{2}$ is irrational. 
Remember that a number is \emph{rational} if it is equal to a ratio
of integers---for example, $3.5 = 7/2$ and $0.1111\dots = 1/9$ are
rational numbers.

\begin{theorem}\label{thm:sqrt2irr_by_contra}
$\sqrt{2}$ is irrational.
\end{theorem}

\begin{proof}
We use proof by contradiction.  Suppose the claim is false, and
$\sqrt{2}$ is rational.  Then we can write $\sqrt{2}$ as a fraction
$n/d$ in \textit{lowest terms}.

Squaring both sides gives $2 = n^2 / d^2$ and so $2 d^2 = n^2$.  This
implies that $n$ is a multiple of $2$ (see
Problems~\ref{TP_divides_n_square_then_n}
and~\ref{TP_divides_n_square_not_n}).  Therefore $n^2$ must be a
multiple of 4.  But since $2d^2 = n^2$, we know $2 d^2$ is a multiple
of 4 and so $d^2$ is a multiple of 2.  This implies that $d$ is a
multiple of $2$.

So, the numerator and denominator have 2 as a common factor, which
contradicts the fact that $n/d$ is in lowest terms. Thus, $\sqrt{2}$ must be
irrational.
\end{proof}

\begin{editingnotes}

\subsection{Potential Pitfall}

Often students use an indirect proof when a direct proof would be
simpler.  Such proofs aren't wrong; they just aren't excellent.  Let's
look at an example.  A function $f$ is \textit{strictly increasing} if
$f(x) > f(y)$ for all real $x$ and $y$ such that $x > y$.

\begin{theorem}
If $f$ and $g$ are strictly increasing functions, then $f + g$ is a
strictly increasing function.
\end{theorem}

Let's first look at a simple, direct proof.

\begin{proof}
Let $x$ and $y$ be arbitrary real numbers such that $x > y$.  Then:
\begin{align*}
f(x) & > f(y) \qquad \text{(since $f$ is strictly increasing)} \\
g(x) & > g(y) \qquad \text{(since $g$ is strictly increasing)} \\
\intertext{Adding these inequalities gives:}
f(x) + g(x) & > f(y) + g(y)
\end{align*}
Thus, $f + g$ is strictly increasing as well.
\end{proof}

Now, we \textit{could} prove the same theorem by contradiction, but
this makes the argument needlessly convoluted.

\begin{proof}
We use proof by contradiction.  Suppose that $f + g$ is not strictly
increasing.  Then there must exist real numbers $x$ and $y$ such that
$x > y$, but
%
\[
f(x) + g(x) \leq f(y) + g(y)
\]
%
This inequality can only hold if either $f(x) \leq f(y)$ or $g(x) \leq
g(y)$.  Either way, we have a contradiction because both $f$ and $g$
were defined to be strictly increasing.  Therefore, $f + g$ must
actually be strictly increasing.
\end{proof}

\end{editingnotes}

\begin{problems}
\practiceproblems
\pinput{TP_power_of_odd}
\pinput{TP_squareroot_size_factor}
\pinput{TP_divides_n_square_then_n}
\pinput{TP_divides_n_square_not_n}

\classproblems
\pinput{CP_generalize_root_2_proof}
\pinput{MQ_log4_of_6_irrational}
\pinput{CP_sqrt2plussqrt3}
\pinput{CP_roots_of_polynomials}

\examproblems
\pinput{MQ_log9_of_12_irrational}
\pinput{MQ_log12_of_18_irrational}
\pinput{FP_equation_prime_factor}

\homeworkproblems
\pinput{CP_log2_of_3_irrational}
\pinput{CP_AMM_root_2_proof}
\pinput{PS_prime_polynomial_41}
\end{problems}

\section{\textit{Good} Proofs in Practice}

One purpose of a \idx{proof} is to establish the truth of an assertion with
absolute certainty, and mechanically checkable proofs of enormous length or
complexity can accomplish this.  But humanly intelligible proofs are the
only ones that help someone understand the subject.  Mathematicians
generally agree that important mathematical results can't be fully
understood until their proofs are understood.  That is why proofs are an
important part of the curriculum.

To be understandable and helpful, more is required of a proof than just
logical correctness: a good proof must also be clear.  Correctness and
clarity usually go together; a well-written proof is more likely to be a
correct proof, since mistakes are harder to hide.

In practice, the notion of proof is a moving target.  Proofs in a
professional research journal are generally unintelligible to all but a
few experts who know all the terminology and prior results used in the
proof.  Conversely, proofs in the first weeks of a beginning course like
6.042 would be regarded as tediously long-winded by a professional
mathematician.  In fact, what we accept as a good proof later in the term
will be different from what we consider good proofs in the first couple of
weeks of 6.042.  But even so, we can offer some general tips on writing
good proofs:

\begin{description}

\item[State your game plan.]  A good proof begins by explaining the
  general line of reasoning, for example, ``We use case analysis'' or ``We
  argue by contradiction.''

\item[Keep a linear flow.]  Sometimes proofs are written like mathematical
  mosaics, with juicy tidbits of independent reasoning sprinkled
  throughout.  This is not good.  The steps of an argument should follow
  one another in an intelligible order.

\item[A proof is an essay, not a calculation.]  Many students initially
  write proofs the way they compute integrals.  The result is a long
  sequence of expressions without explanation, making it very hard to
  follow.  This is bad.  A good proof usually looks like an essay with
  some equations thrown in.  Use complete sentences.

\item[Avoid excessive symbolism.]  Your reader is probably good at
understanding words, but much less skilled at reading arcane
mathematical symbols.  Use words where you reasonably can.

\item[Revise and simplify.]  Your readers will be grateful.

\item[Introduce notation thoughtfully.]  Sometimes an argument can be
greatly simplified by introducing a variable, devising a special
notation, or defining a new term.  But do this sparingly, since you're
requiring the reader to remember all that new stuff.  And remember to
actually \textit{define} the meanings of new variables, terms, or
notations; don't just start using them!

\item[Structure long proofs.]  Long programs are usually broken into a
  hierarchy of smaller procedures.  Long proofs are much the same.
  When your proof needed facts that are easily stated, but not readily
  proved, those fact are best pulled out as preliminary lemmas.
  Also, if you are repeating essentially the same argument over and
  over, try to capture that argument in a general lemma, which you can
  cite repeatedly instead.

\item[Be wary of the ``obvious.'']  When familiar or truly obvious facts
  are needed in a proof, it's OK to label them as such and to not prove
  them.  But remember that what's obvious to you may not be---and
  typically is not---obvious to your reader.

  Most especially, don't use phrases like ``clearly'' or ``obviously'' in
  an attempt to bully the reader into accepting something you're having
  trouble proving.  Also, go on the alert whenever you see one of these
  phrases in someone else's proof.

\item[Finish.]  At some point in a proof, you'll have established all the
essential facts you need.  Resist the temptation to quit and leave the
reader to draw the ``obvious'' conclusion.  Instead, tie everything
together yourself and explain why the original claim follows.

\end{description}

Creating a good proof is a lot like creating a beautiful work of art.  In
fact, mathematicians often refer to really good proofs as being
``elegant'' or ``beautiful.''  It takes a practice and experience to write
proofs that merit such praises, but to get you started in
the right direction, we will provide templates for the most useful proof
techniques.

Throughout the text there are also examples of \emph{bogus
  proofs}---arguments that look like proofs but aren't.  Sometimes a
bogus proof can reach false conclusions because of missteps or
mistaken assumptions.  More subtle bogus proofs reach correct
conclusions, but do so in improper ways such as circular reasoning,
leaping to unjustified conclusions, or saying that the hard part of
the proof is ``left to the reader.''  Learning to spot the flaws in
improper proofs will hone your skills at seeing how each proof step
follows logically from prior steps.  It will also enable you to spot
flaws in your own proofs.

The analogy between good proofs and good programs extends beyond
structure.  The same rigorous thinking needed for proofs is essential
in the design of critical computer systems.  When algorithms and
protocols only ``mostly work'' due to reliance on hand-waving
arguments, the results can range from problematic to catastrophic.  An
early example was the
\href{http://sunnyday.mit.edu/papers/therac.pdf}{Therac 25}, a machine
that provided radiation therapy to cancer victims, but occasionally
killed them with massive overdoses due to a software race condition.
A further example of a dozen years ago (August 2004) involved a single
faulty command to a computer system used by United and American
Airlines that grounded the entire fleet of both companies---and all
their passengers!

It is a certainty that we'll all one day be at the mercy of critical
computer systems designed by you and your classmates.  So we really
hope that you'll develop the ability to formulate rock-solid logical
arguments that a system actually does what you think it should do!

\begin{editingnotes}
\subsection{Wrong proofs through the ages\dots}
\TBA{Update needed. From Karger S01, unedited. }

If you make mistakes, you are in good company. 
Even great mathematicians can goof proofs.
\begin{itemize}
\item Andrew Wiles recently announced a proof of Fermat's Last
  Theorem.  It was several hundred pages long.  It took mathematicians
  months of hard work to discover it had a fatal flaw (so Wiles
  produced another proof of several hundred pages; this one seems to
  have convinced people for now).
\item Kempe's invalid ``proof'' of the Four Color Theorem stood for 10
years (1879--1890)
\item Gauss's 1799 Ph.D. thesis is usually referred to as being the
first rigorous proof of the Fundamental Theorem of Algebra (every
polynomial has a zero over the complex numbers).  But it contains
quotes like
\begin{quote}
  ``If a branch of an algebraic curve enters a bounded region, it
   must necessarily leave it again. ... Nobody, to my knowledge,
   has ever doubted [this fact].  But if anybody desires it, then
   on another occasion I intend to give a demonstration which will
   leave no doubt.''
\end{quote}
Fields Medalist Steve Smale writes about this, calling it an ``immense
gap'' in the proof that was not filled in until 1920, more than a hundred
years later.
\item In 1900 Poincare carelessly claimed a certain very simple topological 
characterization of the 3-dimensional sphere.  Later realizing it was 
not so obvious, he demoted the claim to the status of a "conjecture" 
in 1904.  The Poincare Conjecture is now one of the biggest open questions
in mathematics (two Fields Medals have been given out for partial progress
on it).
\item In the 1940's Paul Erdos conjectured a certain combinatorial fact about 
arithmetic progressions (every set of natural numbers of positive density 
contains arbitrarily long arithmetic progressions), and offered \$1000 for a
proof or disproof.  Endre Szemeredi proved the conjecture in 1972, but
the proof was so long and badly written that Erdos was not sure whether
to believe it.  Finally, Andras Hajnal stepped in and wrote a much clearer
version of the same proof, which was eventually published under Szemeredi's
name.  At some point during the write-up, Hajnal informed Erdos that
he was now confident enough of the proof that he was willing to buy it 
from Szemeredi for \$500.
\item  There's also the story of Newton waiting 20 years to publish
the Principia because he didn't see how to prove that one could assume all
the mass of a sphere to be concentrated at its center when calculating
gravitational attraction.  The proof ultimately required the invention 
of calculus.

\end{itemize}
\end{editingnotes}

\section{References}

\cite{Cupillari12}, \cite{AignerG99}, \cite{Velleman94}, \cite{Fagin95}, \cite{Gelfond34}

\endinput
