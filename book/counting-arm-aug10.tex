\chapter{Counting}\label{counting_chap}

%initial part of F07 1n10 almost verbatim

\hyperdef{start}{counting}{\section{Why Count?}}\label{why_count_sec}

Are there two different subsets of the ninety 25-digit numbers shown below
that have the same sum---for example, maybe the sum of the numbers in the
first column is equal to the sum of the numbers in the second column?

{\scriptsize
\[\begin{array}{rr}
0020480135385502964448038 &
3171004832173501394113017 \\
5763257331083479647409398 &
8247331000042995311646021 \\
0489445991866915676240992 &
3208234421597368647019265 \\
5800949123548989122628663 &
8496243997123475922766310 \\
1082662032430379651370981 &
3437254656355157864869113 \\
6042900801199280218026001 &
8518399140676002660747477 \\
1178480894769706178994993 &
3574883393058653923711365 \\
6116171789137737896701405 &
8543691283470191452333763 \\
1253127351683239693851327 &
3644909946040480189969149 \\
6144868973001582369723512 &
8675309258374137092461352 \\
1301505129234077811069011 &
3790044132737084094417246 \\
6247314593851169234746152 &
8694321112363996867296665 \\
1311567111143866433882194 &
3870332127437971355322815 \\
6814428944266874963488274 &
8772321203608477245851154 \\
1470029452721203587686214 &
4080505804577801451363100 \\
6870852945543886849147881 &
8791422161722582546341091 \\
1578271047286257499433886 &
4167283461025702348124920 \\
6914955508120950093732397 &
9062628024592126283973285 \\
1638243921852176243192354 &
4235996831123777788211249 \\
6949632451365987152423541 &
9137845566925526349897794 \\
1763580219131985963102365 &
4670939445749439042111220 \\
7128211143613619828415650 &
9153762966803189291934419 \\
1826227795601842231029694 &
4815379351865384279613427 \\
7173920083651862307925394 &
9270880194077636406984249 \\
1843971862675102037201420 &
4837052948212922604442190 \\
7215654874211755676220587 &
9324301480722103490379204 \\
2396951193722134526177237 &
5106389423855018550671530 \\
7256932847164391040233050 &
9436090832146695147140581 \\
2781394568268599801096354 &
5142368192004769218069910 \\
7332822657075235431620317 &
9475308159734538249013238 \\
2796605196713610405408019 &
5181234096130144084041856 \\
7426441829541573444964139 &
9492376623917486974923202 \\
2931016394761975263190347 &
5198267398125617994391348 \\
7632198126531809327186321 &
9511972558779880288252979 \\
2933458058294405155197296 &
5317592940316231219758372 \\
7712154432211912882310511 &
9602413424619187112552264 \\
3075514410490975920315348 &
5384358126771794128356947
\end{array}\]

\[\begin{array}{rr}
7858918664240262356610010 &
9631217114906129219461111 \\
8149436716871371161932035 &
3157693105325111284321993 \\
3111474985252793452860017 &
5439211712248901995423441 \\
7898156786763212963178679 &
9908189853102753335981319 \\
3145621587936120118438701 &
5610379826092838192760458 \\
8147591017037573337848616 &
9913237476341764299813987 \\
3148901255628881103198549 &
5632317555465228677676044 \\
5692168374637019617423712 &
8176063831682536571306791
\end{array}\]
}
 
Finding two subsets with the same sum may seem like an silly puzzle, but
solving problems like this turns out to be useful, for example in finding
good ways to fit packages into shipping containers and in decoding secret
messages.

The answer to the question turns out to be ``yes.''  Of course this would
be easy to confirm just by showing two subsets with the same sum, but that
turns out to be kind of hard to do.  So before we put a lot of effort into
finding such a pair, it would be nice to be sure there were some.
Fortunately, it \emph{is} very easy to see why there is such a pair---or at
least it will be easy once we have developed a few simple rules for
counting things.


\iffalse
Can you find two such subsets?  This is a challenging computational
problem.  But we'll prove that such subsets must exist!  This is the sort
of weird conclusion one can reach by tricky use of counting, the topic of
this chapter.
\fi

\floatingtextbox{
\textboxtitle{The Contest to Find Two Sets with the Same Sum}

One term, Eric \idx{Lehman}, a 6.042 instructor who contributed to many
parts of this book, offered a \$100 prize for being the first 6.042
student to actually \emph{find} two different subsets of the above ninety
25-digit numbers that have the same sum.  Eric didn't expect to have to
pay off this bet, but he underestimated the ingenuity and initiative of
6.042 students.

One computer science major wrote a program that cleverly searched only
among a reasonably small set of ``plausible'' sets, sorted them by
their sums, and actually found a couple with the same sum.  He won the
prize.  A few days later, a math major figured out how to reformulate
the sum problem as a ``\idx{lattice basis reduction}'' problem; then
he found a software package implementing an efficient basis reduction
procedure, and using it, he very quickly found lots of pairs of
subsets with the same sum.  He didn't win the prize, but he got a
standing ovation from the class---staff included.}

Counting seems easy enough: 1, 2, 3, 4, etc.  This direct approach works
well for counting simple things---like your toes---and may be the only
approach for extremely complicated things with no identifiable structure.
However, subtler methods can help you count many things in the vast middle
ground, such as:

\begin{itemize}

\item The number of different ways to select a dozen doughnuts when
there are five varieties available.

\item The number of 16-bit numbers with exactly 4 ones.

\end{itemize}

Counting is useful in computer science for several reasons:

\begin{itemize}

\item Determining the time and storage required to solve a
  computational problem---a central objective in computer
  science---often comes down to solving a counting problem.

\item Counting is the basis of probability theory, which plays a central
  role in all sciences, including computer science.

\item Two remarkable proof techniques, the ``\idx{pigeonhole principle}'' and
  ``\idx{combinatorial proof},'' rely on counting.  These lead to a variety of
  interesting and useful insights.

\end{itemize}

We're going to present a lot of \hyperdef{counting}{rules}{rules for
  counting}.  These rules are actually theorems, but most of them are
pretty obvious anyway, so we're not going to focus on proving them.
Our objective is to teach you simple counting as a practical skill,
like integration.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Counting One Thing by Counting Another}\label{bijection_counting_sec}


How do you count the number of people in a crowded room?  You could count
heads, since for each person there is exactly one head.  Alternatively,
you could count ears and divide by two.  Of course, you might have to
adjust the calculation if someone lost an ear in a pirate raid or someone
was born with three ears.  The point here is that you can often
\emph{count one thing by counting another}, though some fudge factors
may be required.  \begin{staffnotes}
This is a central theme of counting, from the
easiest problems to the hardest.
\end{staffnotes}

In more formal terms, every counting problem comes down to determining
the size of some set.  The \term{size} or \term{cardinality} of a
finite set $S$ is the number of elements in it and is denoted
\index{$\card{S}$ (size of set $S$)} $\card{S}$.  In these terms,
we're claiming that we can often find the size of one set by finding
the size of a related set.  We've already seen a general statement of
this idea in the idx{Mapping Rules} Theorem~\ref{maprul_thm}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Bijection Rule}

We've already implicitly used the \idx{bijection mapping rule} of
Theorem~\ref{maprul_thm}.\ref{bij_same_fincard} a lot.  For example,
when we studied stable marriage and bipartite matching, we assumed the
obvious fact that if we can pair up all the girls at a dance with all
the boys, then there must be an equal number of each.  If we needed to
be explicit about using the Bijection Rule, we could say that $A$ was
the set of boys, $B$ was the set of girls, and the bijection between
them was how they were paired.

The Bijection Rule acts as a magnifier of counting ability; if you
figure out the size of one set, then you can immediately determine the
sizes of many other sets via bijections.  For example, let's return to
two sets mentioned earlier:
%
\begin{align*}
A & = \text{all ways to select a dozen doughnuts when five varieties are available} \\
B & = \text{all 16-bit sequences with exactly 4 ones}
\end{align*}

Let's consider a particular element of set $A$:
%
\[
\underbrace{0\ 0}_{\text{chocolate}} \quad
\underbrace{}_{\text{lemon-filled}} \quad
\underbrace{0\ 0\ 0\ 0\ 0\ 0}_{\text{sugar}} \quad
\underbrace{0\ 0}_{\text{glazed}} \quad
\underbrace{0\ 0}_{\text{plain}}
\]
%
We've depicted each doughnut with a $0$ and left a gap between the
different varieties.  Thus, the selection above contains two chocolate
doughnuts, no lemon-filled, six sugar, two glazed, and two plain.  Now
let's put a 1 into each of the four gaps:
%
\[
\underbrace{0\ 0}_{\text{chocolate}} \quad 1 \quad
\underbrace{}_{\text{lemon-filled}} \quad 1 \quad
\underbrace{0\ 0\ 0\ 0\ 0\ 0}_{\text{sugar}} \quad 1 \quad
\underbrace{0\ 0}_{\text{glazed}} \quad 1 \quad
\underbrace{0\ 0}_{\text{plain}}
\]
%
We've just formed a 16-bit number with exactly 4 ones--- an element of
$B$!

This example suggests a bijection from set $A$ to set $B$: map a dozen
doughnuts consisting of:
%
\[
\text{$c$ chocolate, $l$ lemon-filled, $s$ sugar, $g$ glazed, and $p$ plain}
\]
%
to the sequence:
%
\[
\underbrace{\ 0 \ldots 0\ }_{\text{$c$}} \quad 1 \quad
\underbrace{\ 0 \ldots 0\ }_{\text{$l$}} \quad 1 \quad
\underbrace{\ 0 \ldots 0\ }_{\text{$s$}} \quad 1 \quad
\underbrace{\ 0 \ldots 0\ }_{\text{$g$}} \quad 1 \quad
\underbrace{\ 0 \ldots 0\ }_{\text{$p$}}
\]

The resulting sequence always has 16 bits and exactly 4
ones, and thus is an element of $B$.  Moreover, the mapping is a
bijection; every such bit sequence is mapped to by exactly one order
of a dozen doughnuts.  Therefore, $\card{A} = \card{B}$ by the
Bijection Rule!

This demonstrates the magnifying power of the bijection rule.  We
managed to prove that two very different sets are actually the same
size--- even though we don't know exactly how big either one is.  But
as soon as we figure out the size of one set, we'll immediately know
the size of the other.

This particular bijection might seem frighteningly ingenious if you've
not seen it before.  But you'll use essentially this same argument
over and over, and soon you'll consider it routine.

\subsection{Counting Sequences}

The Bijection Rule lets us count one thing by counting another.  This
suggests a general strategy: get really good at counting just a
\textit{few} things and then use bijections to count
\textit{everything else}.  This is the strategy we'll follow.  In
particular, we'll get really good at counting \emph{sequences}.  When
we want to determine the size of some other set $T$, we'll find a
bijection from $T$ to a set of sequences $S$.  Then we'll use our
super-ninja sequence-counting skills to determine $\card{S}$, which
immediately gives us $\card{T}$.  We'll need to hone this idea
somewhat as we go along, but that's pretty much the plan!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Sum Rule}

Linus allocates his big sister Lucy a quota of 20 crabby days, 40
irritable days, and 60 generally surly days.  On how many days can
Lucy be out-of-sorts one way or another?  Let set $C$ be her crabby
days, $I$ be her irritable days, and $S$ be the generally surly.  In
these terms, the answer to the question is $\card{C \cup I \cup S}$.
Now assuming that she is permitted at most one bad quality each day,
the size of this union of sets is given by the \term{Sum Rule}:

\begin{mathrule}[Sum Rule]
If $A_1, A_2, \ldots, A_n$ are \emph{disjoint} sets, then:
%
\[
\card{A_1 \cup A_2 \cup \ldots \cup A_n}
    = \card{A_1} + \card{A_2} + \ldots + \card{A_n}
\]
\end{mathrule}

Thus, according to Linus' budget, Lucy can be out-of-sorts for:
%
\begin{align*}
\card{C \cup I \cup S}
    & = \card{C} + \card{I} + \card{S} \\
    & = 20 + 40 + 60 \\
    & = 120 \text{ days}
\end{align*}

Notice that the Sum Rule holds only for a union of {\em disjoint}
sets.  Finding the size of a union of intersecting sets is a more
complicated problem that we'll take up later.

\subsection{The Product Rule}

The \term{Product Rule} gives the size of a product of sets.  Recall that
if $P_1, P_2, \ldots, P_n$ are sets, then
%
\[
P_1 \times P_2 \times \ldots \times P_n
\]
%
is the set of all sequences whose first term is drawn from $P_1$,
second term is drawn from $P_2$ and so forth.

\begin{mathrule}[Product Rule]
If $P_1, P_2, \ldots P_n$ are sets, then:
%
\begin{align*}
\card{P_1 \times P_2 \times \ldots \times P_n}
    & = \card{P_1} \cdot \card{P_2} \cdots \card{P_n}
\end{align*}
\end{mathrule}

Unlike the sum rule, the product rule does not require the sets $P_1,
\ldots, P_n$ to be disjoint.  For example, suppose a {\em daily diet}
consists of a breakfast selected from set $B$, a lunch from set $L$,
and a dinner from set $D$:
%
\begin{align*}
B & = \set{\text{pancakes},
      	   \text{bacon and eggs},
           \text{bagel},
           \text{Doritos}} \\
L & = \set{\text{burger and fries},
           \text{garden salad},
           \text{Doritos}} \\
D & = \set{\text{macaroni},
           \text{pizza},
           \text{frozen burrito},
           \text{pasta},
           \text{Doritos}}
\end{align*}
%
Then $B \times L \times D$ is the set of all possible daily diets.
Here are some sample elements:
%
\begin{gather*}
(\text{pancakes}, \text{burger and fries}, \text{pizza}) \\
(\text{bacon and eggs}, \text{garden salad}, \text{pasta}) \\
(\text{Doritos}, \text{Doritos}, \text{frozen burrito})
\end{gather*}
%
The Product Rule tells us how many different daily diets are possible:
%
\begin{align*}
\card{B \times L \times D}
    & = \card{B} \cdot \card{L} \cdot \card{D} \\
    & = 4 \cdot 3 \cdot 5 \\
    & = 60
\end{align*}

\subsection{Putting Rules Together}

Few counting problems can be solved with a single rule.  More often, a
solution is a flurry of sums, products, bijections, and other methods.
Let's look at some examples that bring more than one rule into play.

\subsubsection*{Counting Passwords}

The sum and product rules together are useful for solving problems
involving passwords, telephone numbers, and license plates.  For
example, on a certain computer system, a valid password is a sequence
of between six and eight symbols.  The first symbol must be a letter
(which can be lowercase or uppercase), and the remaining symbols must
be either letters or digits.  How many different passwords are
possible?

Let's define two sets, corresponding to valid symbols in the first and
subsequent positions in the password.
%
\begin{align*}
F & = \set{ a, b, \ldots, z, A, B, \ldots, Z } \\
S & = \set{ a, b, \ldots, z, A, B, \ldots, Z, 0, 1, \ldots, 9 }
\end{align*}
%
In these terms, the set of all possible passwords is:
%
\[
(F \times S^5) \cup (F \times S^6) \cup (F \times S^7)
\]
%
Thus, the length-six passwords are in set $F \times S^5$, the
length-seven passwords are in $F \times S^6$, and the length-eight
passwords are in $F \times S^7$.  Since these sets are disjoint, we
can apply the Sum Rule and count the total number of possible
passwords as follows:
%
\begin{align*}
\card{(F \times S^5) \cup (F \times S^6) \cup (F \times S^7)}
    & = \card{F \times S^5} + \card{F \times S^6} + \card{F \times S^7}
        & \text{Sum Rule} \\
    & = \card{F} \cdot \card{S}^5 +
          \card{F} \cdot \card{S}^6 +
          \card{F} \cdot \card{S}^7
        & \text{Product Rule} \\
    & = 52 \cdot 62^5 + 52 \cdot 62^6 + 52 \cdot 62^7 \\
    & \approx 1.8 \cdot 10^{14} \text{ different passwords}
\end{align*}

\subsubsection*{Subsets of an $n$-element Set}
%REVISE IN REF CARDINALITY CHAPTER.

How many different subsets of an $n$-element set $X$ are there?  For
example, the set $X = \set{x_1, x_2, x_3}$ has eight different subsets:
%
\[
\begin{array}{cccc}
\emptyset & \set{x_1} & \set{x_2} & \set{x_1, x_2} \\
\set{x_3} & \set{x_1, x_3} & \set{x_2, x_3} & \set{x_1, x_2, x_3}
\end{array}
\]

There is a natural bijection from subsets of $X$ to $n$-bit sequences.
Let $x_1, x_2, \ldots, x_n$ be the elements of $X$.  Then a particular
subset of $X$ maps to the sequence $(b_1, \ldots, b_n)$ where $b_i =
1$ if and only if $x_i$ is in that subset.  For example, if $n = 10$,
then the subset $\set{x_2, x_3, x_5, x_7, x_{10}}$ maps to a 10-bit
sequence as follows:
%
\[
\begin{array}{rrrrrrrrrrrrr}
\text{subset:} &
\{ &    & x_2, & x_3, &    & x_5, &   & x_7, &    &    & x_{10} & \} \\
\text{sequence:} &
(  & 0, &   1, &   1, & 0, &   1, & 0, &   1, & 0, & 0, &        1 & )
\end{array}
\]
%
We just used a bijection to transform the original problem into a
question about sequences---\emph{exactly according to plan!}  Now
if we answer the sequence question, then we've solved our original
problem as well.

But how many different $n$-bit sequences are there?  For example,
there are 8 different 3-bit sequences:
%
\[
\begin{array}{ccccccc}
(0,0,0) & \quad & (0,0,1) & \quad & (0,1,0) & \quad & (0,1,1) \\
(1,0,0) & \quad & (1,0,1) & \quad & (1,1,0) & \quad & (1,1,1)
\end{array}
\]

Well, we can write the set of all $n$-bit sequences as a product of
sets:
%
\[
\underbrace{\set{0,1} \times \set{0,1} \times
        \ldots \times \set{0,1}}_{\text{$n$ terms}} = \set{0,1}^n
\]
%
Then Product Rule gives the answer:
%
\begin{align*}
\card{\set{0,1}^n}
    & = \card{\set{0,1}}^n \\
    & = 2^n
\end{align*}

This means that the number of subsets of an $n$-element set $X$ is
also $2^n$.  We'll put this answer to use shortly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problems}
\practiceproblems
\pinput{MQ_unselected_book_counting}

\classproblems
\pinput{CP_counting_license_plates}
\pinput{CP_nonadjacent_books}
\pinput{CP_inequality-string-bijections}
\pinput{CP_numbered_trees}

\homeworkproblems
\pinput{PS_alphabet}
\pinput{PS_5_card_poker}
\end{problems}


\hyperdef{pigeon}{hole}{\section{The Pigeonhole Principle}\label{pigeon_hole_sec}}

Here is an old puzzle:

\begin{quotation}
\noindent A drawer in a dark room contains red socks, green socks, and
blue socks.  How many socks must you withdraw to be sure that you have
a matching pair?
\end{quotation}

For example, picking out three socks is not enough; you might end up
with one red, one green, and one blue.  The solution relies on the
\term{Pigeonhole Principle}, which is a friendly name for the
contrapositive of the Mapping Rules Theorem injective
case~\ref{maprul_thm}.\ref{inj_le_fincard}.  Let's write it
down:

\begin{quotation}
If $\card{X} > \card{Y}$, then no total function\footnote{This Mapping
  Rule actually applies even if $f$ is a total
  \emph{relation}.} $f : X \to Y$ is injective.
\end{quotation}

And now rewrite it again to eliminate the word ``injective.''

\begin{mathrule}[Pigeonhole Principle]
  If $\card{X} > \card{Y}$, then for every total function $f : X \to Y$,
  there exist two different elements of $X$ that are mapped to the same
  element of $Y$.
\end{mathrule}

What this abstract mathematical statement has to do with selecting
footwear under poor lighting conditions is maybe not obvious.  However,
let $A$ be the set of socks you pick out, let $B$ be the set of colors
available, and let $f$ map each sock to its color.  The Pigeonhole
Principle says that if $\card{A} > \card{B} = 3$, then at least two
elements of $A$ (that is, at least two socks) must be mapped to the same
element of $B$ (that is, the same color).  For example, one possible
mapping of four socks to three colors is shown below.

\begin{center}
\begin{picture}(145,100)(0,-10)
%\put(0,-10){\dashbox(145,100){}}
\put(24,80){\makebox(0,0){$A$}}
\put(80,80){\makebox(0,0){$f$}}
\put(125,80){\makebox(0,0){$B$}}
\put(48,60){\makebox(0,6)[tr]{1st sock}}
\put(48,40){\makebox(0,6)[tr]{2nd sock}}
\put(48,20){\makebox(0,6)[tr]{3rd sock}}
\put(48,0){\makebox(0,6)[tr]{4th sock}}
\put(110,60){\makebox(0,6)[tl]{red}}
\put(110,40){\makebox(0,6)[tl]{green}}
\put(110,20){\makebox(0,6)[tl]{blue}}
\put(50,60){\vector(1,0){58}}
\put(50,40){\vector(1,0){58}}
\put(50,20){\vector(1,0){58}}
\put(50,0){\vector(3,2){58}}
\end{picture}
\end{center}

Therefore, four socks are enough to ensure a matched pair.

Not surprisingly, the pigeonhole principle is often described in terms
of pigeons:
\begin{quote}
\emph{If there are more pigeons than holes they occupy, then at least two
  pigeons must be in the same hole.}
\end{quote}
In this case, the pigeons form set $A$, the pigeonholes are set $B$, and
$f$ describes which hole each pigeon flies into.

Mathematicians have come up with many ingenious applications for the
pigeonhole principle.  If there were a cookbook procedure for
generating such arguments, we'd give it to you.  Unfortunately, there
isn't one.  One helpful tip, though: when you try to solve a problem
with the pigeonhole principle, the key is to clearly identify three
things:

\begin{enumerate}

\item The set $A$ (the pigeons).

\item The set $B$ (the pigeonholes).

\item The function $f$ (the rule for assigning pigeons to pigeonholes).

\end{enumerate}

\subsection{Hairs on Heads}

There are a number of generalizations of the pigeonhole principle.
For example:

\begin{mathrule}[\idx{Generalized Pigeonhole Principle}]
  If $\card{X} > k \cdot \card{Y}$, then every total function $f : X \to
  Y$ maps at least $k+1$ different elements of $X$ to the same element of
  $Y$.
\end{mathrule}

For example, if you pick two people at random, surely they are extremely
unlikely to have \emph{exactly} the same number of hairs on their heads.
However, in the remarkable city of Boston, Massachusetts there are
actually \emph{three} people who have exactly the same number of hairs!
Of course, there are many bald people in Boston, and they all have zero
hairs.  But we're talking about non-bald people; say a person is non-bald
if they have at least ten thousand hairs on their head.

Boston has about 500,000 non-bald people, and the number of hairs on a
person's head is at most 200,000.  Let $A$ be the set of non-bald people
in Boston, let $B = \set{10,000, 10,001, \dots, 200,000}$, and let $f$ map
a person to the number of hairs on his or her head.  Since $\card{A} > 2
\card{B}$, the Generalized Pigeonhole Principle implies that at least
three people have exactly the same number of hairs.  We don't know who
they are, but we know they exist!

\subsection{Subsets with the Same Sum}

We asserted that two different subsets of the ninety 25-digit numbers
listed on the first page have the same sum.  This actually follows
from the Pigeonhole Principle.  Let $A$ be the collection of all
subsets of the 90 numbers in the list.  Now the sum of any subset of
numbers is at most $90 \cdot 10^{25}$, since there are only 90 numbers
and every 25-digit number is less than $10^{25}$.  So let $B$ be the
set of integers $\set{0, 1, \ldots, 90 \cdot 10^{25}}$, and let $f$
map each subset of numbers (in $A$) to its sum (in $B$).

We proved that an $n$-element set has $2^n$ different subsets.
Therefore:
%
\begin{align*}
\card{A}
    & = 2^{90} \\
    & \geq 1.237 \times 10^{27}
\end{align*}
%
On the other hand:
%
\begin{align*}
\card{B}
    & = 90 \cdot 10^{25} + 1 \\
    & \leq 0.901 \times 10^{27}
\end{align*}
%
Both quantities are enormous, but $\card{A}$ is a bit greater than
$\card{B}$.  This means that $f$ maps at least two elements of $A$ to
the same element of $B$.  In other words, by the Pigeonhole Principle,
two different subsets must have the same sum!

Notice that this proof gives no indication \emph{which} two sets of
numbers have the same sum.  This frustrating variety of argument is
called a \term{nonconstructive proof}.

\floatingtextbox{
\textboxtitle{Sets with Distinct Subset Sums}

How can we construct a set of $n$ positive integers such that all its
subsets have {\em distinct} sums?  One way is to use powers of two:
\[
\set{1, 2, 4, 8, 16}
\]
This approach is so natural that one suspects all other such sets must
involve larger numbers.  (For example, we could safely replace 16 by
17, but not by 15.)  Remarkably, there are examples involving {\em
smaller} numbers.  Here is one:
\[
\set{6, 9, 11, 12, 13}
\]
One of the top mathematicans of the Twentieth Century, Paul Erd\H{o}s,
conjectured in 1931 that there are no such sets involving {\em
  significantly} smaller numbers.  More precisely, he conjectured that the
largest number must be $> c2^n$ for some constant $c>0$.  He offered \$500
to anyone who could prove or disprove his conjecture, but the problem
remains unsolved.}

\begin{problems}
\classproblems
\pinput{CP_pigeon_hole}

\homeworkproblems
\pinput{PS_pigeon_hunting}
\pinput{PS_pigeonhole-power_of_3}
\end{problems}

\section{The Generalized Product Rule}\label{generalized_product_sec}

We realize everyone has been working pretty hard this term, and we're
considering awarding some prizes for \emph{truly exceptional}
coursework.  Here are some possible categories:

\begin{description}

\item[Best Administrative Critique] We asserted that the quiz was
closed-book.  On the cover page, one strong candidate for this award
wrote, ``There is no book.''

\item[Awkward Question Award] ``Okay, the left sock, right sock, and
pants are in an antichain, but how--- even with assistance--- could I
put on all three at once?''

\item[Best Collaboration Statement] Inspired by a student who wrote
``I worked alone'' on Quiz 1.

\end{description}

In how many ways can, say, three different prizes be awarded to $n$
people?  This is easy to answer using our strategy of translating the
problem about awards into a problem about sequences.  Let $P$ be the set
of $n$ people in 6.042.  Then there is a bijection from ways of awarding
the three prizes to the set $P^3 \eqdef P \times P \times P$.  In
particular, the assignment:
%
\begin{center}
``person $x$ wins prize \#1, $y$ wins prize \#2, and $z$ wins prize \#3''
\end{center}
%
maps to the sequence $(x, y, z)$.  By the Product Rule, we have
$\card{P^3}= \card{P}^3 = n^3$, so there are $n^3$ ways to award the
prizes to a class of $n$ people.

But what if the three prizes must be awarded to \emph{different}
students?  As before, we could map the assignment
%
\begin{center}
``person $x$ wins prize \#1, $y$ wins prize \#2, and $z$ wins prize \#3''
\end{center}
%
to the triple $(x, y, z) \in P^3$.  But this function is \emph{no longer
a bijection}.  For example, no valid assignment maps to the triple (Dave,
Dave, Becky) because Dave is not allowed to receive two awards.  However,
there \emph{is} a bijection from prize assignments to the set:
%
\[
S = \set{(x, y, z) \in P^3 \mid \text{$x$, $y$ and $z$ are different people}}
\]
%
This reduces the original problem to a problem of counting sequences.
Unfortunately, the Product Rule is of no help in counting sequences of
this type because the entries depend on one another; in particular,
they must all be different.  However, a slightly sharper tool does the
trick.

\begin{mathrule}[\idx{Generalized Product Rule}]
Let $S$ be a set of length-$k$ sequences.  If there are:
%
\begin{itemize}
\item $n_1$ possible first entries,
\item $n_2$ possible second entries for each first entry,
\item $n_3$ possible third entries for each combination of first and
second entries, etc.
\end{itemize}
%
then:
%
\[
\card{S} = n_1 \cdot n_2 \cdot n_3 \cdots n_k
\]
\end{mathrule}

In the awards example, $S$ consists of sequences $(x, y, z)$.  There
are $n$ ways to choose $x$, the recipient of prize \#1.  For each of
these, there are $n-1$ ways to choose $y$, the recipient of prize \#2,
since everyone except for person $x$ is eligible.  For each
combination of $x$ and $y$, there are $n-2$ ways to choose $z$, the
recipient of prize \#3, because everyone except for $x$ and $y$ is
eligible.  Thus, according to the Generalized Product Rule, there are
%
\[
\card{S} = n \cdot (n-1) \cdot (n-2)
\]
%
ways to award the 3 prizes to different people.

\subsection{Defective Dollars}

A dollar is \emph{defective} if some digit appears more than once in
the 8-digit serial number.  If you check your wallet, you'll be sad to
discover that defective dollars are all-too-common.  In fact, how
common are \emph{nondefective} dollars?  Assuming that the digit
portions of serial numbers all occur equally often, we could answer
this question by computing:
%
\begin{align*}
\text{fraction dollars that are nondefective}
    & = \frac{\text{\# of serial \#'s with all digits different}}
             {\text{total \# of serial \#'s}}
\end{align*}
%
Let's first consider the denominator.  Here there are no restrictions;
there are are 10 possible first digits, 10 possible second digits, 10
third digits, and so on.  Thus, the total number of 8-digit serial
numbers is $10^8$ by the Product Rule.

Next, let's turn to the numerator.  Now we're not permitted to use any
digit twice.  So there are still 10 possible first digits, but only 9
possible second digits, 8 possible third digits, and so forth.  Thus, by
the Generalized Product Rule, there are
%
\begin{align*}
10 \cdot 9 \cdot 8 \cdot 7 \cdot 6 \cdot 5 \cdot 4 \cdot 3
    & = \frac{10!}{2} \\
    & = 1,814,400
\end{align*}
%
serial numbers with all digits different.  Plugging these results into
the equation above, we find:
%
\begin{align*}
\text{fraction dollars that are nondefective}
    & = \frac{1,814,400}{100,000,000} \\
    & = 1.8144\%
\end{align*}

\subsection{A Chess Problem}

In how many different ways can we place a pawn ($p$), a knight ($k$),
and a bishop ($b$) on a chessboard so that no two pieces share a row
or a column?  A valid configuration is shown below on the left,
and an invalid configuration is shown on the right.
%
\[
\begin{array}{ccc}
\begin{array}{|c|c|c|c|c|c|c|c|}
\hline
\ &\ &\ &\ &\ &\ &\ &\ \\ \hline
 & & & &k& & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 &b& & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & &p& & \\ \hline
 & & & & & & & \\ \hline
\end{array}
& \hspace{1in} &
\begin{array}{|c|c|c|c|c|c|c|c|}
\hline
\ &\ &\ &\ &\ &\ &\ &\ \\ \hline
 & & & & & & & \\ \hline
 & & & &p& & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & &b& & &k& & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
\end{array} \\
\\
\text{valid} & & \text{invalid}
\end{array}
\]
%
First, we map this problem about chess pieces to a question about
sequences.  There is a bijection from configurations to sequences
%
\[
(r_p, c_p, r_k, c_k, r_b, c_b)
\]
%
where $r_p$, $r_k$ and $r_b$ are distinct rows and $c_p$, $c_k$ and
$c_b$ are distinct columns.  In particular, $r_p$ is the pawn's row,
$c_p$ is the pawn's column, $r_k$ is the knight's row, etc.  Now we
can count the number of such sequences using the Generalized Product
Rule:
%
\begin{center}
\begin{tabular}{l}
$\bullet$ $r_p$ is one of 8 rows \\
$\bullet$ $c_p$ is one of 8 columns \\
$\bullet$ $r_k$ is one of 7 rows (any one but $r_p$) \\
$\bullet$ $c_k$ is one of 7 columns (any one but $c_p$) \\
$\bullet$ $r_b$ is one of 6 rows (any one but $r_p$ or $r_k$) \\
$\bullet$ $c_b$ is one of 6 columns (any one but $c_p$ or $c_k$)
\end{tabular}
\end{center}
%
\noindent Thus, the total number of configurations is $(8 \cdot 7
\cdot 6)^2$.

\hyperdef{per}{mutations}{\subsection{Permutations}}

A \term{permutation} of a set $S$ is a sequence that contains every
element of $S$ exactly once.  For example, here are all the
permutations of the set $\set{a, b, c}$:
%
\[
\begin{array}{ccc}
(a, b, c) & (a, c, b) & (b, a, c) \\
(b, c, a) & (c, a, b) & (c, b, a)
\end{array}
\]

How many permutations of an $n$-element set are there?  Well, there
are $n$ choices for the first element.  For each of these, there are
$n - 1$ remaining choices for the second element.  For every
combination of the first two elements, there are $n - 2$ ways to
choose the third element, and so forth.  Thus, there are a total of
%
\[
n \cdot (n-1) \cdot (n-2) \cdots 3 \cdot 2 \cdot 1 = n!
\]
%
permutations of an $n$-element set.  In particular, this formula says
that there are $3! = 6$ permuations of the 3-element set $\set{a, b,
c}$, which is the number we found above.

Permutations will come up again in this course approximately 1.6
bazillion times.  In fact, permutations are the reason why factorial
comes up so often and why we taught you Stirling's approximation:
%
\[
n! \sim \sqrt{2 \pi n} \left(\frac{n}{e}\right)^n
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hyperdef{division}{rule}{\section{The Division Rule}}\label{division_rule_sec}

Counting ears and dividing by two is a silly way to count the number of
people in a room, but this approach is representative of a powerful
counting principle.

A \term{$k$-to-1 function} maps exactly $k$ elements of the domain to
every element of the codomain.  For example, the function mapping each
ear to its owner is 2-to-1:
\begin{center}
\unitlength = 2pt
\begin{picture}(70,56)(-15,-3)
% \put(-15,-3){\dashbox(70,56){}} % bounding box
\put(-2,50){\makebox(0,3)[rt]{ear 1}}
\put(-2,40){\makebox(0,3)[rt]{ear 2}}
\put(-2,30){\makebox(0,3)[rt]{ear 3}}
\put(-2,20){\makebox(0,3)[rt]{ear 4}}
\put(-2,10){\makebox(0,3)[rt]{ear 5}}
\put(-2, 0){\makebox(0,3)[rt]{ear 6}}
\put(30,50){\makebox(0,3)[lt]{person A}}
\put(30,30){\makebox(0,3)[lt]{person B}}
\put(30,10){\makebox(0,3)[lt]{person C}}
\put(0,50){\vector(1,0){28}}
\put(0,40){\vector(3,-1){28}}
\put(0,30){\vector(3,2){28}}
\put(0,20){\vector(3,-1){28}}
\put(0,10){\vector(1,0){28}}
\put(0, 0){\vector(1,1){28}}
\end{picture}
\end{center}

Similarly, the function mapping each finger to its owner is 10-to-1, and
the function mapping each finger and toe to its owner is 20-to-1.  The
general rule is:
\begin{mathrule}[\idx{Division Rule}]
If $f : A \to B$ is $k$-to-1, then $\card{A} = k \cdot \card{B}$.
\end{mathrule}

For example, suppose $A$ is the set of ears in the room and $B$ is the set
of people.  There is a 2-to-1 mapping from ears to people, so by the
Division Rule $\card{A} = 2 \cdot \card{B}$ or, equivalently, $\card{B} =
\card{A} / 2$, expressing what we knew all along: the number of people is
half the number of ears.  Unlikely as it may seem, many counting problems
are made much easier by initially counting every item multiple times and
then correcting the answer using the Division Rule.  Let's look at some
examples.

\subsection{Another Chess Problem}

In how many different ways can you place two identical rooks on a
chessboard so that they do not share a row or column?  A valid
configuration is shown below on the left, and an invalid configuration
is shown on the right.
%
\[
\begin{array}{ccc}
\begin{array}{|c|c|c|c|c|c|c|c|}
\hline
\ &\ &\ &\ &\ &\ &\ &r \\ \hline
 & & & & & & &\ \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
r& & & & & & & \\ \hline
\end{array}
& \hspace{1in} &
\begin{array}{|c|c|c|c|c|c|c|c|}
\hline
\ &\ &\ &\ &\ &\ &\ &\ \\ \hline
 & & & & & & & \\ \hline
 & & &r& & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & & & & & & \\ \hline
 & & &r& & & & \\ \hline
\end{array} \\
\\
\text{valid} & & \text{invalid}
\end{array}
\]

Let $A$ be the set of all sequences
%
\[
(r_1, c_1, r_2, c_2)
\]
%
where $r_1$ and $r_2$ are distinct rows and $c_1$ and $c_2$ are
distinct columns.  Let $B$ be the set of all valid rook
configurations.  There is a natural function $f$ from set $A$ to set
$B$; in particular, $f$ maps the sequence $(r_1, c_1, r_2, c_2)$ to a
configuration with one rook in row $r_1$, column $c_1$ and the other
rook in row $r_2$, column $c_2$.

But now there's a snag.  Consider the sequences:
%
\[
(1, 1, 8, 8) \qquad \text{ and } \qquad (8, 8, 1, 1)
\]
%
The first sequence maps to a configuration with a rook in the
lower-left corner and a rook in the upper-right corner.  The second
sequence maps to a configuration with a rook in the upper-right corner
and a rook in the lower-left corner.  The problem is that those are
two different ways of describing the \emph{same} configuration!  In
fact, this arrangement is shown on the left side in the diagram above.

More generally, the function $f$ maps exactly two sequences to
\emph{every} board configuration; that is $f$ is a 2-to-1 function.
Thus, by the quotient rule, $\card{A} = 2 \cdot \card{B}$.
Rearranging terms gives:
%
\begin{align*}
\card{B}
    & = \frac{\card{A}}{2} \\
    & = \frac{(8 \cdot 7)^2}{2}
\end{align*}
%
On the second line, we've computed the size of $A$ using the General
Product Rule just as in the earlier chess problem.

\subsection{Knights of the Round Table}

In how many ways can King Arthur seat $n$ different knights at his
round table?  Two seatings are considered equivalent if one can be
obtained from the other by rotation.  For example, the following two
arrangements are equivalent:

\begin{center}
\begin{picture}(230,80)
%\put(0,0){\dashbox(230,80){}}
\put(0,0){
\begin{picture}(80,80)(-40,-40)
%\put(-40,-40){\dashbox(80,80){}}
\put(0,0){\circle{36}}
\put(0,26){\makebox(0,0){$k_1$}}
\put(26,0){\makebox(0,0){$k_2$}}
\put(0,-26){\makebox(0,0){$k_3$}}
\put(-26,0){\makebox(0,0){$k_4$}}
\end{picture}}
\put(150,0){
\begin{picture}(80,80)(-40,-40)
%\put(-40,-40){\dashbox(80,80){}}
\put(0,0){\circle{36}}
\put(0,26){\makebox(0,0){$k_3$}}
\put(26,0){\makebox(0,0){$k_4$}}
\put(0,-26){\makebox(0,0){$k_1$}}
\put(-26,0){\makebox(0,0){$k_2$}}
\end{picture}}
\end{picture}
\end{center}

Let $A$ be all the permutations of the knights, and let $B$ be the set
of all possible seating arrangements at the round table.  We can map
each permutation in set $A$ to a circular seating arrangement in set
$B$ by seating the first knight in the permutation anywhere, putting
the second knight to his left, the third knight to the left of the
second, and so forth all the way around the table.  For example:
%
\begin{center}
\begin{picture}(200,80)(-160,-40)
%\put(-160,-40){\dashbox(200,80){}} % bounding box
\put(-120,0){\makebox(0,0){$(k_2, k_4, k_1, k_3)$}}
\put(-60,0){\makebox(0,0){$\implies$}}
\put(0,0){\circle{36}}
\put(0,26){\makebox(0,0){$k_2$}}
\put(26,0){\makebox(0,0){$k_4$}}
\put(0,-26){\makebox(0,0){$k_1$}}
\put(-26,0){\makebox(0,0){$k_3$}}
\end{picture}
\end{center}
%
This mapping is actually an $n$-to-1 function from $A$ to $B$, since
all $n$ cyclic shifts of the original sequence map to the same seating
arrangement.  In the example, $n = 4$ different sequences map to the
same seating arrangement:
%
\begin{center}
\begin{picture}(200,80)(-160,-40)
% \put(-160,-40){\dashbox(200,80){}} % bounding box
\put(-120,24){\makebox(0,0){$(k_2, k_4, k_1, k_3)$}}
\put(-120,8){\makebox(0,0){$(k_4, k_1, k_3, k_2)$}}
\put(-120,-8){\makebox(0,0){$(k_1, k_3, k_2, k_4)$}}
\put(-120,-24){\makebox(0,0){$(k_3, k_2, k_4, k_1)$}}
\put(-60,0){\makebox(0,0){$\implies$}}
\put(0,0){\circle{36}}
\put(0,26){\makebox(0,0){$k_2$}}
\put(26,0){\makebox(0,0){$k_4$}}
\put(0,-26){\makebox(0,0){$k_1$}}
\put(-26,0){\makebox(0,0){$k_3$}}
\end{picture}
\end{center}
%
Therefore, by the division rule, the number of circular seating
arrangements is:
%
\begin{align*}
\card{B}
    & = \frac{\card{A}}{n} \\
    & = \frac{n!}{n} \\
    & = (n-1)!
\end{align*}
%
Note that $\card{A} = n!$ since there are $n!$ permutations of $n$
knights.

%verbatim S06 ln9

\begin{problems}
  \classproblems
  \pinput{CP_division_rule_assign_groups}
  \pinput{CP_pizza_sale}
  \pinput{CP_generalized_product}

  \examproblems
  \pinput{MQ_count_double_deck}

\end{problems}

\hyperdef{comb}{inations}{\section{Counting Subsets}}\label{combinations_sec}

How many $k$-element subsets of an $n$-element set are there?  This
question arises all the time in various guises:

\begin{itemize}

\item In how many ways can I select 5 books from my collection of 100
to bring on vacation?

\item How many different 13-card Bridge hands can be dealt from a
52-card deck?

\item In how many ways can I select 5 toppings for my pizza if there
are 14 available toppings?

\end{itemize}

This number comes up so often that there is a special notation for it:
\[
\binom{n}{k} \eqdef \text{ the number of $k$-element subsets of an $n$-element set.}
\]

The expression $\dbinom{n}{k}$ is read ``$n$ choose $k$.''  Now we can
immediately express the answers to all three questions above:

\begin{itemize}

\item I can select 5 books from 100 in $\dbinom{100}{5}$ ways.

\item There are $\dbinom{52}{13}$ different Bridge hands.

\item There are $\dbinom{14}{5}$ different 5-topping pizzas, if 14
toppings are available.

\end{itemize}

\subsection{The Subset Rule}

We can derive a simple formula for the $n$-choose-$k$ number using the
Division Rule.  We do this by mapping any permutation of an $n$-element
set $\set{a_1,\dots, a_n}$ into a $k$-element subset simply by taking the
first $k$ elements of the permutation.  That is, the permutation
$a_1a_2\dots a_n$ will map to the set $\set{a_1,a_2,\dots,a_k}$.

Notice that any other permutation with the same first $k$ elements
$a_1,\dots,a_k$ \emph{in any order} and the same remaining elements $n-k$
elements \emph{in any order} will also map to this set.  What's more, a
permutation can only map to $\set{a_1,a_2,\dots,a_k}$ if its first $k$
elements are the elements $a_1,\dots,a_k$ in some order.  Since there are
$k!$ possible permutations of the first $k$ elements and $(n-k)!$
permutations of the remaining elements, we conclude from the Product Rule
that exactly $k!(n-k)!$ permutations of the $n$-element set map to the the
particular subset $S$.  In other words, the mapping from permutations to
$k$-element subsets is $k!(n-k)!$-to-1.

But we know there are $n!$ permutations of an $n$-element set, so by the
Division Rule, we conclude that
\[
n!= k!(n-k)!\binom{n}{k}
\]
which proves:
\begin{mathrule}[Subset Rule]
\label{rule:subset}
The number,
\[
\binom{n}{k},
\]
of $k$-element subsets of an $n$-element set is
\[
\frac{n!}{k!\ (n-k)!}.
\]
\end{mathrule}

Notice that this works even for 0-element subsets: $n!/0!n! = 1$.  Here we
use the fact that $0!$ is a \emph{product} of 0 terms, which by convention
equals 1.  (A \emph{sum} of zero terms equals 0.)

\subsection{Bit Sequences}

How many $n$-bit sequences contain exactly $k$ ones?  We've already seen
the straightforward bijection between subsets of an $n$-element set and
$n$-bit sequences.  For example, here is a 3-element subset of $\set{x_1,
x_2, \ldots, x_8}$ and the associated 8-bit sequence:
%
\[
\begin{array}{rccccccccl}
\{ & x_1, &    &    & x_4, & x_5  &    &    &   & \} \\
(  &   1, & 0, & 0, &   1, &   1, & 0, & 0, & 0 & )
\end{array}
\]
Notice that this sequence has exactly 3 ones, each corresponding to an
element of the 3-element subset.  More generally, the $n$-bit sequences
corresponding to a $k$-element subset will have exactly $k$ ones.  So by
the Bijection Rule,
\begin{quote}
The number of $n$-bit sequences with exactly $k$ ones is $\dbinom{n}{k}$.
\end{quote}


\hyperdef{book}{keeper}{\section{Sequences with Repetitions}}\label{bookkeeper_sec}

\subsection{Sequences of Subsets}

Choosing a $k$-element subset of an $n$-element set is the same as
splitting the set into a pair of subsets: the first subset of size $k$ and
the second subset consisting of the remaining $n-k$ elements.  So the
Subset Rule can be understood as a rule for counting the number of such
splits into pairs of subsets.

We can generalize this to splits into more than two subsets.  Namely, let
$A$ be an $n$-element set and $k_1,k_2, \dots, k_m$ be nonnegative integers
whose sum is $n$.  A \term{$(k_1,k_2, \dots, k_m)$-split of $A$} is a
sequence
\[
(A_1, A_2,\dots,A_m)
\]
where the $A_i$ are pairwise disjoint\footnote{That is $A_i \intersect A_j
 = \emptyset$ whenever $i \neq j$.  Another way to say this is that no
element appears in more than one of the $A_i$'s.} subsets of $A$ and
$\card{A_i} = k_i$ for $i=1,\dots,m$.

The same reasoning used to explain the Subset Rule extends directly to a
rule for counting the number of splits into subsets of given sizes.

\begin{mathrule}[Subset Split Rule]
The number of $(k_1,k_2, \dots, k_m)$-splits of an $n$-element set is
\[
\binom{n}{k_1,\dots,k_m} \eqdef \frac{n!}{k_1!\ k_2!\ \cdots k_m!}
\]
\end{mathrule}

The proof of this Rule is essentially the same as for the Subset Rule.
Namely, we map any permutation $a_1a_2\dots a_n$ of an $n$-element set
$A$ into a $(k_1,k_2, \dots, k_m)$-split by letting the 1st subset in the
split be the first $k_1$ elements of the permutation, the 2nd subset of
the split be the next $k_2$ elements, \dots, and the $m$th subset of the
split be the final $k_m$ elements of the permutation.  This map is a
$k_1!\ k_2!\ \cdots\ k_m!$-to-1 from the $n!$ permutations to the
$(k_1,k_2, \dots, k_m)$-splits of $A$, and the Subset Split Rule now
follows from the Division Rule.

\subsection{The Bookkeeper Rule}

We can also generalize our count of $n$-bit sequences with $k$-ones to
counting length $n$ sequences of letters over an alphabet with more than
two letters.  For example, how many sequences can be formed by permuting
the letters in the 10-letter word BOOKKEEPER?

Notice that there are 1 B, 2 O's, 2 K's, 3 E's, 1 P, and 1 R in
BOOKKEEPER.  This leads to a straightforward bijection between
permutations of BOOKKEEPER and (1,2,2,3,1,1)-splits of $\set{1,\dots,n}$.
Namely, map a permutation to the sequence of sets of positions where each
of the different letters occur.

For example, in the permutation BOOKKEEPER itself, the B is in the 1st
position, the O's occur in the 2nd and 3rd positions, K's in 4th and 5th,
the E's in the 6th, 7th and 9th, P in the 8th, and R is in the 10th
position, so BOOKKEEPER maps to
\[
(\set{1}, \set{2,3}, \set{4,5}, \set{6,7,9}, \set{8}, \set{10}).
\]
From this bijection and the Subset Split Rule, we conclude that the
number of ways to rearrange the letters in the word BOOKKEEPER is:
\[
\frac{\overbrace{10!}^{\text{total letters}}}{
\underbrace{1!}_{\text{B's}}
\underbrace{2!}_{\text{O's}}
\underbrace{2!}_{\text{K's}}
\underbrace{3!}_{\text{E's}}
\underbrace{1!}_{\text{P's}}
\underbrace{1!}_{\text{R's}}}
\]

This example generalizes directly to an exceptionally useful counting
principle which we will call the
\begin{mathrule}[Bookkeeper Rule]
Let $l_1, \ldots, l_m$ be distinct elements.  The number of sequences with
$k_1$ occurrences of $l_1$, and $k_2$ occurrences of $l_2$, \dots, and
$k_m$ occurrences of $l_m$ is
\[
\frac{(k_1 + k_2 + \ldots + k_m)!}{k_1!\ k_2!\ \ldots\ k_m!}
\]
\end{mathrule}

\begin{example*} 20-Mile Walks.

I'm planning a 20-mile walk, which should include 5 northward miles, 5
eastward miles, 5 southward miles, and 5 westward miles.  How many
different walks are possible?

There is a bijection between such walks and sequences with 5 N's, 5
E's, 5 S's, and 5 W's.  By the Bookkeeper Rule, the number of such
sequences is:
\[
\frac{20!}{5!^4}
\]
\end{example*}

\subsection{A Word about Words}

Someday you might refer to the Subset Split Rule or the Bookkeeper Rule
in front of a roomful of colleagues and discover that they're all staring
back at you blankly.  This is not because they're dumb, but rather because
we made up the name ``Bookkeeper Rule''.  However, the rule is excellent
and the name is apt, so we suggest that you play through: ``You know?  The
Bookkeeper Rule?  Don't you guys know \emph{anything???}''

The Bookkeeper Rule is sometimes called the ``formula for permutations
with indistinguishable objects.''  The size $k$ subsets of an $n$-element
set are sometimes called \term{$k$-combinations}.  Other similar-sounding
descriptions are ``combinations with repetition, permutations with
repetition, $r$-permutations, permutations with indistinguishable
objects,'' and so on.  However, the counting rules we've taught you are
sufficient to solve all these sorts of problems without knowing this
jargon, so we won't burden you with it.

\begin{problems}
\classproblems
\pinput{CP_bookkeeper_tao}
\end{problems}


\section{Magic Trick}

There is a Magician and an Assistant.  The Assistant goes into the
audience with a deck of 52 cards while the Magician looks away.%
\footnote{ There are 52 cards in a standard deck.  Each card has a
  \emph{suit} and a \emph{rank}.  There are four suits:
%
\[
\spadesuit (\text{ spades}) \qquad
\heartsuit (\text{ hearts}) \qquad
\clubsuit (\text{ clubs}) \qquad
\diamondsuit (\text{ diamonds})
\]
%
And there are 13 ranks, listed here from lowest to highest:
%
\[
\stackrel{\text{Ace}}{A},\
2\ ,\ 3\ ,\ 4\ ,\ 5\ ,\ 6\ ,\ 7\ ,\ 8\ ,\ 9\ ,\
\stackrel{\text{Jack}}{J}\ ,\
\stackrel{\text{Queen}}{Q}\ ,\
\stackrel{\text{King}}{K}
\]
%
Thus, for example, $8 \heartsuit$ is the 8 of hearts and $A
\spadesuit$ is the ace of spades.}

Five audience members each select one card from the deck.  The Assistant
then gathers up the five cards and holds up four of them so the Magician
can see them.  The Magician concentrates for a short time and then
correctly names the secret, fifth card!

Since we don't really believe the Magician can read minds, we know the
Assistant has somehow communicated the secret card to the Magician.  Since
real Magicians and Assistants are not to be trusted, we can expect that
the Assistant would illegitimately signal the Magician with coded phrases
or body language, but they don't have to cheat in this way.  In fact, the
Magician and Assistant could be kept out of sight of each other while some
audience member holds up the 4 cards designated by the Assistant for the
Magician to see.

Of course, without cheating, there is still an obvious way the Assistant
can communicate to the Magician: he can choose any of the $4! = 24$
permutations of the 4 cards as the order in which to hold up the cards.
However, this alone won't quite work: there are 48 cards remaining in the
deck, so the Assistant doesn't have enough choices of orders to indicate
exactly what the secret card is (though he could narrow it down to two
cards).

\subsection{The Secret}

The method the Assistant can use to communicate the fifth card exactly is
a nice application of what we know about counting and matching.

The Assistant really has another legitimate way to communicate: he can
choose \emph{which of the five cards to keep hidden}.  Of course, it's not
clear how the Magician could determine which of these five possibilities
the Assistant selected by looking at the four visible cards, but there is
a way, as we'll now explain.

The problem facing the Magician and Assistant is actually a bipartite
matching problem.  Put all the \emph{sets} of 5 cards in a collection
$X$ on the left.  And put all the sequences of 4 distinct cards in a
collection $Y$ on the right.  These are the two sets of vertices in the
bipartite graph.  There is an edge between a set of 5 cards and a sequence
of 4 if every card in the sequence is also in the set.  In other words, if
the audience selects a set of cards, then the Assistant must reveal a
sequence of cards that is adjacent in the bipartite graph.  Some edges are
shown in the diagram below.

\noindent
\begin{picture}(350,155)(0,25)
%\put(0,25){\framebox(450,155){}} % bounding box

\put(30,164){\makebox(0,0){$X = $}}
\put(30,150){\makebox(0,0){all sets of}}
\put(30,136){\makebox(0,0){5 cards}}

\put(80,172){\makebox(0,0){$\bullet$}}
\put(80,154){\makebox(0,0){$\bullet$}}
\put(80,136){\makebox(0,0){$\bullet$}}
\put(80,118){\makebox(0,0){$\bullet$}}
\put(80,100){\makebox(0,0){$\set{8 \hea, K \spa, Q \spa, 2 \dia, 6 \dia}$}}
\put(80,82){\makebox(0,0){$\bullet$}}
\put(80,64){\makebox(0,0){$\bullet$}}
\put(80,46){\makebox(0,0){$\set{8 \hea, K \spa, Q \spa, 9 \clu, 6 \dia}$}}
\put(80,28){\makebox(0,0){$\bullet$}}

\put(270,172){\makebox(0,0){$Y = $ all}}
\put(270,158){\makebox(0,0){sequences of 4}}
\put(270,144){\makebox(0,0){distinct cards}}

\put(320,172){\makebox(0,0){$\bullet$}}
\put(320,154){\makebox(0,0){$\bullet$}}
\put(320,136){\makebox(0,0){$\bullet$}}
\put(320,118){\makebox(0,0){$(8 \hea, K \spa, Q \spa, 2 \dia)$}}
\put(320,100){\makebox(0,0){$(K \spa, 8 \hea, Q \spa, 2 \dia)$}}
\put(320,82){\makebox(0,0){$(K \spa, 8 \hea, 6 \dia, Q \spa)$}}
\put(320,64){\makebox(0,0){$\bullet$}}
\put(320,46){\makebox(0,0){$\bullet$}}
\put(320,28){\makebox(0,0){$\bullet$}}

\put(135,100){\line(3,1){60}}
\put(135,100){\line(1,0){115}}
\put(135,100){\line(6,-1){125}}
\put(135,100){\line(3,-1){60}}

\put(145,50){\line(3,1){60}}
\put(145,50){\line(1,0){60}}

\thicklines
\put(135,100){\line(6,1){110}}
\put(145,50){\line(5,1){110}}
\end{picture}

For example,
\begin{equation}\label{2dia6dia}
\set{ 8 \hea, K \spa, Q \spa, 2 \dia, 6 \dia }
\end{equation}
is an element of $X$ on the left.  If the audience selects this set of 5
cards, then there are many different 4-card sequences on the right in set
$Y$ that the Assistant could choose to reveal, including $(8 \hea, K \spa,
Q \spa, 2 \dia)$, $(K \spa, 8 \hea, Q \spa, 2 \dia)$ and $(K \spa, 8
\hea, 6 \dia, Q \spa)$.

What the Magician and his Assistant need to perform the trick is a
\emph{matching} for the $X$ vertices.  If they agree in advance on some
matching, then when the audience selects a set of 5 cards, the Assistant
reveals the matching sequence of 4 cards.  The Magician uses the reverse
of the matching to find the audience's chosen set of 5 cards, and so he
can name the one not already revealed.

For example, suppose the Assistant and Magician agree on a matching
containing the two bold edges in the diagram above.  If the audience
selects the set
\begin{equation}\label{8heaKspa}
\set{8 \hea, K \spa, Q \spa, 9 \clu, 6 \dia},
\end{equation}
then the Assistant reveals the corresponding sequence
\begin{equation}\label{Kspa8hea}
(K \spa, 8 \hea, 6 \dia, Q \spa).
\end{equation}
Using the matching, the Magician sees that the hand~\eqref{8heaKspa} is
matched to the sequence~\eqref{Kspa8hea}, so he can name the one card in
the corresponding set not already revealed, namely, the $9 \clu$.  Notice
that the fact that the sets are \emph{matched}, that is, that different
sets are paired with \emph{distinct} sequences, is essential.  For
example, if the audience picked the previous hand~\eqref{2dia6dia}, it
would be possible for the Assistant to reveal the same
sequence~\eqref{Kspa8hea}, but he better not do that: if he did, then the
Magician would have no way to tell if the remaining card was the $9 \clu$
or the $2 \dia$.

So how can we be sure the needed matching can be found?  The reason is
that each vertex on the left has degree $5 \cdot 4! = 120$, since there
are five ways to select the card kept secret and there are $4!$
permutations of the remaining 4 cards.  In addition, each vertex on the
right has degree 48, since there are 48 possibilities for the fifth card.
So this graph is \emph{\idx{degree-constrained}} according to
Definition~\ref{degree-constrained_def}, and therefore satisfies \idx{Hall's
matching condition}.

In fact, this reasoning show that the Magician could still pull off the
trick if 120 cards were left instead of 48, that is, the trick would work
with a deck as large as 124 different cards---without any magic!

\subsection{The Real Secret}

But wait a minute!  It's all very well in principle to have the Magician
and his Assistant agree on a matching, but how are they supposed to
remember a matching with $\binom{52}{5} = 2,598,960$ edges?  For the trick
to work in practice, there has to be a way to match hands and card
sequences mentally and on the fly.

%We'll describe how in lecture\dots.

We'll describe one approach.  As a running example, suppose that the
audience selects:
%
\[
10 \hea \quad 9 \dia \quad 3 \hea \quad Q \spa \quad J \dia
\]

\begin{itemize}

\item The Assistant picks out two cards of the same suit.  In the
example, the assistant might choose the $3 \hea$ and $10 \hea$.

\item The Assistant locates the ranks of these two cards on the cycle
shown below:

\begin{center}
\begin{picture}(120,120)(-60,-60)
% \put(-60,-60){\framebox(120,120){}} % bounding box
\put(0.000000,50.000000){\makebox(0,0){$A$}}
\put(23.236159,44.272801){\makebox(0,0){$2$}}
\put(41.149193,28.403237){\makebox(0,0){$\mathbf{3}$}}
\put(49.635444,6.026834){\makebox(0,0){$4$}}
\put(46.750812,-17.730244){\makebox(0,0){$5$}}
\put(33.156133,-37.425537){\makebox(0,0){$6$}}
\put(11.965783,-48.547091){\makebox(0,0){$7$}}
\put(-11.965783,-48.547091){\makebox(0,0){$8$}}
\put(-33.156133,-37.425537){\makebox(0,0){$9$}}
\put(-46.750812,-17.730244){\makebox(0,0){$\mathbf{10}$}}
\put(-49.635444,6.026834){\makebox(0,0){$J$}}
\put(-41.149193,28.403237){\makebox(0,0){$Q$}}
\put(-23.236159,44.272801){\makebox(0,0){$K$}}
\end{picture}
\end{center}

For any two distinct ranks on this cycle, one is always between 1 and
6 hops clockwise from the other.  For example, the $3 \hea$ is 6 hops
clockwise from the $10 \hea$.

\item The more counterclockwise of these two cards is revealed first,
and the other becomes the secret card.  Thus, in our example, the $10
\hea$ would be revealed, and the $3 \hea$ would be the secret card.
Therefore:

\begin{itemize}

\item The suit of the secret card is the same as the suit of the first
card revealed.

\item The rank of the secret card is between 1 and 6 hops clockwise
from the rank of the first card revealed.

\end{itemize}

\item All that remains is to communicate a number between 1 and 6.
The Magician and Assistant agree beforehand on an ordering of all the
cards in the deck from smallest to largest such as:
%
\[
A \clu\  A \dia\  A \hea\ A \spa\
2 \clu\  2 \dia\  2 \hea\ 2 \spa\
\dots\ K \hea\ K \spa
\]
%
The order in which the last three cards are revealed communicates the
number according to the following scheme:
%
\[
\begin{array}{rcccll}
(&\text{small},&\text{medium},&\text{large}&) & = 1 \\
(&\text{small},&\text{large},&\text{medium}&) & = 2 \\
(&\text{medium},&\text{small},&\text{large}&) & = 3 \\
(&\text{medium},&\text{large},&\text{small}&) & = 4 \\
(&\text{large},&\text{small},&\text{medium}&) & = 5 \\
(&\text{large},&\text{medium},&\text{small}&) & = 6
\end{array}
\]
%
In the example, the Assistant wants to send 6 and so reveals the
remaining three cards in large, medium, small order.  Here is the
complete sequence that the Magician sees:
%
\[
10 \hea \quad Q \spa \quad J \dia \quad 9 \dia
\]

\item The Magician starts with the first card $10 \hea$ and hops 6
ranks clockwise to reach $3 \hea$, which is the secret card!

\end{itemize}

So that's how the trick can work with a standard deck of 52 cards.  On the
other hand, Hall's Theorem implies that the Magician and Assistant can
\emph{in principle} perform the trick with a deck of up to 124 cards.  It
turns out that there is a method which they could actually learn to use
with a reasonable amount of practice for a 124 card deck (see
\href{http://courses.csail.mit.edu/6.042/spring10/cardTrick.pdf}{\emph{The Best
    Card Trick}} by Michael Kleber).

\iffalse
http://people.brandeis.edu/~kleber/Papers/card.pdf

Also, \emph{Using a Card Trick to Teach Discrete Mathematics}, Simonson,
Shai, Holm, Tara S., Primus: Problems, Resources, and Issues in
Mathematics Undergraduate Studies, Sep 2003.
\fi

\subsection{Same Trick with Four Cards?}\label{4_card_trick_subsec}

Suppose that the audience selects only \emph{four} cards and the
Assistant reveals a sequence of \emph{three} to the Magician.  Can
the Magician determine the fourth card?

Let $X$ be all the sets of four cards that the audience might select,
and let $Y$ be all the sequences of three cards that the Assistant
might reveal.  Now, on one hand, we have
\[
\card{X} = \binom{52}{4} = 270,725
\]
by the Subset Rule.  On the other hand, we have
\[
\card{Y} = 52 \cdot 51 \cdot 50 = 132,600
\]
by the Generalized Product Rule.  Thus, by the Pigeonhole Principle, the
Assistant must reveal the \emph{same} sequence of three cards for at
least
\[
\ceil{\frac{270,725}{132,600}} = 3
\]
\emph{different} four-card hands.  This is bad news for the Magician:
if he sees that sequence of three, then there are at least three
possibilities for the fourth card which he cannot distinguish.  So there
is no legitimate way for the Assistant to communicate exactly what the
fourth card is!

%%%%%%%%%%%%%%%%%

\begin{problems}
\classproblems
\pinput{CP_magic_trick_124_cards}
\pinput{CP_magic_trick_hide_2}

\homeworkproblems

\pinput{PS_magic_trick_4cards}

\end{problems}


\section{Counting Practice: Poker Hands}\label{poker hands}

Five-Card Draw is a card game in which each player is initially dealt
a \emph{hand}, a subset of 5 cards.  (Then the game gets
complicated, but let's not worry about that.)  The number of different
hands in Five-Card Draw is the number of 5-element subsets of a
52-element set, which is 52 choose 5:
%
\[
\text{total \# of hands} = \binom{52}{5} = 2,598,960
\]
%
Let's get some counting practice by working out the number of hands
with various special properties.

\subsection{Hands with a Four-of-a-Kind}

A \emph{Four-of-a-Kind} is a set of four cards with the same rank.
How many different hands contain a Four-of-a-Kind?  Here are a couple
examples:
%
\[
\begin{array}{rcccccl}
\{ & 8 \spa, & 8 \dia, & Q \hea, & 8 \hea, & 8 \clu & \} \\
\{ & A \clu, & 2 \clu, & 2 \hea, & 2 \dia, & 2 \spa & \} \\
\end{array}
\]
%
As usual, the first step is to map this question to a
sequence-counting problem.  A hand with a Four-of-a-Kind is completely
described by a sequence specifying:
%
\begin{enumerate}
\item The rank of the four cards.
\item The rank of the extra card.
\item The suit of the extra card.
\end{enumerate}
%
Thus, there is a bijection between hands with a Four-of-a-Kind and
sequences consisting of two distinct ranks followed by a suit.  For
example, the three hands above are associated with the following
sequences:
%
\[
\begin{array}{rccccclcl}
(8, Q, \hea) & \leftrightarrow &
  \{ & 8 \spa, & 8 \dia, & 8 \hea, & 8 \clu, & Q \hea & \} \\
(2, A, \clu) & \leftrightarrow &
  \{ & 2 \clu, & 2 \hea, & 2 \dia, & 2 \spa, & A \clu & \} \\
\end{array}
\]
%
Now we need only count the sequences.  There are 13 ways to choose the
first rank, 12 ways to choose the second rank, and 4 ways to choose
the suit.  Thus, by the Generalized Product Rule, there are $13 \cdot
12 \cdot 4 = 624$ hands with a Four-of-a-Kind.  This means that only 1
hand in about 4165 has a Four-of-a-Kind; not surprisingly, this is
considered a very good poker hand!

\subsection{Hands with a Full House}

A \emph{Full House} is a hand with three cards of one rank and
two cards of another rank.  Here are some examples:
%
\[
\begin{array}{rcccccl}
\{ & 2 \spa, & 2 \clu, & 2 \dia, & J \clu, & J \dia & \} \\
\{ & 5 \dia, & 5 \clu, & 5 \hea, & 7 \hea, & 7 \clu & \}
\end{array}
\]
%
Again, we shift to a problem about sequences.  There is a bijection
between Full Houses and sequences specifying:
%
\begin{enumerate}
\item The rank of the triple, which can be chosen in 13 ways.
\item The suits of the triple, which can be selected in $\binom{4}{3}$ ways.
\item The rank of the pair, which can be chosen in 12 ways.
\item The suits of the pair, which can be selected in $\binom{4}{2}$ ways.
\end{enumerate}
%
The example hands correspond to sequences as shown below:
%
\[
\begin{array}{rcrcccccl}
(2, \set{\spa, \clu, \dia}, J, \set{\clu, \dia}) & \leftrightarrow &
    \{ & 2 \spa, & 2 \clu, & 2 \dia, & J \clu, & J \dia & \} \\
(5, \set{\dia, \clu, \hea}, 7, \set{\hea, \clu}) & \leftrightarrow &
    \{ & 5 \dia, & 5 \clu, & 5 \hea, & 7 \hea, & 7 \clu & \}
\end{array}
\]
%
By the Generalized Product Rule, the number of Full Houses is:
%
\[
13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}
\]
%
We're on a roll--- but we're about to hit a speedbump.

\subsection{Hands with Two Pairs}

How many hands have \emph{Two Pairs}; that is, two cards of one
rank, two cards of another rank, and one card of a third rank?
Here are examples:
%
\[
\begin{array}{rcccccl}
\{ & 3 \dia, & 3 \spa, & Q \dia, & Q \hea, & A \clu & \} \\
\{ & 9 \hea, & 9 \dia, & 5 \hea, & 5 \clu, & K \spa & \}
\end{array}
\]
%
Each hand with Two Pairs is described by a sequence consisting of:
%
\begin{enumerate}
\item The rank of the first pair, which can be chosen in 13 ways.
\item The suits of the first pair, which can be selected $\binom{4}{2}$ ways.
\item The rank of the second pair, which can be chosen in 12 ways.
\item The suits of the second pair, which can be selected in $\binom{4}{2}$ ways.
\item The rank of the extra card, which can be chosen in 11 ways.
\item The suit of the extra card, which can be selected in $\binom{4}{1} = 4$ ways.
\end{enumerate}
%
Thus, it might appear that the number of hands with Two Pairs is:
%
\[
13 \cdot \binom{4}{2} \cdot 12 \cdot \binom{4}{2} \cdot 11 \cdot 4
\]
%
Wrong answer!  The problem is that there is \emph{not} a bijection
from such sequences to hands with Two Pairs.  This is actually a
2-to-1 mapping.  For example, here are the pairs of sequences that map
to the hands given above:
%
\[
\begin{array}{rcrcccccl}
(3, \set{\dia, \spa}, Q, \set{\dia, \hea}, A, \clu) & \searrow \\
 & & \{ & 3 \dia, & 3 \spa, & Q \dia, & Q \hea, & A \clu & \} \\
(Q, \set{\dia, \hea}, 3, \set{\dia, \spa}, A, \clu) & \nearrow \\
\\
(9, \set{\hea, \dia}, 5, \set{\hea, \clu}, K, \spa) & \searrow \\
& & \{ & 9 \hea, & 9 \dia, & 5 \hea, & 5 \clu, & K \spa & \} \\
(5, \set{\hea, \clu}, 9, \set{\hea, \dia}, K, \spa) & \nearrow \\
\end{array}
\]
%
The problem is that nothing distinguishes the first pair from the
second.  A pair of 5's and a pair of 9's is the same as a pair of 9's
and a pair of 5's.  We avoided this difficulty in counting Full Houses
because, for example, a pair of 6's and a triple of kings is different
from a pair of kings and a triple of 6's.

We ran into precisely this difficulty last time, when we went from
counting arrangements of \emph{different} pieces on a chessboard to
counting arrangements of two \emph{identical} rooks.  The solution
then was to apply the Division Rule, and we can do the same here.  In
this case, the Division rule says there are twice as many sequences
as hands, so the number of hands with Two Pairs is actually:
%
\[
\frac{13 \cdot \binom{4}{2} \cdot 12 \cdot \binom{4}{2} \cdot 11 \cdot 4}{2}
\]

\subsubsection*{Another Approach}

The preceding example was disturbing!  One could easily overlook the
fact that the mapping was 2-to-1 on an exam, fail the course, and turn
to a life of crime.  You can make the world a safer place in two ways:

\begin{enumerate}

\item Whenever you use a mapping $f : A \to B$ to translate one counting
  problem to another, check that the same number elements in $A$ are
  mapped to each element in $B$.  If $k$ elements of $A$ map to each of
  element of $B$, then apply the Division Rule using the constant $k$.

\item As an extra check, try solving the same problem in a different
way.  Multiple approaches are often available--- and all had better
give the same answer!  (Sometimes different approaches give answers
that \emph{look} different, but turn out to be the same after some
algebra.)

\end{enumerate}

We already used the first method; let's try the second.  There is a
bijection between hands with two pairs and sequences that specify:
%
\begin{enumerate}
\item The ranks of the two pairs, which can be chosen in $\binom{13}{2}$ ways.
\item The suits of the lower-rank pair, which can be selected in $\binom{4}{2}$ ways.
\item The suits of the higher-rank pair, which can be selected in $\binom{4}{2}$ ways.
\item The rank of the extra card, which can be chosen in $11$ ways.
\item The suit of the extra card, which can be selected in $\binom{4}{1} = 4$ ways.
\end{enumerate}
%
For example, the following sequences and hands correspond:
%
\[
\begin{array}{rcrcccccl}
(\set{3, Q}, \set{\dia, \spa}, \set{\dia, \hea}, A, \clu) & \leftrightarrow &
  \{ & 3 \dia, & 3 \spa, & Q \dia, & Q \hea, & A \clu & \} \\
(\set{9, 5}, \set{\hea, \clu}, \set{\hea, \dia}, K, \spa) & \leftrightarrow &
  \{ & 9 \hea, & 9 \dia, & 5 \hea, & 5 \clu, & K \spa & \}
\end{array}
\]
%
Thus, the number of hands with two pairs is:
%
\[
\binom{13}{2} \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot 11 \cdot 4
\]
%
This is the same answer we got before, though in a slightly different
form.

\subsection{Hands with Every Suit}

How many hands contain at least one card from every suit?  Here is an
example of such a hand:
%
\[
\begin{array}{rcccccl}
\{ & 7 \dia, & K \clu, & 3 \dia, & A \hea, & 2 \spa & \}
\end{array}
\]
%
Each such hand is described by a sequence that specifies:

\begin{enumerate}

\item The ranks of the diamond, the club, the heart, and the spade,
which can be selected in $13 \cdot 13 \cdot 13 \cdot 13 = 13^4$ ways.

\item The suit of the extra card, which can be selected in 4 ways.

\item The rank of the extra card, which can be selected in 12 ways.

\end{enumerate}

For example, the hand above is described by the sequence:
%
\[
\begin{array}{rcrcccccl}
(7, K, A, 2, \dia, 3) & \leftrightarrow &
    \{ & 7 \dia, & K \clu, & A \hea, & 2 \spa, & 3 \dia & \}
\end{array}
\]
%
Are there other sequences that correspond to the same hand?  There is
one more!  We could equally well regard either the $3 \dia$ or the $7
\dia$ as the extra card, so this is actually a 2-to-1 mapping.  Here
are the two sequences corresponding to the example hand:
%
\[
\begin{array}{rcrcccccl}
(7, K, A, 2, \dia, 3) & \searrow & \\
 && \{ & 7 \dia, & K \clu, & A \hea, & 2 \spa, & 3 \dia & \} \\
(3, K, A, 2, \dia, 7) & \nearrow &
\end{array}
\]
%
Therefore, the number of hands with every suit is:
%
\[
\frac{13^4 \cdot 4 \cdot 12}{2}
\]

\begin{problems}
\classproblems
\pinput{CP_more_counting}
\pinput{CP_counting_practice}

\examproblems
\pinput{FP_counting_given_answers}

\end{problems}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hyperdef{inclusion}{exclusion}
{\section{Inclusion-Exclusion}}\label{inc-ex_sec}

How big is a union of sets?  For example, suppose there are 60 math
majors, 200 EECS majors, and 40 physics majors.  How many students are
there in these three departments?  Let $M$ be the set of math majors,
$E$ be the set of EECS majors, and $P$ be the set of physics majors.  In
these terms, we're asking for $\card{M \cup E \cup P}$.

The Sum Rule says that the size of union of \emph{disjoint} sets is
the sum of their sizes:
%
\[
\card{M \cup E \cup P} = \card{M} + \card{E} + \card{P}
    \qquad \text{(if $M$, $E$ and $P$ are disjoint)}
\]
%
However, the sets $M$, $E$ and $P$ might \emph{not} be disjoint.  For
example, there might be a student majoring in both math and
physics.  Such a student would be counted twice on the right side of this
equation, once as an element of $M$ and once as an element of $P$.  Worse,
there might be a triple-major\footnote{\dots though not at MIT anymore.}
counted \emph{three} times on the right side!

Our last counting rule determines the size of a union of sets that are
not necessarily disjoint.  Before we state the rule, let's build some
intuition by considering some easier special cases: unions of just two
or three sets.

\subsection{Union of Two Sets}

For two sets $S_1$ and $S_2$, the \term{Inclusion-Exclusion Rule} is that the
size of their union is:
\begin{equation}\label{IE2}
\card{S_1 \cup S_2} = \card{S_1} + \card{S_2} - \card{S_1 \cap S_2}
\end{equation}
Intuitively, each element of $S_1$ is accounted for in the first term,
and each element of $S_2$ is accounted for in the second term.
Elements in \emph{both} $S_1$ and $S_2$ are counted
\emph{twice}--- once in the first term and once in the second.  This
double-counting is corrected by the final term.

We can capture this double-counting idea in a precise way by decomposing
the union of $S_1$ and $S_2$ into three disjoint sets, the elements in
each set but not the other, and the elements in both:
\begin{equation}\label{sus}
S_1 \cup S_2 = (S_1 - S_2) \union (S_2-S_1) \union (S_1 \intersect S_2).
\end{equation}
Similarly, we can decompose each of $S_1$ and $S_2$ into the elements
exclusively in each set and the elements in both:
\begin{align}
S_1 & = (S_1 - S_2) \union (S_1 \intersect S_2),\label{s1}\\
S_2 & = (S_2 - S_1) \union (S_1 \intersect S_2).\label{s2}
\end{align}
Now we have from~\eqref{s1} and~\eqref{s2}
\begin{align}
\card{S_1} + \card{S_2} & = (\card{S_1 - S_2} + \card{S_1 \intersect S_2})
                   + (\card{S_2 - S_1} + \card{S_1 \intersect S_2})\notag\\
        & = \card{S_1 - S_2} + \card{S_2 - S_1} +
                 2\card{S_1 \intersect S_2}, \label{2s}
\end{align}                      
which shows the double-counting of $S_1 \intersect S_2$ in the sum.  On
the other hand, we have from~\eqref{sus}
\begin{equation}\label{csus}
\card{S_1 \cup S_2} = \card{S_1 - S_2} + \card{S_2 - S_1}
                          + \card{S_1 \intersect S_2}.
\end{equation}
Subtracting~\eqref{csus} from~\eqref{2s}, we get
\[
(\card{S_1} + \card{S_2}) - \card{S_1 \cup S_2} =
          \card{S_1 \intersect S_2}
\]
which proves~\eqref{IE2}.

\iffalse
$S_1$ into the elements prove equation~\eqref{IE2} rigorously by applying
the Sum Rule to some disjoint subsets of $S_1 \union S_2$.  As a first
step, we observe that given any two sets $S,T$, we can decompose $S$ into
the disjoint sets consisting of those elements in $S$ but not $T$, and
those elements in $S$ and also in $T$.  That is, $S$ is the union of the
disjoint sets $S-T$ and $S \intersect T$.  So by the Sum Rule we have
\begin{align}
\card{S} & = \card{S-T} + \card{S \intersect T}, & \text{and so}\notag\\
\card{S-T} & = \card{S} - \card{S \intersect T}.\label{s-t}
\end{align}
Now we decompose $S_1 \union S_2$ into three disjoint sets:
\begin{equation}\label{sin3}
S_1 \cup S_2
     = (S_1 - S_2) \cup (S_2 - S_1) \cup (S_1 \cap S_2).
\end{equation}
Now we have
\begin{align*}
\card{S_1 \cup S_2}
    & = \card{(S_1 - S_2) \cup (S_2 - S_1) \cup (S_1 \cap S_2)}
        && \text{(by~\eqref{sin3})} \\
    & = \card{S_1 - S_2} + \card{S_2 - S_1} + \card{S_1 \cap S_2}
        && \text{(Sum Rule)} \\
    & = (\card{S_1} - \card{S_1 \cap S_2})
      + (\card{S_2} - \card{S_1 \cap S_2})
      + \card{S_1 \cap S_2}
        && \text{(by~\eqref{s-t})} \\
    & = \card{S_1} + \card{S_2} - \card{S_1 \cap S_2}
        && \text{(algebra)}
\end{align*}
\fi


\subsection{Union of Three Sets}

So how many students are there in the Math, EECS, and Physics
departments?  In other words, what is $\card{M \cup E \cup P}$ if:
%
\begin{align*}
\card{M} & = 60 \\
\card{E} & = 200 \\
\card{P} & = 40
\end{align*}
%
The size of a union of three sets is given by a more complicated
\idx{Inclusion-Exclusion} formula:
%
\begin{align*}
\card{S_1 \cup S_2 \cup S_3} & = \card{S_1} + \card{S_2} + \card{S_3} \\
  & \quad - \card{S_1 \cap S_2} - \card{S_1 \cap S_3} - \card{S_2 \cap S_3} \\
  & \quad + \card{S_1 \cap S_2 \cap S_3}
\end{align*}
%
Remarkably, the expression on the right accounts for each element in the
union of $S_1$, $S_2$ and $S_3$ exactly once.  For example, suppose that
$x$ is an element of all three sets.  Then $x$ is counted three times (by
the $\card{S_1}$, $\card{S_2}$ and $\card{S_3}$ terms), subtracted off
three times (by the $\card{S_1 \cap S_2}$, $\card{S_1 \cap S_3}$ and
$\card{S_2 \cap S_3}$ terms), and then counted once more (by the
$\card{S_1 \cap S_2 \cap S_3}$ term).  The net effect is that $x$ is
counted just once.

So we can't answer the original question without knowing the sizes of
the various intersections.  Let's suppose that there are:
%
\begin{center}
\begin{tabular}{cl}
4 & Math - EECS double majors \\
3 & Math - Physics double majors \\
11 & EECS - Physics double majors \\
2 & triple majors
\end{tabular}
\end{center}
%
Then $\card{M \cap E} = 4 + 2$, $\card{M \cap P} = 3 + 2$, $\card{E
\cap P} = 11 + 2$, and $\card{M \cap E \cap P} = 2$.  Plugging all this
into the formula gives:
%
\begin{align*}
\card{M \cup E \cup P}
    & = \card{M} + \card{E} + \card{P}
      - \card{M \cap E} - \card{M \cap P} - \card{E \cap P}
      + \card{M \cap E \cap P} \\
    & = 60 + 200 + 40 - 6 - 5 - 13 + 2 \\
    & = 278
\end{align*}

\subsubsection{Sequences with 42, 04, or 60}

In how many permutations of the set $\set{0, 1, 2, \dots, 9}$ do
either 4 and 2, 0 and 4, or 6 and 0 appear consecutively?  For
example, none of these pairs appears in:
%
\[
(7, 2, 9, 5, 4, 1, 3, 8, 0, 6)
\]
%
The 06 at the end doesn't count; we need 60.  On the other hand, both
04 and 60 appear consecutively in this permutation:
%
\[
(7, 2, 5, \underline{6}, \underline{0}, \underline{4}, 3, 8, 1, 9)
\]
%
Let $P_{42}$ be the set of all permutations in which 42 appears; define
$P_{60}$ and $P_{04}$ similarly.  Thus, for example, the permutation above
is contained in both $P_{60}$ and $P_{04}$.  In these terms, we're looking
for the size of the set $P_{42} \cup P_{04} \cup P_{60}$.

First, we must determine the sizes of the individual sets, such as
$P_{60}$.  We can use a trick: group the 6 and 0 together as a single
symbol.  Then there is a natural bijection between permutations of
$\set{0, 1, 2, \dots 9}$ containing 6 and 0 consecutively and
permutations of:
%
\[
\set{60, 1, 2, 3, 4, 5, 7, 8, 9}
\]
%
For example, the following two sequences correspond:
%
\[
(7, 2, 5, \underline{6}, \underline{0}, 4, 3, 8, 1, 9)
\qquad \leftrightarrow \qquad
(7, 2, 5, \underline{60}, 4, 3, 8, 1, 9)
\]
%
There are $9!$ permutations of the set containing 60, so
$\card{P_{60}} = 9!$ by the Bijection Rule.  Similarly, $\card{P_{04}}
= \card{P_{42}} = 9!$ as well.

Next, we must determine the sizes of the two-way intersections, such
as $P_{42} \cap P_{60}$.  Using the grouping trick again, there is a
bijection with permutations of the set:
%
\[
\set{42, 60, 1, 3, 5, 7, 8, 9}
\]
%
Thus, $\card{P_{42} \cap P_{60}} = 8!$.  Similarly, $\card{P_{60} \cap
P_{04}} = 8!$ by a bijection with the set:
%
\[
\set{604, 1, 2, 3, 5, 7, 8, 9}
\]
%
And $\card{P_{42} \cap P_{04}} = 8!$ as well by a similar argument.
Finally, note that $\card{P_{60} \cap P_{04} \cap P_{42}} = 7!$ by a
bijection with the set:
%
\[
\set{6042, 1, 3, 5, 7, 8, 9}
\]

Plugging all this into the formula gives:
%
\begin{align*}
\card{P_{42} \cup P_{04} \cup P_{60}}
    & = 9! + 9! + 9! - 8! - 8! - 8! + 7!
\end{align*}

\subsection{Union of \emph{n} Sets}

The size of a union of $n$ sets is given by the following rule.

\begin{mathrule}[\idx{Inclusion-Exclusion}]
\[
\card{S_1 \cup S_2 \cup \cdots \cup S_n} = 
\]
%
\centerline{\begin{tabular}[t]{rl}
 & the sum of the sizes of the individual sets \\
\textit{minus} & the sizes of all two-way intersections \\
\textit{plus} & the sizes of all three-way intersections \\
\textit{minus} & the sizes of all four-way intersections \\
\textit{plus} & the sizes of all five-way intersections, etc.
\end{tabular}}
\end{mathrule}

The formulas for unions of two and three sets are special cases of this
general rule.

This way of expressing Inclusion-Exclusion is easy to understand and
nearly as precise as expressing it in mathematical symbols, but we'll need
the symbolic version below, so let's work on deciphering it now.

We already have a standard notation for the sum of sizes of the individual
sets, namely,
\[
\sum_{i=1}^n \card{S_i}.
\]
A ``two-way intersection'' is a set of the form $S_i \intersect S_j$ for
$i \neq j$.  We regard $S_j \intersect S_i$ as the same two-way
intersection as $S_i \intersect S_j$, so we can assume that $i < j$.  Now
we can express the sum of the sizes of the two-way intersections as
\[
\sum_{1\leq i < j \leq n} \card{S_i \intersect S_j}.
\]
Similarly, the sum of the sizes of the three-way intersections is
\[
\sum_{1\leq i < j < k \leq n} \card{S_i \intersect S_j \intersect S_k}.
\]
These sums have alternating signs in the Inclusion-Exclusion formula, with
the sum of the $k$-way intersections getting the sign $(-1)^{k-1}$.  This
finally leads to a symbolic version of the rule:

\begin{mathrule*}[Inclusion-Exclusion]
\begin{align*}
\card{\lgunion_{i=1}^n S_i} 
   = & \sum_{i=1}^n \card{S_i}\\
     & - \sum_{1\leq i < j \leq n} \card{S_i \intersect S_j}\\
     &  + \sum_{1\leq i < j < k \leq n} \card{S_i \intersect S_j
       \intersect S_k} + \cdots\\
     & + (-1)^{n-1} \card{\lgintersect_{i=1}^n S_i}.
\end{align*}
\end{mathrule*}

\begin{staffnotes}

\subsubsection*{Counting Primes}

How many of the numbers $1, 2, \dots, 100$ are \idx{prime}?  One way to
answer this question is to test each number up to 100 for primality and
keep a count.  This requires considerable effort.  (Is 57 prime?  How
about 67?)

Another approach is to use the \idx{Inclusion-Exclusion Principle}.  This
requires one trick: to determine the number of primes, we will first count
the number of {\em non-primes}.  By the Sum Rule, we can then find the
number of primes by subtraction from 100.  This trick of ``counting the
complement'' is a good one to remember.

\subsubsection*{Reduction to a Union of Four Sets}

The set of non-primes in the range $1, \dots, 100$ consists of the set,
$C$, of composite numbers in this range: $4, 6, 8, 9, \dots, 99, 100$ and
the number 1, which is neither prime nor composite.  The main job is to
determine the size of the set $C$ of composite numbers.  For this purpose,
define $A_m$ to be the set of numbers in the range $m+1, \dots, 100$ that
are divisible by $m$:
\[
A_m \eqdef \set{x \leq 100 \suchthat x > m \text{ and } \paren{m \divides x}}
\]

For example, $A_2$ is all the even numbers from 4 to 100.  The following
Lemma will now allow us to compute the cardinality of $C$ by using
Inclusion-Exclusion for the union of four sets:

\begin{lemma}
\[
C = A_2 \cup A_3 \cup A_5 \cup A_7.
\]
\end{lemma}

\begin{proof}
We prove the two sets equal by showing that each contains the other.

To show that $A_2 \cup A_3 \cup A_5 \cup A_7 \subseteq C$, let $n$ be an
element of $A_2 \cup A_3 \cup A_5 \cup A_7$.  Then $n \in A_m$ for $m = 2,
3, 5$ or $7$.  This implies that $n$ is in the range $1, \dots, 100$ and
is composite because it has $m$ as a factor.  That is, $n \in C$.

Conversely, to show that $C \subseteq A_2 \cup A_3 \cup A_5 \cup A_7$, let
$n$ be an element of $C$.  Then $n$ is a composite number in the range $1,
\dots, 100$.  This means that $n$ has at least two prime factors.  Now if
both prime factors are $> 10$, then their product would be a number $>
100$ which divided $n$, contradicting the fact that $n<100$.  So $n$ must
have a prime factor $\leq 10$.  But 2, 3, 5, and 7 are the only primes
$\leq 10$.  This means that $n$ is an element of $A_2$, $A_3$, $A_5$ or
$A_7$, and so $n \in A_2 \cup A_3 \cup A_5 \cup A_7$.
\end{proof}

\subsubsection*{Computing the Cardinality of the Union}

Now it's easy to find the cardinality of each set $A_m$: every $m$th
integer is divisible by $m$, so the number of integers in the range $1,
\dots, 100$ that are divisible by $m$ is simply $\floor{100/m}$.  So
\[
\card{A_m} = \floor{\frac{100}{m}} - 1,
\]
where the $-1$ arises because we defined $A_m$ to exclude $m$ itself.
This formula gives:

\begin{eqnarray*}
\card{A_2} & = \lfloor\frac{100}{2}\rfloor - 1 = & 49 \\
\card{A_3} & = \lfloor\frac{100}{3}\rfloor - 1 = & 32 \\
\card{A_5} & = \lfloor\frac{100}{5}\rfloor - 1 = & 19 \\
\card{A_7} & = \lfloor\frac{100}{7}\rfloor - 1 = & 13
\end{eqnarray*}

Notice that these sets $A_2$, $A_3$, $A_5$ and $A_7$ are not disjoint.
For example, 6 is in both $A_2$ and $A_3$.  Since the sets intersect, we
must use the Inclusion-Exclusion Principle:

\begin{align*}
\card{C}
  = & \card{A_2 \cup A_3 \cup A_5 \cup A_7} \\
  = & \card{A_2} + \card{A_3} + \card{A_5} + \card{A_7} \\
    & - \card{A_2 \cap A_3} - \card{A_2 \cap A_5} - \card{A_2 \cap A_7}
             - \card{A_3 \cap A_5} - \card{A_3 \cap A_7} - \card{A_5 \cap A_7} \\
    & + \card{A_2 \cap A_3 \cap A_5} + \card{A_2 \cap A_3 \cap A_7}
             + \card{A_2 \cap A_5 \cap A_7} + \card{A_3 \cap A_5 \cap A_7} \\
    & - \card{A_2 \cap A_3 \cap A_5 \cap A_7}
\end{align*}

There are a lot of terms here!  Fortunately, all of them are easy to
evaluate.  For example, $\card{A_3 \cap A_7}$ is the number of multiples
of $3 \cdot 7 = 21$ in the range 1 to 100, which is $\floor{100/21} = 4$.
\iffalse (Note that there is no reason to subtract 1 as we did when
evaluating $\card{A_m}$ above.)\fi Substituting such values for all of the
terms above gives:
\begin{align*}
\card{C}  = & 49 + 32 + 19 + 13 \\
            & - 16 - 10 - 7 - 6 - 4 - 2 \\
            & + 3 + 2 + 1 + 0 \\
            & - 0 \\
          = & 74
\end{align*}

This calculation shows that there are 74 composite numbers in the
range 1 to 100.  Since the number 1 is neither composite nor prime,
there are $100 - 74 - 1 = 25$ primes in this range.

At this point it may seem that checking each number from 1 to 100 for
primality and keeping a count of primes might have been easier than using
Inclusion-Exclusion.  However, the Inclusion-Exclusion approach used here
is asymptotically faster as the range of numbers grows large.

\textcolor{blue}{
The naive strategy requires $n$ runs of a primality test if the upper
bound is $n$.  The Inclusion-Exclusion approach seems to require
summing an immense number of terms, but fewer than $n$ of these are
non-zero and the rest can be ignored.
}
\end{staffnotes}


\subsection{Computing Euler's Function}

We will now use Inclusion-Exclusion to calculate Euler's function,
$\phi(n)$.  By definition, $\phi(n)$ is the number of nonnegative integers
less than a positive integer $n$ that are relatively prime to $n$.  But
the set $S$ of nonnegative integers less than $n$ that are \emph{not}
relatively prime to $n$ will be easier to count.

Suppose the prime factorization of $n$ is $p_1^{e_1}\cdots p_m^{e_m}$
for distinct primes $p_i$.  This means that the integers in $S$ are
precisely the nonnegative integers less than $n$ that are divisible by at
least one of the $p_i$'s.  So, letting $C_i$ be the set of nonnegative
integers less than $n$ that are divisible by $p_i$, we have
\[
S = \lgunion_{i=1}^m C_i.
\]

We'll be able to find the size of this union using Inclusion-Exclusion
because the intersections of the $C_i$'s are easy to count.  For example,
$C_1 \intersect C_2 \intersect C_3$ is the set of nonnegative integers less
than $n$ that are divisible by each of $p_1$, $p_2$ and $p_3$.  But since
the $p_i$'s are distinct primes, being divisible by each of these primes is
that same as being divisible by their product.  Now observe that if $r$ is
a positive divisor of $n$, then exactly $n/r$ nonnegative integers less
than $n$ are divisible by $r$, namely, $0,r,2r,\dots,((n/r)-1)r$.  So
exactly $n/p_1p_2p_3$ nonnegative integers less than $n$ are divisible by
all three primes $p_1$, $p_2$, $p_3$.  In other words,
\[
\card{C_1 \intersect C_2 \intersect C_3} = \frac{n}{p_1p_2p_3}.
\]

So reasoning this way about all the intersections among the $C_i$'s and
applying Inclusion-Exclusion, we get
\begin{align*}
\card{S}
  & = \card{\lgunion_{i=1}^m C_i}\\
  & = \sum_{i=1}^m \card{C_i} - \sum_{1\leq i < j \leq m} \card{C_i \intersect C_j}
       + \sum_{1\leq i < j < k \leq m} \card{C_i \intersect C_j \intersect C_k} -
       \cdots + (-1)^{m-1} \card{\lgintersect_{i=1}^m C_i}\\
  & = \sum_{i=1}^m \frac{n}{p_i} -
      \sum_{1\leq i < j \leq m} \frac{n}{p_ip_j}
       + \sum_{1\leq i < j < k \leq m} \frac{n}{p_ip_jp_k} - \cdots
        + (-1)^{m-1} \frac{n}{p_1p_2\cdots p_n}\\
  & = n\paren{\sum_{i=1}^m \frac{1}{p_i} -
      \sum_{1\leq i < j \leq m} \frac{1}{p_ip_j}
       + \sum_{1\leq i < j < k \leq m} \frac{1}{p_ip_jp_k} - \cdots
        + (-1)^{m-1} \frac{1}{p_1p_2\cdots p_n}}
\end{align*}
But $\phi(n)=n-\card{S}$ by definition, so
\begin{align}
  \phi(n) & = n\paren{1 - \sum_{i=1}^m \frac{1}{p_i} +  \sum_{1\leq i < j \leq m} \frac{1}{p_ip_j}
    - \sum_{1\leq i < j < k \leq m} \frac{1}{p_ip_jp_k} + \cdots
    + (-1)^m\frac{1}{p_1p_2\cdots p_n}}\notag\\
          &  = n \prod_{i=1}^m \paren{1 - \frac{1}{p_i}}.\label{inex-phi}
\end{align}

Notice that in case $n = p^k$ for some prime $p$ then~\eqref{inex-phi}
simplifies to
\[
\phi(p^k) = p^k\paren{1-\frac{1}{p}} = p^k - p^{k-1}
\]
as claimed in chapter~\ref{number_theory_chap}.

\textbf{Quick Question}:  Why does equation~\eqref{inex-phi} 
imply that
\[
\phi(ab) = \phi(a)\phi(b)
\]
for relatively prime integers $a,b>1$, as claimed in
Theorem~\ref{th:phi}.(a)?

\begin{problems}
\practiceproblems
\pinput{MQ_sick_days}

\classproblems
\pinput{CP_inclusion-exclusion_passwords}

\homeworkproblems
\pinput{PS_path_counting}
\pinput{PS_derangement}
\pinput{PS_inclusion-exclusion_primes}

\end{problems}

\iffalse

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Grand Scheme for Counting}

The rules and techniques we've covered to this point snap together
into an overall scheme for solving elementary counting problems.  Here
it is:

\textbox{
\textboxtitle{Grand Scheme for Counting}

\begin{enumerate}

\item Learn to count sequences using two techniques:

\begin{itemize}

\item the General Product Rule

\item the BOOKKEEPER formula

\end{itemize}

\item Translate everything else to a sequence-counting problem via:

\begin{itemize}

\item bijections

\item $k$-to-1 functions

\end{itemize}

\item But for unions of sets, use Inclusion-Exclusion.

\end{enumerate}
}

Everything here should be familiar to you by now, except for the
BOOKKEEPER formula, which you'll see in recitation tomorrow.
\fi

\hyperdef{bin}{omial}{\section{Binomial Theorem}}\label{binomial_theorem_sec}

Counting gives insight into one of the basic theorems of algebra.  A
\term{binomial} is a sum of two terms, such as $a + b$.  Now consider its
fourth power $(a + b)^4$.

If we multiply out this 4th power expression completely, we get
\[\begin{array}{rccccccccc}
(a + b)^4
   & = &    & aaaa & + & aaab & + & aaba & + & aabb \\
   &   &  + & abaa & + & abab & + & abba & + & abbb \\
   &   &  + & baaa & + & baab & + & baba & + & babb \\
   &   &  + & bbaa & + & bbab & + & bbba & + & bbbb
\end{array}\]
Notice that there is one term for every sequence of $a$'s and $b$'s.  So
there are $2^4$ terms, and the number of terms with $k$ copies of $b$ and
$n - k$ copies of $a$ is:
\[
\frac{n!}{k!\ (n-k)!} = \binom{n}{k}
\]
by the Bookkeeper Rule.  Now let's group equivalent terms, such as
$aaab = aaba = abaa = baaa$.  Then the coefficient of $a^{n-k} b^k$ is
$\binom{n}{k}$.  So for $n = 4$, this means:
\[
(a + b)^4 =
    \binom{4}{0} \cdot a^4 b^0 + 
    \binom{4}{1} \cdot a^3 b^1 + 
    \binom{4}{2} \cdot a^2 b^2 + 
    \binom{4}{3} \cdot a^1 b^3 + 
    \binom{4}{4} \cdot a^0 b^4
\]
In general, this reasoning gives the Binomial Theorem:

\begin{theorem}[\idx{Binomial Theorem}]
For all $n \in \mathbb{N}$ and $a, b \in \mathbb{R}$:
%
\[
(a + b)^n = \sum_{k=0}^n \binom{n}{k} a^{n-k} b^k
\]
\end{theorem}

The expression $\dbinom{n}{k}$ is often called a ``\idx{binomial
  coefficient}'' in honor of its appearance here.

This reasoning about binomials extends nicely to \term{multinomials},
which are sums of two or more terms.  For example, suppose we wanted
the coefficient of
%
\[
b o^2 k^2 e^3 p r
\]
%
in the expansion of $(b + o + k + e + p + r)^{10}$.  Each term in this
expansion is a product of 10 variables where each variable is one of
$b$, $o$, $k$, $e$, $p$ or $r$.  Now, the coefficient of $b o^2 k^2
e^3 p r$ is the number of those terms with exactly 1 $b$, 2 $o$'s, 2
$k$'s, 3 $e$'s, 1 $p$, and 1 $r$.  And the number of such terms is
precisely the number of rearrangments of the word BOOKKEEPER:
\[
\binom{10}{1,2,2,3,1,1} = \frac{10!}{1!\ 2!\ 2!\ 3!\ 1!\ 1!}.
\]
The expression on the left is called a ``multinomial coefficient.''  This
reasoning extends to a general theorem.

\begin{definition}
For $n,k_1,\dots,k_m \in naturals$, such that $k_1+k_2+\cdots+k_m = n$,
define the \term{multinomial coefficient}
\[
\binom{n}{k_1, k_2, \dots, k_m} \eqdef \frac{n!}{k_1!\, k_2!\, \dots k_m!}.
\]
\end{definition}

\begin{theorem}[Multinomial Theorem]\label{multinom-thm}
For all $n \in \mathbb{N}$ and $z_1, \dots z_m \in \mathbb{R}$:
\[
(z_1 + z_2 + \cdots + z_m)^n =
   \sum_{\substack{k_1, \dots, k_m \in \mathbb{N} \\
                   k_1 + \cdots + k_m = n}}
   \binom{n}{k_1, k_2, \dots, k_m} z_1^{k_1} z_2^{k_2} \cdots z_m^{k_m} 
\]
\end{theorem}
You'll be better off remembering the reasoning behind the Multinomial
Theorem rather than this ugly formal statement.

\begin{problems}

\practiceproblems
\pinput{MQ_binomial_coef}

\classproblems
\pinput{CP_binom_coeff}
\pinput{CP_multinomial_fermat}

\homeworkproblems
\pinput{PS_more_numbered_trees}

\end{problems}


\hyperdef{combinatorial}{proof}{\section{Combinatorial Proof}}\label{combinatorial_proof_sec}

Suppose you have $n$ different T-shirts, but only want to keep $k$.
You could equally well select the $k$ shirts you want to keep or
select the complementary set of $n - k$ shirts you want to throw out.
Thus, the number of ways to select $k$ shirts from among $n$ must be
equal to the number of ways to select $n - k$ shirts from among $n$.
Therefore:
%
\[
\binom{n}{k} = \binom{n}{n-k}
\]
%
This is easy to prove algebraically, since both sides are equal to:
%
\[
\frac{n!}{k!\ (n-k)!}
\]
%
But we didn't really have to resort to algebra; we just used counting
principles.

Hmm.

\subsection{Boxing}

Jay, famed 6.042 TA, has decided to try out for the US Olympic
boxing team.  After all, he's watched all of the \emph{Rocky} movies
and spent hours in front of a mirror sneering, ``Yo, you wanna piece
a' \emph{me}?!''  Jay figures that $n$ people (including himself)
are competing for spots on the team and only $k$ will be selected.  As
part of maneuvering for a spot on the team, he needs to work out how
many different teams are possible.  There are two cases to consider:

\begin{itemize}
  
\item Jay \emph{is} selected for the team, and his $k - 1$
  teammates are selected from among the other $n - 1$ competitors.
  The number of different teams that can be formed in this way is:
%
\[
\binom{n-1}{k-1}
\]

\item Jay is \emph{not} selected for the team, and all $k$ team
members are selected from among the other $n - 1$ competitors.  The
number of teams that can be formed this way is:
%
\[
\binom{n - 1}{k}
\]

\end{itemize}

All teams of the first type contain Jay, and no team of the second
type does; therefore, the two sets of teams are disjoint.  Thus, by
the Sum Rule, the total number of possible Olympic boxing teams is:
%
\[
\binom{n-1}{k-1} + \binom{n - 1}{k}
\]

Jeremy, equally-famed 6.042 TA, thinks Jay isn't so tough and so
he might as well also try out.  He reasons that $n$ people (including
himself) are trying out for $k$ spots.  Thus, the number of ways to
select the team is simply:
%
\[
\binom{n}{k}
\]

Jeremy and Jay each correctly counted the number of possible boxing
teams; thus, their answers must be equal.  So we know:
%
\[
\binom{n-1}{k-1} + \binom{n - 1}{k} = \binom{n}{k}
\]
%
This is called \term{Pascal's Identity}.  And we proved it
\emph{without any algebra!}  Instead, we relied purely on counting
techniques.

\subsection{Finding a Combinatorial Proof}

A \term{combinatorial proof} is an argument that establishes an
algebraic fact by relying on counting principles.  Many such proofs
follow the same basic outline:
%
\begin{enumerate}

\item Define a set $S$.

\item Show that $\card{S} = n$ by counting one way.

\item Show that $\card{S} = m$ by counting another way.

\item Conclude that $n = m$.

\end{enumerate}
%
In the preceding example, $S$ was the set of all possible Olympic boxing
teams.  Jay computed
\[
\card{S} = \binom{n-1}{k-1} + \binom{n-1}{k}
\]
by counting one way, and Jeremy computed
\[
\card{S} = \binom{n}{k}
\]
by counting another.  Equating these two expressions gave Pascal's
Identity.

More typically, the set $S$ is defined in terms of simple sequences or
sets rather than an elaborate story.  Here is less colorful example of a
combinatorial argument.

\begin{theorem}
\label{th:comb-ex}
\[
\sum_{r=0}^n \binom{n}{r} \binom{2n}{n-r} = \binom{3n}{n}
\]
\end{theorem}

\begin{proof}
We give a combinatorial proof.  Let $S$ be all $n$-card hands that can
be dealt from a deck containing $n$ red cards (numbered $1, \dots,
n$) and $2n$ black cards (numbered $1, \dots, 2n$).  First, note that
every $3n$-element set has
%
\[
\card{S} = \binom{3n}{n}
\]
%
$n$-element subsets.

From another perspective, the number of hands with exactly $r$ red
cards is
%
\[
\binom{n}{r} \binom{2n}{n - r}
\]
%
since there are $\binom{n}{r}$ ways to choose the $r$ red cards and
$\binom{2n}{n - r}$ ways to choose the $n - r$ black cards.  Since the
number of red cards can be anywhere from 0 to $n$, the total number of
$n$-card hands is:
%
\[
\card{S} = \sum_{r=0}^n \binom{n}{r} \binom{2n}{n-r}
\]
%
Equating these two expressions for $\card{S}$ proves the theorem.
\end{proof}

Combinatorial proofs are almost magical.  Theorem~\ref{th:comb-ex}
looks pretty scary, but we proved it without any algebraic
manipulations at all.  The key to constructing a combinatorial proof
is choosing the set $S$ properly, which can be tricky.  Generally, the
simpler side of the equation should provide some guidance.  For
example, the right side of Theorem~\ref{th:comb-ex} is
$\binom{3n}{n}$, which suggests choosing $S$ to be all $n$-element
subsets of some $3n$-element set.

\begin{problems}
\classproblems
\pinput{CP_multinomial_theorem}

\homeworkproblems
\pinput{CP_combination_identity}
\pinput{PS_combinatorial_proof}
\pinput{PS_multinomial_theorem}
\pinput{PS_com_proof}

\end{problems}
\endinput
