% \input{latex-macros/handout-preamble.tex}
% \inhandout{
% \lecturenotes{2}{Logic} 
% }

\newcommand{\solves}{\text{Solves}}
\newcommand{\probs}{\text{Probs}}
\newcommand{\even}{\text{Evens}}
\newcommand{\primes}{\text{Primes}}


\hyperdef{propform}{english}{\section{Propositional Formulas}}

It can be amazing that people manage to communicate in the English
language.  Here are some sentences that illustrate the issue:
%
\begin{enumerate}
\item ``You may have cake, or you may have ice cream.''
\item ``If pigs can fly, then you can understand the Chebyshev bound.''
\item ``If you can solve any problem we come up with, then you get an
  \emph{A} for the course.''
\item ``Every American has a dream.''
\end{enumerate}
%
What \textit{precisely} do these sentences mean?  Can you have both cake
and ice cream or must you choose just one dessert?  If the second sentence
is true, then is the Chebyshev bound incomprehensible?  If you can solve
some problems we come up with but not all, then do you get an \emph{A} for
the course?  And can you still get an \emph{A} even if you can't solve any
of the problems?  Does the last sentence imply that all Americans have the
same dream or might some of them have different dreams?

Some uncertainty is tolerable in normal conversation.  But when we need to
formulate ideas precisely ---as in mathematics and programming ---the
ambiguities inherent in everyday language can be a real problem.  We can't
hope to make an exact argument if we're not sure exactly what the
statements mean.  So before we start into mathematics, we need to
investigate the problem of how to talk about mathematics.

To get around the ambiguity of English, mathematicians have devised a
special mini-language for talking about logical relationships.  This
language mostly uses ordinary English words and phrases such as ``or'',
``implies'', and ``for all''.  But mathematicians endow these words with
definitions more precise than those found in an ordinary dictionary.
Without knowing these definitions, you might sometimes get the gist of
statements in this language, but you would regularly get misled about what
they really meant.

Surprisingly, in the midst of learning the language of logic, we'll
come across the most important open problem in computer science ---a
problem whose solution could change the world.

\subsection{Combining Propositions}

In English, we can modify, combine, and relate propositions with words
such as ``not'', ``and'', ``or'', ``implies'', and ``if-then''.
For example, we can combine three propositions into one like this:
%
\begin{center}
\textbf{If} all humans are mortal \textbf{and} all Greeks are human,
\textbf{then} all Greeks are mortal.
\end{center}

For the next while, we won't be much concerned with the internals of
propositions ---whether they involve mathematics or Greek mortality ---but
rather with how propositions are combined and related.  So we'll
frequently use variables such as $P$ and $Q$ in place of specific
propositions such as ``All humans are mortal'' and ``$2 + 3 = 5$''.  The
understanding is that these variables, like propositions, can take on only
the values \true ~(true) and \false ~(false).  Such true/false variables are
sometimes called \term{Boolean variables} after their inventor, George
---you guessed it ---Boole.

\subsubsection{``Not'', ``And'', and ``Or''}

We can precisely define these special words using \term{truth tables}.
For example, if $P$ denotes an arbitrary proposition, then the
truth of the proposition ``not $P$'' is defined by the following
truth table:
%
\[
\begin{array}{c|c}
P & \text{not $P$} \\ \hline
\true & \false \\
\false & \true \\
\end{array}
\]
%
The first row of the table indicates that when proposition $P$ is true,
the proposition ``not $P$'' is false.  The second line indicates that
when $P$ is false, ``not $P$'' is true.  This is probably what you would
expect.

In general, a truth table indicates the true/false value of a
proposition for each possible setting of the variables.  For example,
the truth table for the proposition ``$P$ and $Q$'' has four lines,
since the two variables can be set in four different ways:
%
\[
\begin{array}{cc|c}
P & Q & \text{$P$ and $Q$} \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \false
\end{array}
\]
%
According to this table, the proposition ``$P$ and $Q$'' is true only when
$P$ and $Q$ are both true.  This is probably the way you think about the
word ``and.''

There is a subtlety in the truth table for ``$P$ or $Q$'':
%
\[
\begin{array}{cc|c}
P & Q & \text{$P$ or $Q$} \\ \hline
\true & \true & \true \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]
%
This says that ``$P$ or $Q$'' is true when $P$ is true, $Q$ is true, or
\textit{both} are true.  This isn't always the intended meaning of ``or''
in everyday speech, but this is the standard definition in mathematical
writing.  So if a mathematician says, ``You may have cake, or you may have
ice cream,'' he means that you \textit{could} have both.

\subsubsection{``Implies''}

The least intuitive connecting word is ``implies.''  Here is its truth
table, with the lines labeled so we can refer to them later.
%
\[
\begin{array}{cc|cr}
    P  &   Q    & \parbox[b]{13ex}{$P$ implies $Q$} \\ \hline
\true  & \true  & \true & \text{(tt)}\\
\true  & \false & \false  & \text{(tf)}\\
\false & \true  & \true  & \text{(ft)}\\
\false & \false & \true  & \text{(ff)}
\end{array}
\]

Let's experiment with this definition.  For example, is the following
proposition true or false?
%
\begin{center}
``If Goldbach's Conjecture is true, then $x^2 \geq 0$ for every real
number $x$.''
\end{center}
%
Now, we told you before that no one knows whether Goldbach's Conjecture is
true or false.  But that doesn't prevent you from answering the question!
This proposition has the form $P \implies Q$ where the \term{hypothesis},
$P$, is ``Goldbach's Conjecture is true'' and the \term{conclusion}, $Q$.
is ``$x^2 \geq 0$ for every real number $x$''.  Since the conclusion is
definitely true, we're on either line~(tt) or line~(ft) of the truth
table.  Either way, the proposition as a whole is \textit{true}!

One of our original examples demonstrates an even stranger side of
implications.
%
\begin{center}
``If pigs fly, then you can understand the Chebyshev bound.''
\end{center}
%
Don't take this as an insult; we just need to figure out whether this
proposition is true or false.  Curiously, the answer has \textit{nothing}
to do with whether or not you can understand the Chebyshev bound.  Pigs do
not fly, so we're on either line (ft) or line (ff) of the truth table.  In
both cases, the proposition is \textit{true}!

In contrast, here's an example of a false implication:
%
\begin{center}
``If the moon shines white, then the moon is made of white cheddar.''
\end{center}
%
Yes, the moon shines white.  But, no, the moon is not made of white
cheddar cheese.  So we're on line (tf) of the truth table, and the
proposition is false.

The truth table for implications can be summarized in words as
follows:
%
\begin{center}
\textit{An implication is true exactly when the if-part is false or the
then-part is true.}
\end{center}
%
This sentence is worth remembering; a large fraction of all
mathematical statements are of the if-then form!

\subsubsection{``If and Only If''}

Mathematicians commonly join propositions in one additional way that
doesn't arise in ordinary speech.  The proposition ``$P$ if and only
if $Q$'' asserts that $P$ and $Q$ are logically equivalent; that is,
either both are true or both are false.
%
\[
\begin{array}{cc|c}
P & Q & P \qiff Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \true
\end{array}
\]
%
The following if-and-only-if statement is true for every real number
$x$:
%
\begin{center}
``$x^2 - 4 \geq 0$ iff $|x| \geq 2$''
\end{center}
%
For some values of $x$, \textit{both} inequalities are true.  For
other values of $x$, \textit{neither} inequality is true .  In every
case, however, the proposition as a whole is true.

\subsection{Propositional Logic in Computer Programs}

Propositions and logical connectives arise all the time in computer
programs.  For example, consider the following snippet, which could be
either C, C++, or Java:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || (x <= 0 \&\& y > 100) )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}
%
The symbol \texttt{||} denotes ``or'', and the symbol \texttt{\&\&}
denotes ``and''.  The \textit{further instructions} are carried out
only if the proposition following the word \texttt{if} is true.  On
closer inspection, this big expression is built from two simpler
propositions.  Let $A$ be the proposition that \texttt{x > 0}, and let
$B$ be the proposition that \texttt{y > 100}.  Then we can rewrite the
condition this way:
%
\hyperdef{AAB}{snippet}{
\begin{equation}\label{ANAB}
A \text{ or } ((\text{not } A) \text{ and } B)
\end{equation}}
%
A truth table reveals that this complicated expression is logically
equivalent to 
\begin{equation}\label{AOB}
A \text{ or } B.
\end{equation}
%
\[
\begin{array}{cc|c|c}
A & B &
    A \text{ or } ((\text{not } A) \text{ and } B) &
    A \text{ or } B \\ \hline
\true & \true & \true & \true \\
\true & \false & \true & \true \\
\false & \true & \true & \true \\
\false & \false & \false & \false
\end{array}
\]
%
This means that we can simplify the code snippet without changing the
program's behavior:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || y > 100 )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}

The equivalence of~\eqref{ANAB} and~\eqref{AOB} can also be confirmed
reasoning by cases:
\begin{itemize}
\item[$A$ is \true.]  Then an expression of the form $(A \text{ or }
  \text{anything})$ will have truth value \true.  Since both expressions
  are of this form, both have the same truth value in this case, namely,
  \true.

\item[$A$ is \false.]  Then $(A \text{ or } P)$ will have the same truth
  value as $P$ for any proposition, $P$.  So~\eqref{AOB} has the same
  truth value as $B$.  Similarly,~\eqref{ANAB} has the same truth value as
  $((\text{not } \false) \text{ and } B)$, which also has the same value
  as $B$.  So in this case, both expressions will have the same truth
  value, namely, the value of $B$.
\end{itemize}

Rewriting a logical expression involving many variables in the
simplest form is both difficult and important.  Simplifying
expressions in software might slightly increase the speed of your
program.  But, more significantly, chip designers face essentially the
same challenge.  However, instead of minimizing \texttt{\&\&} and
\texttt{||} symbols in a program, their job is to minimize the number
of analogous physical devices on a chip.  The payoff is potentially
enormous: a chip with fewer devices is smaller, consumes less power,
has a lower defect rate, and is cheaper to manufacture.

\subsection{A Cryptic Notation}

Programming languages use symbols like $\&\&$ and $!$ in place of
words like ``and'' and ``not''.  Mathematicians have devised their own
cryptic symbols to represent these words, which are summarized in the
table below.
%
\begin{center}
\begin{tabular}{ll}
\textbf{English} & \textbf{Cryptic Notation} \\[1ex]
not $P$ & $\neg P$ \quad (alternatively, $\overline{P}$) \\
$P$ and $Q$ & $P \wedge Q$ \\
$P$ or $Q$ & $P \vee Q$ \\
$P$ implies $Q$ & $P \implies Q$ \\
if $P$ then $Q$ & $P \implies Q$ \\
$P \qiff Q$ & $P \iff Q$
\end{tabular}
\end{center}
%
For example, using this notation, ``If $P$ and not $Q$, then $R$''
would be written:
%
\[
(P \wedge \neg Q) \implies R
\]

This symbolic language is helpful for writing complicated logical
expressions compactly.  But words such as ``or'' and ``implies,'' whose
meaning is easy to remember, serve just as well as the symbols such as
$\vee$ and $\implies$.  So we'll use this symbolic language sparingly, and
we advise you to do the same.

\subsection{Logically Equivalent Implications}

Do these two sentences say the same thing?
%
\begin{center}
If I am hungry, then I am grumpy. \\
If I am not grumpy, then I am not hungry.
\end{center}
%
We can settle the issue by recasting both sentences in terms of
propositional logic.  Let $P$ be the proposition ``I am hungry'', and
let $Q$ be ``I am grumpy''.  The first sentence says ``$P$ implies
$Q$'' and the second says ``(not $Q$) implies (not $P$)''.  We can
compare these two statements in a truth table:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    \text{$P$ implies $Q$} &
    \text{(not $Q$) implies (not $P$)} \\ \hline
\true & \true & \true & \true \\
\true & \false & \false & \false \\
\false & \true & \true & \true \\
\false & \false & \true & \true
\end{array}
\]
%
Sure enough, the columns of truth values under these two statements are
the same, which precisely means they are equivalent.  In general, ``(not
$Q$) implies (not $P$)'' is called the \term{contrapositive} of ``$P$
implies $Q$.''  And, as we've just shown, the two are just different ways
of saying the same thing.

In contrast, the \term{converse} of ``$P$ implies $Q$'' is the
statement ``$Q$ implies $P$''.  In terms of our example, the converse
is:
%
\begin{center}
If I am grumpy, then I am hungry.
\end{center}
%
This sounds like a rather different contention, and a truth table
confirms this suspicion:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    \text{$P$ implies $Q$} &
    \text{$Q$ implies $P$} \\ \hline
\true & \true & \true & \true \\
\true & \false & \false & \true \\
\false & \true & \true & \false \\
\false & \false & \true & \true
\end{array}
\]
%
Thus, an implication \textit{is} logically equivalent to its
contrapositive but is \textit{not} equivalent to its converse.

One final relationship: an implication and its converse together are
equivalent to an iff statement, specifically, to these two statements
together.  For example,
%
\begin{center}
If I am grumpy, then I am hungry. \\
If I am hungry, then I am grumpy.
\end{center}
%
are equivalent to the single statement:
%
\begin{center}
I am grumpy iff I am hungry.
\end{center}
%
Once again, we can verify this with a truth table:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    \text{($P$ implies $Q$) and ($Q$ implies $P$)} &
    Q \qiff P \\ \hline
\true & \true & \true & \true \\
\true & \false & \false & \false \\
\false & \true & \false & \false \\
\false & \false & \true & \true
\end{array}
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\floatingtextbox{
\textboxtitle{SAT}

A proposition is \textbf{satisfiable} if some setting of the variables
makes the proposition true.  For example, $P \wedge \neg Q$ is
satisfiable because the expression is true when $P$ is true and $Q$ is
false.  On the other hand, $P \wedge \neg P$ is not satisfiable
because the expression as a whole is false for both settings of $P$.
But determining whether or not a more complicated proposition is
satisfiable is not so easy.  How about this one?
%
\[
(P \vee Q \vee R) \wedge (\neg P \vee \neg Q)
                  \wedge (\neg P \vee \neg R)
                  \wedge (\neg R \vee \neg Q)
\]

The general problem of deciding whether a proposition is satisfiable
is called \term{SAT}.  One approach to SAT is to construct a truth
table and check whether or not a $\true$ ever appears.  But this
approach is not very efficient; a proposition with $n$ variables has a
truth table with $2^n$ lines.  For a proposition with just 30
variables, that's already over a billion!

Is there an \textit{efficient} solution to SAT?  In other words, is there
some, possibly very ingenious, procedure that \textit{quickly} determines
whether any given proposition is satifiable or not?  No one knows.  And an
awful lot hangs on the answer.  An efficient solution to SAT would
immediately imply efficient solutions to many, many other important
problems involving packing, scheduling, routing, and circuit verification,
among other things.  This would be wonderful, but there would also be
worldwide chaos.  Decrypting coded messages would also become an easy task
(for most codes).  Online financial transactions would be insecure and
secret communications could be read by everyone.

At present, though, researchers are completely stuck.  No one has a good
idea how to either solve SAT more efficiently or to prove that no
efficient solution exists.  This is the outstanding unanswered question in
theoretical Computer Science.}

\section{Logical Deductions }

Logical deductions or \emph{inference rules} are used to prove new
propositions using previously proved ones.

A fundamental inference rule is \emph{modus ponens}.  This rule says that
a proof of $P$ together with a proof of $P \implies Q$ is a proof of
$Q$.

Inference rules are sometimes written in a funny notation.  For example,
\emph{modus ponens} is written:
\begin{rul*}
\Rule{P, \quad P \implies Q}{Q}
\end{rul*}

When the statements above the line, called the \emph{antecedents}, are
proved, then we can consider the statement below the line, called the
\emph{conclusion} or \emph{consequent}, to also be proved.

A key requirement of an inference rule is that it must be \emph{sound}: any
assignment of truth values that makes all the antecedents true must also
make the consequent true.  So if we start off with true axioms and apply
sound inference rules, everything we prove will also be true.

There are many other natural, sound inference rules, for example:
\begin{rul*}
\Rule{P \implies Q, \quad Q \implies R}{P \implies R}
\end{rul*}

\begin{rul*}
\Rule{\neg{P} \implies Q, \quad \neg{Q}}{P}
\end{rul*}

\begin{rul*}
\Rule{\neg{P} \implies \neg{Q}}{Q \implies P}
\end{rul*}

On the other hand,
\begin{rul*}
\Rule{\neg{P} \implies \neg{Q}}{P \implies Q}
\end{rul*}
is not sound: if $P$ is assigned $\true$ and $Q$ is assigned $\false$, then
the antecedent is true and the consequent is not.

\begin{notesproblem}
Prove that a propositional inference rule is sound iff the conjunction
(AND) of all its antecedents implies its consequent.
\end{notesproblem}

As with axioms, we will not be too formal about the set of legal inference
rules.  Each step in a proof should be clear and ``logical''; in
particular, you should state what previously proved facts are used to
derive each new conclusion.

\hyperdef{preds}{preds}{\section{Predicates}}

A \term{predicate} is a proposition whose truth depends on the value of
one or more variables.  For example,
%
\begin{center}
``$n$ is a perfect square''
\end{center}
%
is a predicate whose truth depends on the value of $n$.  The predicate
is true for $n = 4$ since four is a perfect square, but false for $n =
5$ since five is not a perfect square.

Like other propositions, predicates are often named with a letter.
Furthermore, a function-like notation is used to denote a predicate
supplied with specific variable values.  For example, we might name
our earlier predicate $P$:
%
\[
P(n) \eqdef \text{``$n$ is a perfect square''}
\]
%
Now $P(4)$ is true, and $P(5)$ is false.

This notation for predicates is confusingly similar to ordinary function
notation.  If $P$ is a predicate, then $P(n)$ is either \textit{true} or
\textit{false}, depending on the value of $n$.  On the other hand, if $p$
is an ordinary function, like $n^2 + 1$, then $p(n)$ is a
\textit{numerical quantity}.  \textbf{Don't confuse these two!}

\subsection{Quantifying a Predicate}

There are a couple of assertions commonly made about a predicate: that it
is \textit{sometimes} true and that it is \textit{always} true.  For
example, the predicate
%
\[
\text{``$x^2 \geq 0$''}
\]
%
is always true when $x$ is a real number.  On the other hand, the
predicate
%
\[
\text{``$5x^2 - 7 = 0$''}
\]
%
is only sometimes true; specifically, when $x = \pm \sqrt{7/5}$.

There are several ways to express the notions of ``always true'' and
``sometimes true'' in English.  The table below gives some general
formats on the left and specific examples using those formats on the
right.  You can expect to see such phrases hundreds of times in
mathematical writing!
%
\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{c}{\textbf{Always True}} \\[1ex]
For all $n$, $P(n)$ is true. & For all $x$, $x^2 \geq 0$. \\
$P(n)$ is true for every $n$. & $x^2 \geq 0$ for every $x$. \\[2ex]
\multicolumn{2}{c}{\textbf{Sometimes True}} \\[1ex]
There exists an $n$ such that $P(n)$ is true. & There exists an $x$ such that $5x^2 - 7 = 0$.\\
$P(n)$ is true for some $n$. & $5x^2 - 7 = 0$ for some $x$.\\
$P(n)$ is true for at least one $n$. & $5x^2-7=0$ for at least one $x$.
\end{tabular}
\end{center}

All these sentences quantify how often the predicate is true.
Specifically, an assertion that a predicate is always true is called a
\term{universal} quantification, and an assertion that a predicate is
sometimes true is an \term{existential} quantification.  Sometimes the
English sentences are unclear with respect to quantification:
%
\begin{center}
  ``If you can solve any problem we come up with, then you get an \emph{A}
  for the course.''
\end{center}
%
The phrase ``you can solve any problem we can come up with'' could
reasonably be interpreted as either a universal or existential
quantification:
%
\begin{quote}
``you can solve \textit{every} problem we come up with,''
\end{quote}
or maybe
\begin{quote}
``you can solve \textit{at least one} problem we come up with.''
\end{quote}
%
In any case, notice that this quantified phrase appears inside a
larger if-then statement.  This is quite normal; quantified statements
are themselves propositions and can be combined with and, or, implies,
etc., just like any other proposition.

\subsection{More Cryptic Notation}

There are symbols to represent universal and existential
quantification, just as there are symbols for ``and'' ($\wedge$),
``implies'' ($\implies$), and so forth.  In particular, to say that a
predicate, $P$, is true for all values of $x$ in some set, $D$, one
writes:
%
\[
\forall x \in D.\; P(x)
\]
%
The symbol $\forall$ is read ``for all'', so this whole expression is
read ``for all $x$ in $D$, $P(x)$ is true''.  To say that a predicate
$P(x)$ is true for at least one value of $x$ in $D$, one writes:
%
\[
\exists x \in D.\; P(x)
\]
%
The backward-E is read ``there exists''.  So this expression would be
read, ``There exists an $x$ in $D$ such that $P(x)$ is true.''  The
symbols $\forall$ and $\exists$ are always followed by a variable
---usually with an indication of the set the variable ranges over ---and
then a predicate, as in the two examples above.

As an example, let $\probs$ be the set of problems we come up with,
$\solves(x)$ be the predicate ``You can solve problem $x$'', and $G$ be
the proposition, ``You get an \emph{A} for the course.''  Then the two
different interpretations of
%
\begin{quote}
``If you can solve any problem we come up with, then you get an \emph{A} for the course.''
\end{quote}
%
can be written as follows:
%
\[
(\forall x \in \probs.\; \solves(x)) \implies G,
\]
or maybe
\[
(\exists x \in \probs.\; \solves(x)) \implies G.
\]

\subsection{Mixing Quantifiers}

Many mathematical statements involve several quantifiers.  For
example, Goldbach's Conjecture states:
%
\begin{center}
``Every even integer greater than 2 is the sum of two primes.''
\end{center}
%
Let's write this more verbosely to make the use of quantification
clearer:
%
\begin{quote}
For every even integer $n$ greater than 2,
there exist primes $p$ and $q$ such that $n = p + q$.
\end{quote}
%
Let $\even$ be the set of even integers greater than 2, and let $\primes$ be the
set of primes.  Then we can write Goldbach's Conjecture in logic
notation as follows:
%
\[
\underbrace{\forall n \in \even}_{\substack
    {\text{for every even} \\
     \text{integer $n > 2$}}}
\
\underbrace{\exists p \in \primes\ \exists q \in \primes.}_{\substack
    {\text{there exist primes} \\
     \text{$p$ and $q$ such that}}}
\ n = p + q.
\]

\subsection{Order of Quantifiers}

Swapping the order of different kinds of quantifiers (existential or
universal) usually changes the meaning of a proposition.  For example, let's return to one of our initial, confusing statements:
\begin{center}
``Every American has a dream.''
\end{center}

This sentence is ambiguous because the order of quantifiers is
unclear.  Let $A$ be the set of Americans, let $D$ be the set of
dreams, and define the predicate $H(a, d)$ to be ``American $a$ has
dream $d$.''.  Now the sentence could mean there is a single dream
that every American shares:
\[
\exists\, d \in D\; \forall a \in A.\; H(a, d)
\]
For example, it might be that every American shares the dream of owning
their own home.

Or it could mean that every American has a personal dream:
\[
\forall a \in A\; \exists\, d \in D.\; H(a, d)
\]
For example, some Americans may dream of a peaceful retirement, while
others dream of continuing practicing their profession as long as they
live, and still others may dream of being so rich they needn't think at
all about work.

Swapping quantifiers in Goldbach's Conjecture creates a patently false
statement that every even number $\geq 2$ is the sum of \emph{the same}
two primes:
\[
\underbrace{\exists\, p \in \primes\ \exists\, q \in \primes}_{\substack
    {\text{there exist primes} \\
     \text{$p$ and $q$ such that}}}
\
\underbrace{\forall n \in \even.}_{\substack
    {\text{for every even} \\
     \text{integer $n > 2$}}}
\ n = p + q.
\]

\subsubsection{Variables over One Domain}
When all the variables in a formula are understood to take values from the
same nonempty set, $D$, it's conventional to omit mention of $D$.  For
example, instead of $\forall x \in D\; \exists y \in D.\; Q(x,y)$ we'd write
$\forall x \exists y.\; Q(x,y)$.  The unnamed nonempty set that $x$ and
$y$ range over is called the \term{domain} of the formula.

It's easy to arrange for all the variables to range over one domain.  For
example, Goldbach's Conjecture could be expressed with all variables
ranging over the domain $\naturals$ as
\[
\forall n.\; n \in \even \implies (\exists\, p \exists\, q.\; p \in \primes \land
q \in \primes \land n = p + q).
\]

\subsection{Negating Quantifiers}

There is a simple relationship between the two kinds of quantifiers.  The
following two sentences mean the same thing:
%
\begin{quote}

It is not the case that everyone likes to snowboard.

There exists someone who does not like to snowboard.

\end{quote}
%
In terms of logic notation, this follows from a general property of
predicate formulas:
%
\[
\neg \forall x.\; P(x)
\hspace{0.1in} \text{is equivalent to} \hspace{0.1in}
\exists x.\; \neg P(x).
\]
%
Similarly, these sentences mean the same thing:
%
\begin{quote}
There does not exist anyone who likes skiing over magma.

Everyone dislikes skiing over magma.
\end{quote}
%
We can express the equivalence in logic notation this way:
%
\begin{equation}\label{nE}
(\neg \exists x.\; P(x))  \iff \forall x.\; \neg P(x).
\end{equation}
%
The general principle is that \textit{moving a ``not'' across a
quantifier changes the kind of quantifier.}

\iffalse Logicians have worked very hard to define strict rules for the
use of logic notation so that ideas can be expressed with absolute rigor.
It's all quite charming and clever.  However, the sad irony is that
applied mathematicans usually use their beloved notation as a crude
shorthand, breaking the rules and abusing the notation willy-nilly ---sort
of like pounding nails with fine china.  \fi

\subsection{Validity}

A propositional formula is called \term{valid} when it evaluates to \true\
no matter what truth values are assigned to the individual propositional
variables.  For example, the propositional version of the Distributive Law
is that $P \conj (Q \disj R)$ is equivalent to $(P \conj Q) \disj (P \conj
R)$.  This is the same as saying that
\[
[P \conj (Q \disj R)] \iff [(P \conj Q) \disj (P \conj R)]
\]
is valid.

The same idea extends to predicate formulas, but to be valid, a
formula now must evaluate to true no matter what values its variables
may take over any unspecified domain, and no matter what
interpretation a predicate variable may be given.  For example, we
already observed that the rule for negating a quantifier is captured
by the valid assertion~\eqref{nE}.

Another useful example of a valid assertion is
\[
\exists x \forall y.\; P(x,y) \implies \forall y \exists x.\; P(x,y).
\]
We could prove this as follows:
\begin{proof}
Let $D$ be the domain for the variables and $P_0$ be some
binary predicate\footnote{That is, a predicate that depends on two variables.}
on $D$.  We need to show that if $\exists x \in D\; \forall y \in D.\;
P_0(x,y)$ holds under this interpretation, then so does $\forall y \in D\;
\exists x \in D.\; P_0(x,y)$.

So suppose $\exists x \in D\; \forall y \in D.\; P_0(x,y)$.  Then some
element $x_0 \in D$ has the property that $P_0(x_0, y)$ is true for all $y
\in D$.  So for every $y \in D$, there is some $x \in D$, namely $x_0$,
such that $P_0(x,y)$ is true.  That is, $\forall y \in D\exists x \in D.\;
P_0(x,y)$ holds; that is, $\forall y\; \exists x.\; P(x,y)$ holds under this
interpretation, as required.
\end{proof}

On the other hand,
\[
\forall y \exists x.\; P(x,y) \implies \exists x \forall y.\; P(x,y).
\]
is \emph{not} valid.  We can prove this simply by describing an
interpretation where the hypothesis, $\forall y \exists x.\; P(x,y)$, is
true but the conclusion, $\exists x \forall y.\; P(x,y)$, is not true.
For example, let the domain be the integers and $P(x,y)$ mean $x > y$.
Then the hypothesis would be true because, given a value, $n$, for $y$ we
could choose the value of $x$ to be $n+1$, for example.  But under this
interpretation the conclusion asserts that there is an integer that is
bigger than all integers, which is certainly false.  An interpetation like
this which falsifies an assertion is called a \emph{counter model} to the
assertion.

\newpage
\section{Glossary of Symbols}
\begin{center}
\begin{tabular}{ll}
symbol &  meaning\\
\hline
$\eqdef$ & is defined to be\\
$\land$ & and\\
$\lor$ & or\\
$\implies$ & implies\\
$\neg$    & not\\
$\neg{P}$ & not $P$\\
$\bar{P}$ & not $P$\\
$\iff$    & iff\\
$\iff$    & equivalent\\
$\oplus$   & xor\\
$\exists$ & exists\\
$\forall$ & for all\\
$\in$   &  is a member of\\

\iffalse

$\subseteq$ & is a subset of\\
$\subset$ & is a proper subset of\\
$\union$  & set union\\
$\intersect$ & set intersection\\
$\bar{A}$ & complement of a set, $A$\\
$\power(A)$ & powerset of a set, $A$\\
$\emptyset$ & the empty set, $\set{}$\\
$\naturals$ & nonnegative integers \\
$\integers$ & integers\\
$\integers^+$ & positive integers\\
$\integers^-$ & negative integers\\
$\rationals$ & rational numbers\\
$\reals$ & real numbers\\
$\complexes$ & complex numbers\\
$\emptystring$ & the empty string/list
\fi

\end{tabular}
\end{center}

\endinput

