\part{Probability}
\label{part:probability}

\partintro

Probability is one of the most important disciplines in all of the
sciences.  It is also one of the least well understood.

Probability is especially important in computer science---it arises in
virtually every branch of the field.  In algorithm design and game
theory, for example, \term{randomized} algorithms and strategies
(those that use a random number generator as a key input for decision
making) frequently outperform deterministic algorithms and
strategies.  In information theory and signal processing, an
understanding of randomness is critical for filtering out noise and
compressing data.  In cryptography and digital rights management,
probability is crucial for achieving security.  The list of examples
is long.

Given the impact that probability has on computer science, it seems
strange that probability should be so misunderstood by so many.
Perhaps the trouble is that basic human intuition is wrong as often as
it is right when it comes to problems involving random events.  As a
consequence, many students develop a fear of probability.  Indeed, we
have witnessed many graduate oral exams where a student will solve the
most horrendous calculation, only to then be tripped up by the simplest
probability question.  Indeed, even some faculty will start squirming
if you ask them a question that starts ``What is the probability
that\dots?''

Our goal in the remaining chapters is to equip you with the tools that
will enable you to easily and confidently solve problems involving
probability.

We begin in Chapter~\ref{probability_chap} with the basic definitions
and an elementary 4-step process that can be used to determine the
probability that a specified event occurs.  We illustrate the method
on two famous problems where your intuition will probably fail you.

In Chapter~\ref{chap:cond_prob}, we describe conditional probability and
the notion of independence.  Both notions are important, and sometimes
misused, in practice.  We will consider the probability of having a
disease given that you tested positive, and the probability that a
suspect is guilty given that his blood type matches the blood found at
the scene of the crime.

We study random variables and distributions in
Chapter~\ref{ran_var_chap}.  Random variables provide a more
quantitative way to measure random events.  For example, instead of
determining the probability that it will rain, we may want to
determine \emph{how much} or \emph{how long} it is likely to rain.
This is closely related to the notion of the expected value of a
random variables, which we will consider in
Chapter~\ref{chap:expectation}.

In Chapter~\ref{chap:deviations}, we examine the probability that a
random variable deviates significantly from its expected value.  This
is especially important in practice, where things are generally fine
if they are going according to expectation, and you would like to be
assured that the probability of deviating from the expectation is very
low.

We conclude in Chapter~\ref{ran_process_chap} by combining the tools
we have acquired to solve problems involving more complex random
processes.  We will see why you will probably never get very far ahead
at the casino, and how two Stanford graduate students became
gazillionaires by combining graph theory and probability theory to
design a better search engine for the web.

\endinput
