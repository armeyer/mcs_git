\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{FP_murphys_law}
  \pcomment{variant of CP_murphys_law}
\end{pcomments}

\pkeywords{
  murphy
  mutually_independent
  independent
  indicator
  sum
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
In this problem you will check a proof of:
\begin{theorem*}[Murphy's Law]
Let $A_1, A_2, \dots A_n$ be mutually independent events, and let $T$ be
the number of these events that occur.  The probability that none of the
events occur is at most $e^{-\expect{T}}$.
\end{theorem*}

To prove Murphy's Law, note that
\begin{equation}\label{Tsum}
T = T_1 + T_2 + \dots + T_n,
\end{equation}
where $T_i$ is the indicator variable for the event $A_i$.

For each line of the following proof, write the number from the list
below of the item that justifies the line.

\begin{proof}
\begin{align*}
\pr{T = 0}
  & = \bar{A_1 \union A_2 \union \cdots \union A_n} \qquad\qquad\underline{\quad\eqref{defT}\quad}\\
  & =  \pr{\bar{A_1} \cap \bar{A_2} \cap \dots \cap \bar{A_n}}\qquad\insolutions{\eqref{DeM}}\examrule[0.5in]\\
  & =  \prod_{i=1}^n \pr{\bar{A_i}}\qquad\qquad\qquad\quad\insolutions{\eqref{MutInd}}\examrule[0.5in]\\
  & =  \prod_{i=1}^n 1 - \pr{A_i}\qquad\qquad\quad\insolutions{\eqref{Compl}}\examrule[0.5in]\\
  & \leq  \prod_{i=1}^n e^{-\pr{A_i}}\qquad\qquad\qquad\insolutions{\eqref{1+xex}}\examrule[0.5in]\\
  & =  e^{-\sum_{i=1}^n \pr{A_i}}\qquad\quad\qquad\insolutions{\eqref{ExpAlg}}\examrule[0.5in]\\
  & =  e^{-\sum_{i=1}^n \expect{T_i}}\qquad\qquad\quad\insolutions{\eqref{ExpInd}}\examrule[0.5in]\\
  & =  e^{-\expect{T}}.\qquad\qquad\qquad\qquad\insolutions{\eqref{LinExp}}\examrule[0.5in]
\end{align*}
\end{proof}

\begin{center}
\textbf{Justification}
\end{center}

\begin{enumerate}[(i)]
\item\label{defT} def. of $[T=0]$
\item Union bound
\item\label{} pairwise independence
\item\label{MutInd} mutual independence
\item\label{LinExp} linearity of $\expect{}$
\item\label{ExpInd} expectation of an indicator
\item distributivity
\item\label{DeM} De Morgan's law
\item\label{Compl} complement rule
\item\label{} Chebyshev inequality
\item\label{} $1 - x \leq e^{-x}$ for all $x$
\item\label{1+xex} $1 + x \leq e^x$ for $\abs{x} \leq 1$
\item\label{} $1+x = o(e^{x})$
\item\label{ExpAlg} exponent algebra
\end{enumerate}

\iffalse
\begin{solution}

\begin{proof}
\begin{align*}
\pr{T = 0}
  & = \bar{A_1 \union A_2 \union \cdots \union A_n} & \text{(def. of $T$)}\\
  & =  \pr{\bar{A_1} \cap \bar{A_2} \cap \dots \cap \bar{A_n}} &
          \text{(De Morgan's law)}\\
  & =  \prod_{i=1}^n \pr{\bar{A_i}} & \text{(mutual independence of $A_i$'s)}\\
  & =  \prod_{i=1}^n 1 - \pr{A_i} & \text{(complement rule)}\\
  & \leq  \prod_{i=1}^n e^{-\pr{A_i}} & \text{(by~(\ref{1+xeleq}))}\\
  & =  e^{-\sum_{i=1}^n \pr{A_i}} & \text{(exponent algebra)}\\
  & =  e^{-\sum_{i=1}^n \expect{T_i}} & (\expect{I_A}=\prob{A})\\
  & =  e^{-\expect{T}}. & \text{(by~\eqref{Tsum} \& linearity of $\expect{}$)}
\end{align*}
\end{proof}

\end{solution}
\fi

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
 
