\chapter{Random Variables and Distributions}\label{ran_var_chap}

Thus far, we have focused on probabilities of \idx{events}.  For
example, we computed the probability that you win the Monty Hall game,
or that you have a rare medical condition given that you tested
positive.  But, in many cases we would like to more more.  For
example, \emph{how many} contestants must play the Monty Hall game
until one of them finally wins?  \emph{How long} will this condition
last?  \emph{How much} will I lose gambling with strange dice all
night?  To answer such questions, we need to work with random
variables.

\section{Definitions and Examples}\label{ran_var_examples_sec}

\begin{definition}
  A \term{random variable}~$R$ on a probability space is a total function
  whose domain is the sample space.
\end{definition}
The codomain of $R$ can be anything, but will usually be a subset of
the real numbers.  Notice that the name ``random variable'' is a
misnomer; random variables are actually functions!

For example, suppose we toss three independent\footnote{Going forward,
  when we talk about flipping independent coins, we will assume that
  they are \emph{mutually} independent.}, unbiased coins.  Let $C$ be the
number of heads that appear.  Let $M = 1$ if the three coins come up
all heads or all tails, and let $M = 0$ otherwise.  Every outcome of
the three coin flips uniquely determines the values of $C$ and $M$.
For example, if we flip heads, tails, heads, then $C = 2$ and $M = 0$.
If we flip tails, tails, tails, then $C = 0$ and $M = 1$.  In effect,
$C$ counts the number of heads, and $M$ indicates whether all the
coins match.

Since each outcome uniquely determines $C$ and $M$, we can regard them
as functions mapping outcomes to numbers.  For this experiment, the
sample space is
\begin{equation*}
    \sspace = \set{ HHH, HHT, HTH, HTT, THH, THT, TTH, TTT }
\end{equation*}
and $C$~is a function that maps each outcome in the sample space to a
number as follows:
\begin{align*}
C(HHH) & = 3 &  C(THH) & =  2 \\
C(HHT) & = 2 &  C(THT) & =  1 \\
C(HTH) & = 2 &  C(TTH) & =  1 \\
C(HTT) & = 1 &  C(TTT) & =  0.
\end{align*}
Similarly, $M$ is a function mapping each outcome another way:
\begin{align*}
M(HHH) & = 1 & M(THH) & =  0 \\
M(HHT) & = 0 & M(THT) & =  0 \\
M(HTH) & = 0 & M(TTH) & =  0 \\
M(HTT) & = 0 & M(TTT) & =  1.
\end{align*}
So $C$ and $M$ are \idx{random variables}.

\subsection{Indicator Random Variables}

An \term{indicator random variable} is a random variable that maps
every outcome to either 0 or~1.  Indicator random variables are also
called \term{Bernoulli variables}.  The random variable~$M$ is an
example.  If all three coins match, then $M=1$; otherwise, $M = 0$.

Indicator random variables are closely related to events.  In
particular, an indicator random variable partitions the sample space
into those outcomes mapped to~1 and those outcomes mapped to~0.  For
example, the indicator $M$ partitions the sample space into two blocks
as follows:
\[
\underbrace{HHH \quad TTT}_{\text{$M = 1$}} \quad
\underbrace{HHT \quad HTH \quad HTT \quad
        THH \quad THT \quad TTH}_{\text{$M = 0$}}.
\]

In the same way, an event~$E$ partitions the sample space into those
outcomes in $E$ and those not in $E$.  So $E$ is naturally associated with
an indicator random variable, \index{$I_E$, indicator for event $E$}
$I_E$, where $I_E(w) = 1$ for outcomes $w \in E$ and $I_E(w) = 0$ for
outcomes $w \notin E$.  Thus, $M=I_E$ where $E$ is the event that all
three coins match.

\subsection{Random Variables and Events}

There is a strong relationship between events and more general random
variables as well.  A random variable that takes on several values
partitions the sample space into several blocks.  For example, $C$
partitions the sample space as follows:
\[
\underbrace{TTT}_{\text{$C = 0$}} \quad
\underbrace{TTH \quad THT \quad HTT}_{\text{$C = 1$}} \quad
\underbrace{THH \quad HTH \quad HHT}_{\text{$C = 2$}} \quad
\underbrace{HHH}_{\text{$C = 3$}}.
\]
Each block is a subset of the sample space and is therefore
an event.  Thus, we can regard an equation or inequality involving a
random variable as an event.  For example, the event that $C = 2$
consists of the outcomes $THH$, $HTH$, and $HHT$.  The event $C \leq
1$ consists of the outcomes $TTT$, $TTH$, $THT$, and $HTT$.

Naturally enough, we can talk about the probability of events defined
by properties of random variables.  For example,
\begingroup
\openup2pt
\begin{align*}
\pr{C = 2}
        &=    \pr{THH} + \pr{HTH} + \pr{HHT} \\
        &=    \frac{1}{8} + \frac{1}{8} + \frac{1}{8} \\
        &=  \frac{3}{8}.
\end{align*}
\endgroup

As another example:
\begingroup\openup2pt
\begin{align*}
\pr{M = 1}
        &= \pr{TTT} + \pr{HHH}\\
        &= \frac{1}{8} + \frac{1}{8} \\
        &= \frac{1}{4}.
\end{align*}
\endgroup

\subsection{Functions of Random Variables}

Random variables can be combined to form other random variables.  For
example, suppose that you roll two unbiased, independent 6-sided
dice.  Let $D_i$~be the random variable denoting the outcome of the
$i$th~die for $i = 1$,~$2$.  For example,
\begin{equation*}
    \pr{D_1 = 3} = 1/6.
\end{equation*}
Then let $T = D_1 + D_2$. \ $T$~is also a random variable and it
denotes the sum of the two dice.  For example,
\begin{align*}
    \pr{T = 2} &= 1/36 \\
\noalign{\noindent and}
    \pr{T = 7} &= 1/6.
\end{align*}

Random variables can be combined in complicated ways, as we will see
in Chapter~\ref{chap:deviations}.  For example,
\begin{equation*}
    Y = e^T
\end{equation*}
is also a random variable.  In this case,
\begin{align*}
    \pr{Y = e^2} &= 1/36 \\
\noalign{\noindent and}
    \pr{Y = e^7} &= 1/6.
\end{align*}

\subsection{Conditional Probability}

Mixing conditional probabilities and events involving random variables
creates no new difficulties.  For example, $\prcond{C \geq 2}{M = 0}$
is the probability that at least two coins are heads ($C \geq 2$)
given that not all three coins are the same ($M = 0$).  We can compute
this probability using the definition of conditional probability:
\begingroup\openup2pt
\begin{align*}
\prcond{C \geq 2}{M = 0}
        & =    \frac{\pr{C \geq 2 \intersect M = 0}}{\pr{M = 0}} \\
        & =    \frac{\pr{\set{THH, HTH, HHT}}}
                        {\pr{\set{THH, HTH, HHT, HTT, THT, TTH }}} \\
        & =    \frac{3/8}{6/8} \\
        & = \frac{1}{2}.
\end{align*}
\endgroup The expression $C \geq 2 \intersect M = 0$ on
the first line may look odd; what is the set operation $\intersect$
doing between an inequality and an equality?  But recall that, in this
context, $C \geq 2$ and $M = 0$ are \emph{events}, and so
they are \emph{sets} of outcomes.

\subsection{Independence}

The notion of independence carries over from events to random variables as
well.  Random variables $R_1$ and $R_2$ are \index{independent random
  variables} \emph{independent} iff for all $x_1$ in the codomain of
$R_1$, and~$x_2$ in the codomain of~$R_2$ for which $\prob{R_2 = X_2}
> 0$, we have:
\[
\prcond{R_1 = x_1}{R_2 = x_2}  =  \pr{R_1 = x_1}.
\]
As with events, we can formulate independence for random variables in
an equivalent and perhaps more useful way: random variables $R_1$
and~$R_2$ are independent if for all $x_1$ and~$x_2$
\[
    \pr{R_1 = x_1 \cap R_2 = x_2}  =  \pr{R_1 = x_1} \cdot \pr{R_2 = x_2}.
\]

For example, are $C$ and~$M$ independent?  Intuitively, the answer
should be ``no''.  The number of heads, $C$, completely determines
whether all three coins match; that is, whether $M = 1$.  But, to
verify this intuition, we must find some $x_1, x_2 \in \reals$ such
that:
\[
\pr{C = x_1 \cap M = x_2} \neq \pr{C = x_1} \cdot \pr{M = x_2}.
\]
One appropriate choice of values is $x_1 = 2$ and $x_2 = 1$.
In this case, we have:
\[
    \pr{C = 2 \cap M = 1} = 0
\]
and
\begin{equation*}
    \pr{M = 1} \cdot \pr{C = 2} = \frac{1}{4} \cdot \frac{3}{8} \ne 0.
\end{equation*}
The first probability is zero because we never have exactly two heads
($C = 2$) when all three coins match ($M = 1$).  The other two
probabilities were computed earlier.

On the other hand, let $F$~be the indicator variable for the event
that the first flip is a Head, so
\[
\text{``$F = 1$''} = \set{HHH, HTH, HHT, HTT}.
\]
Then $F$~is independent of~$M$, since
\begin{equation*}
    \pr{M=1} = 1/4 = \prcond{M=1}{F=1} = \prcond{M=1}{F=0}
\end{equation*}
and
\begin{equation*}
    \pr{M=0} = 3/4 = \prcond{M=0}{F=1} = \prcond{M=0}{F=0}.
\end{equation*}
This example is an instance of a simple lemma:
\begin{lemma}
  Two events are independent iff their \idx{indicator variables} are
  independent.
\end{lemma}
As with events, the notion of independence generalizes to more than two
random variables.
\begin{definition}\label{def:RV_mutually_ind}
Random variables $R_1, R_2, \dots, R_n$ are \term{mutually independent} iff
\begin{align*}
\lefteqn{\pr{R_1 = x_1 \cap R_2 = x_2 \cap \cdots \cap R_n = x_n}}\\
        & =  \pr{R_1 = x_1} \cdot \pr{R_2 = x_2} \cdots \pr{R_n = x_n}.
\end{align*}
for all $x_1, x_2, \dots, x_n$.
\end{definition}

A consequence of Definition~\ref{def:RV_mutually_ind} is that the
probability that any \emph{subset} of the variables takes a particular
set of values is equal to the product of the probabilities that the
individual variables take their values.  Thus, for example, if $R_1,
R_2, \dots, R_{100}$ are mutually independent random variables, then
it follows that:
\begin{align*}
\lefteqn{\pr{R_1 = 7 \cap R_7 = 9.1 \cap R_{23} = \pi}}\qquad \\
& = \pr{R_1 = 7} \cdot \pr{R_7 = 9.1} \cdot \pr{R_{23} = \pi}.
\end{align*}
The proof is based on summing over all possible values for all of the
other random variables.

\section{Distribution Functions}\label{distributions_sec}

A random variable maps outcomes to values. Often, random variables
that show up for different spaces of outcomes wind up behaving in much
the same way because they have the same probability of having any
given value.  Hence, random variables on different probability spaces
may wind up having the same \term{probability density function}.

\begin{definition}
Let $R$ be a random variable with codomain $V$.
The \term{probability density function (pdf)} of $R$
is a function $\pdf_R : V \to [0,1]$ defined by:
%
\[
\pdf_R(x) \eqdef \begin{cases}
            \pr{R = x} & \text{if } x \in \range{R}\\
             0 & \text{if } x \notin \range{R}.
           \end{cases}
\]
\end{definition}
%
A consequence of this definition is that
%
\[
\sum_{x \in \range{R}} \pdf_R(x) = 1.
\]
This is because $R$~has a value for each outcome, so summing the
probabilities over all outcomes is the same as summing over the
probabilities of each value in the range of~$R$.

As an example, suppose that you roll two unbiased, independent,
6-sided dice.  Let $T$~be the random variable that equals the sum of
the two rolls.  This random variable takes on values in the set $V =
\set{2, 3, \dots, 12}$.  A plot of the probability density function
for~$T$ is shown in Figure~\ref{fig:16F2}: The lump in the middle
indicates that sums close to 7 are the most likely.  The total area of
all the rectangles is 1 since the dice must take on exactly one of the
sums in $V = \set{2, 3, \dots, 12}$.

\begin{figure}

\graphic{Figure_16F2}

\caption{The probability density function for the sum of two 6-sided
  dice.}

\label{fig:16F2}

\end{figure}

A closely-related concept to a~$\pdf$ is the \term{cumulative
  distribution function (cdf)} for a random variable whose codomain is
the real numbers.  This is a function $\cdf_R : \reals \to [0,1]$
defined by:
%
\[
    \cdf_R(x) = \pr{R \leq x}.
\]
%
As an example, the cumulative distribution function for the random
variable $T$ is shown in Figure~\ref{fig:16F3}:
%
\begin{figure}

\graphic{Figure_16F3}

\caption{The cumulative distribution function for the sum of two
  6-sided dice.}

\label{fig:16F3}

\end{figure}
%
The height of the $i$th bar in the cumulative distribution function
is equal to the \emph{sum} of the heights of the leftmost $i$ bars
in the probability density function.  This follows from the
definitions of pdf and~cdf:
%
\begin{align*}
\cdf_R(x) & = \pr{R \leq x} \\
          & = \sum_{y \leq x} \pr{R = y} \\
          & = \sum_{y \leq x} \pdf_R(y).
\end{align*}

In summary, $\pdf_R(x)$ measures the probability that $R = x$ and
$\cdf_R(x)$ measures the probability that $R \leq x$.  Both $\pdf_R$
and $\cdf_R$ capture the same information about the random variable
$R$---you can derive one from the other---but sometimes one is more
convenient.

One of the really interesting things about density functions and
distribution functions is that many random variables turn out to have
the \emph{same} pdf and~cdf.  In other words, even though $R$ and~$S$
are different random variables on different probability spaces, it is
often the case that
\begin{equation*}
    \pdf_R = \pdf_s.
\end{equation*}
In fact, some pdfs are so common that they are given special names.
For example, the three most important distributions in computer
science are the \term{Bernoulli distribution}, the \term{uniform
  distribution}, and the \term{binomial distribution}.  We look more
closely at these common distributions in the next several sections.

\section{Bernoulli Distributions}\label{sec:bernoulli_dist}

The Bernoulli distribution is the simplest and most common
distribution function.  That's because it is the distribution function
for an indicator random variable.  Specifically, the \term{Bernoulli
  distribution} has a probability density function of the form $f_p:
\set{0, 1} \to [0, 1]$ where
\begin{align*}
    f_p(0) &= p, \quad\text{and} \\
    f_p(1) &= 1 - p,
\end{align*}
for some $p \in [0, 1]$.  The corresponding cumulative distribution
function is $F_p: \reals \to [0, 1]$ where:
\begin{equation*}
F_{p}(x) =
    \begin{cases}
        0 & \text{if $x < 0$} \\
        p & \text{if $0 \le x < 1$} \\
        1 & \text{if $1 \le x$}. \\
    \end{cases}
\end{equation*}

\section{Uniform Distributions}\label{sec:uniform_dist}

\subsection{Definition}

A random variable that takes on each possible value with the same
probability is said to be \term{uniform}.  If the sample space
is~$\set{1, 2, \dots, n}$, then the \term{uniform distribution} has a
pdf of the form
\begin{equation*}
    f_n : \set{1, 2, \dots, n} \to [0,1]
\end{equation*}
where
\begin{equation*}
    f_n(k) = \frac{1}{n}
\end{equation*}
for some $n \in \naturals^+$.  The cumulative distribution function
is then $F_n: \reals \to [0, 1]$ where
\begin{equation*}
F_n(x) =
    \begin{cases}
        0 & \text{if $x < 1$} \\
        k/n & \text{if $k \le x < k + 1$ for $1 \le k < n$} \\
        1 & \text{if $n \le x$}. \\
    \end{cases}
\end{equation*}
Uniform distributions arise frequently in practice.  For example, the
number rolled on a fair die is uniform on the set $\set{1, 2, \dots,
  6}$.  If~$p = 1/2$, then an indicator random variable is uniform on
the set~$\set{0, 1}$.

\subsection{The Numbers Game}\label{bigger_number_subsec}

Enough definitions---let's play a game!  I have two envelopes.  Each
contains an integer in the range $0, 1, \dots, 100$, and the numbers
are distinct.  To win the game, you must determine which envelope
contains the larger number.  To give you a fighting chance, we'll let
you peek at the number in one envelope selected at random.  Can you
devise a strategy that gives you a better than 50\% chance of winning?

For example, you could just pick an envelope at random and guess that
it contains the larger number.  But this strategy wins only 50\% of
the time.  Your challenge is to do better.

So you might try to be more clever.  Suppose you peek in one envelope
and see the number~12.  Since 12~is a small number, you might guess
that that the number in the other envelope is larger.  But perhaps
we've been tricky and put small numbers in \emph{both} envelopes.
Then your guess might not be so good!

An important point here is that the numbers in the envelopes may
\emph{not} be random.  We're picking the numbers and we're choosing
them in a way that we think will defeat your guessing strategy.  We'll
only use randomization to choose the numbers if that serves our
purpose, which is to make you lose!

\subsubsection{Intuition Behind the Winning Strategy}

Amazingly, there is a strategy that wins more than 50\% of the time,
regardless of what numbers we put in the envelopes!

Suppose that you somehow knew a number~$x$ that was in between the
numbers in the envelopes.  Now you peek in one envelope and see a
number.  If it is bigger than~$x$, then you know you're peeking at the
higher number.  If it is smaller than $x$, then you're peeking at the
lower number.  In other words, if you know a number $x$ between the
numbers in the envelopes, then you are certain to win the game.

The only flaw with this brilliant strategy is that you do \emph{not}
know such an~$x$.  Oh well.

But what if you try to \emph{guess}~$x$?  There is some probability
that you guess correctly.  In this case, you win 100\% of the time.
On the other hand, if you guess incorrectly, then you're no worse off
than before; your chance of winning is still 50\%.  Combining these
two cases, your overall chance of winning is better than 50\%!

Informal arguments about probability, like this one, often sound
plausible, but do not hold up under close scrutiny.  In contrast, this
argument sounds completely implausible---but is actually correct!

\subsubsection{Analysis of the Winning Strategy}

For generality, suppose that we can choose numbers from the set
$\set{0, 1, \dots, n}$.  Call the lower number~$L$ and the higher
number~$H$.

Your goal is to guess a number $x$ between $L$ and $H$.  To avoid
confusing equality cases, you select $x$ at random from among the
half-integers:
%
\[
\Set{\frac{1}{2},\ 1\frac{1}{2},\ 2\frac{1}{2},\ \dots,\ n - \frac{1}{2}}
\]
%
But what probability distribution should you use?

The uniform distribution turns out to be your best bet.  An informal
justification is that if we figured out that you were unlikely to pick
some number---say $50\frac{1}{2}$---then we'd always put 50 and~51 in
the envelopes.  Then you'd be unlikely to pick an~$x$ between $L$
and~$H$ and would have less chance of winning.

After you've selected the number~$x$, you peek into an envelope and
see some number~$T$.  If~$T > x$, then you guess that you're looking
at the larger number.  If~$T < x$, then you guess that the other
number is larger.

All that remains is to determine the probability that this strategy
succeeds.  We can do this with the usual four step method and a tree
diagram.

\paragraph{Step 1: Find the sample space.}

You either choose~$x$ too low ($< L$), too high ($> H$), or just right
($L < x < H$).  Then you either peek at the lower number ($T = L$) or
the higher number ($T = H$).  This gives a total of six possible
outcomes, as show in Figure~\ref{fig:16F4}.

\begin{figure}[h]

\graphic{numbers-game}

\caption{The tree diagram for the numbers game.}

\label{fig:16F4}

\end{figure}

\paragraph{Step 2: Define events of interest.}

The four outcomes in the event that you win are marked in the tree
diagram.

\paragraph{Step 3: Assign outcome probabilities.}

First, we assign edge probabilities.  Your guess $x$ is too low with
probability $L/n$, too high with probability $(n-H)/n$, and just right
with probability $(H-L)/n$.  Next, you peek at either the lower or
higher number with equal probability.  Multiplying along root-to-leaf
paths gives the outcome probabilities.

\paragraph{Step 4: Compute event probabilities.}

The probability of the event that you win is the sum of the
probabilities of the four outcomes in that event:
%
\begin{align*}
\pr{\text{win}}
    & = \frac{L}{2n} + \frac{H-L}{2n} + \frac{H-L}{2n}  + \frac{n-H}{2n} \\
    & = \frac{1}{2} + \frac{H-L}{2n} \\
    & \geq \frac{1}{2} + \frac{1}{2n}
\end{align*}
%
The final inequality relies on the fact that the higher number $H$ is
at least 1 greater than the lower number $L$ since they are required
to be distinct.

Sure enough, you win with this strategy more than half the time,
regardless of the numbers in the envelopes!  For example, if I choose
numbers in the range $0, 1, \dots, 100$, then you win with probability at
least $\frac{1}{2} + \frac{1}{200} = 50.5\%$.  Even better, if I'm allowed
only numbers in the range $0, \dots, 10$, then your probability of
winning rises to 55\%!  By Las Vegas standards, those are great odds!

\subsection{Randomized Algorithms}

The best strategy to win the numbers game is an example of a
\term{randomized algorithm}---it uses random numbers to influence
decisions.  Protocols and algorithms that make use of random numbers
are very important in computer science.  There are many problems for
which the best known solutions are based on a random number generator.

For example, the most commonly-used protocol for deciding when to send
a broadcast on a shared bus or Ethernet is a randomized algorithm
known as \term{exponential backoff}.  One of the most commonly-used
sorting algorithms used in practice, called \term{quicksort}, uses
random numbers.  You'll see many more examples if you take an
algorithms course.  In each case, randomness is used to improve the
probability that the algorithm runs quickly or otherwise performs
well.

\section{Binomial Distributions}\label{binomial_distribution_section}

\subsection{Definitions}

The third commonly-used distribution in computer science is the
\term{binomial distribution}.  The standard example of a random
variable with a binomial distribution is the number of heads that come
up in $n$~independent flips of a coin.  If the coin is fair, then the
number of heads has an \term{unbiased binomial distribution},
specified by the pdf
\begin{equation*}
    f_n: \set{1, 2, \dots, n} \to [0, 1]
\end{equation*}
where
\begin{equation*}
    f_n(k) = \binom{n}{k} 2^{-n}
\end{equation*}
for some $n \in \naturals^+$.  This is because there are
$\binom{n}{k}$ sequences of $n$ coin tosses with exactly $k$ heads,
and each such sequence has probability $2^{-n}$.

A plot of~$f_{20}(k)$ is shown in Figure~\ref{fig:16F5}.  The most
likely outcome is $k = 10$ heads, and the probability falls off
rapidly for larger and smaller values of $k$.  The falloff regions to
the left and right of the main hump are called the \term{tails of the
  distribution}.  We'll talk a lot more about these tails shortly.

\begin{figure}

\graphic{Figure_16F5}

\caption{The pdf for the unbiased binomial distribution for $n =
  20$,~$f_{20}(k)$.}

\label{fig:16F5}

\end{figure}

The cumulative distribution function for the unbiased binomial
distribution is $F_n: \reals \to [0, 1]$ where
\begin{equation*}
F_n(x) =
    \begin{cases}
        0 & \text{if $x < 1$} \\
        \sum_{i = 0}^k \binom{n}{i} 2^{-n}
            & \text{if $k \le x < k + 1$ for $1 \le k < n$} \\
        1 & \text{if $n \le x$}.
    \end{cases}
\end{equation*}

\subsubsection{The General Binomial Distribution}

If the coins are biased so that each coin is heads with
probability~$p$, then the number of heads has a \term{general binomial
  density function} specified by the pdf
\begin{equation*}
    f_{n,p} : \set{1, 2, \dots, n} \to [0, 1]
\end{equation*}
where
\[
    f_{n, p}(k) = \binom{n}{k} p^k (1-p)^{n-k}.
\]
for some $n \in \naturals^+$ and $p \in [0, 1]$.  This is because
there are $\binom{n}{k}$ sequences with $k$ heads and $n - k$ tails,
but now the probability of each such sequence is $p^k (1-p)^{n-k}$.

For example, the plot in Figure~\ref{fig:16F7} shows the probability
density function $f_{n, p}(k)$ corresponding to flipping $n=20$
independent coins that are heads with probability $p = 0.75$.  The
graph shows that we are most likely to get $k = 15$ heads, as
you might expect.  Once again, the probability falls off quickly for
larger and smaller values of $k$.
%
\begin{figure}

\graphic{Fig_16F7}

\caption{The pdf for the general binomial distribution~$f_{n, p}(k)$
  for $n = 20$ and $p = .75$.}

\label{fig:16F7}

\end{figure}

The cumulative distribution function for the general binomial
distribution is~$F_{n, p}: \reals \to [0,1]$ where
\begin{equation}\label{eqn:16F5}
F_{n, p}(x) =
    \begin{cases}
        0 & \text{if $x < 1$} \\
        \sum_{i = 0}^k \binom{n}{i} p^i (1 - p)^{n - i}
          & \text{if $k \le x < k + 1$ for $1 \le k < n$} \\
        1 & \text{if $n \le x$}.
    \end{cases}
\end{equation}


\subsection{Approximating the Probability Density Function}

Computing the general binomial density function is daunting when $k$
and~$n$ are large.  Fortunately, there is an approximate closed-form
formula for this function based on an approximation for the binomial
coefficient.  In the formula below, $k$~is replaced by~$\alpha n$
where $\alpha$~is a number between 0 and~1.
%
\begin{lemma}\label{LN12:bincoeff-bound}
\begin{equation}\label{eqn:17BA}
\binom{n}{\alpha n}
        \sim \frac{2^{n H(\alpha)}}{\sqrt{2 \pi \alpha (1 - \alpha) n}}
\end{equation}
and
\begin{equation}\label{eqn:17A3}
\binom{n}{\alpha n} < \frac{ 2^{n H(\alpha)} }
                           { \sqrt{2 \pi \alpha (1 - \alpha) n} }
\end{equation}
where $H(\alpha)$ is the \term{entropy function}\footnote{$\log(x)$
  means $\log_2(x)$.}
\begin{equation*}
H(\alpha) \eqdef \alpha \log\paren{\frac{1}{\alpha}} +
                (1 - \alpha) \log\paren{\frac{1}{1 - \alpha}}.
\end{equation*}
Moreover, if $\alpha n > 10$ and $(1 - \alpha) n > 10$, then the left
and right sides of Equation~\ref{eqn:17BA} differ by at most~$2\%$.  If
$\alpha n > 100$ and $(1 - \alpha) n > 100$, then the difference is at
most~$0.2\%$.
\end{lemma}

The graph of~$H$ is shown in Figure~\ref{LN12:entropy}.

                                % GNUPLOT: LaTeX picture
\begin{figure}

\graphic{entropy}

\caption{The Entropy Function}
\label{LN12:entropy}

\end{figure}

Lemma~\eqref{LN12:bincoeff-bound} provides an excellent approximation
for binomial coefficients.  We'll skip its derivation, which consists
of plugging in Theorem~\ref{thm:stirling} for the factorials in the
binomial coefficient and then simplifying.

Now let's plug Equation~\ref{eqn:17BA} into the general binomial density
function.  The probability of flipping $\alpha n$~heads in $n$~tosses
of a coin that comes up heads with probability~$p$ is:
\begin{align}
f_{n, p}(\alpha n)
    &\sim \frac{ 2^{n H(\alpha)} p^{\alpha n} (1 - p)^{(1 - \alpha)n} }
            { \sqrt{2 \pi \alpha (1 - \alpha) n} } \notag\\[4pt]
    &= \frac{ 2^{n \left(\alpha \log\paren{\frac{p}{\alpha}}
                    + (1 - \alpha) \log\paren{\frac{1 - p}{1 - \alpha}}\right)} 
            }
            { \sqrt{2 \pi \alpha (1 - \alpha) n} }, \label{LN12:binbnd}
\end{align}
where the margin of error in the approximation is the same as in
Lemma~\ref{LN12:bincoeff-bound}.  From Equation~\ref{eqn:17A3}, we
also find that
\begin{equation}\label{eqn:17A4}
    f_{n, p}(\alpha n) < \frac{ 2^{n \paren{\alpha
        \log\paren{\frac{p}{\alpha}} + (1 - \alpha) \log\paren{\frac{1
          - p}{1 - \alpha}}}} }
                              { \sqrt{2 \pi \alpha (1 - \alpha) n} }.
\end{equation}

The formula in Equations~\ref{LN12:binbnd} and \ref{eqn:17A4} is as
ugly as a bowling shoe, but it's useful because it's easy to evaluate.
For example, suppose we flip a fair coin $n$ times.  What is the
probability of getting \emph{exactly} $pn$ heads?  Plugging $\alpha =
p$ into~Equation~\ref{LN12:binbnd} gives:
%
\begin{equation*}
f_{n, p}(pn)
    \sim \frac{1}{\sqrt{2 \pi p (1 - p) n} }.
\end{equation*}
%
Thus, for example, if we flip a fair coin (where $p = 1/2$) \ $n =
100$ times, the probability of getting exactly 50 heads is within~2\%
of~$0.079$, which is about~8\%.

\subsection{Approximating the Cumulative Distribution Function}

In many fields, including computer science, probability analyses come
down to getting small bounds on the \idx{tails} of the binomial
distribution.  In a typical application, you want to bound the tails
in order to show that there is very small probability that too many
\emph{bad} things happen.  For example, we might like to know that it
is very unlikely that too many bits are corrupted in a message, or
that too many servers or communication links become overloaded, or
that a randomized algorithm runs for too long.

So it is usually good news that the binomial distribution has small
tails.  To get a feel for their size, consider the probability of
flipping at most 25~heads in 100~independent tosses of a fair coin.

The probability of getting at most $\alpha n$~heads is given by
the binomial cumulative distribution function
\begin{equation}\label{LN12:Jsum}
F_{n, p}(\alpha n)
    = \sum_{i = 0}^{\alpha n} \binom{n}{i} p^i (1 - p)^{n - i}.
\end{equation}
We can bound this sum by bounding the ratio of successive terms.

In particular, for $i \le \alpha n$,
\begingroup
\openup3pt
\begin{align*}
\frac{ \displaystyle \binom{n}{i - 1} p^{i - 1} (1 - p)^{n - (i - 1)} }
     { \displaystyle \binom{n}{i}     p^i       (1 - p)^{n - i} }
    &=    \frac{\displaystyle
                  \frac{ n! p^{i - 1} (1 - p)^{n - i + 1} }
                       { (i - 1)! (n - i + 1) ! }
              }
              {\displaystyle
                  \frac{ n! p^i (1 - p)^{n - i} }
                       { i! (n - i)! }
              } \\
    &=    \frac{ i (1 - p) }{ (n - i + 1) p } \\
    &\le  \frac{ \alpha n (1 - p) }{ (n - \alpha n + 1) p } \\
    &\le  \frac{ \alpha (1 - p) }{ (1 - \alpha) p }.
\end{align*}
\endgroup
This means that for $\alpha < p$,
\begingroup
\openup3pt
\begin{align}
F_{n, p}(\alpha n)
    &<  f_{n, p}(\alpha n)
        \sum_{i = 0}^\infty \left[ \frac{\alpha(1 - p)}{(1 - \alpha)p}\right]^i
\notag \\
    &= \frac{\displaystyle f_{n, p}(\alpha n)}
            {\displaystyle 1 - \frac{\alpha (1 - p)}{(1 - \alpha)p}}
            \notag\\
    &= \left( \frac{1 - \alpha}{1 - \alpha/p} \right) f_{n, p}(\alpha n).
\label{eqn:16F7}
\end{align}
\endgroup

In other words, the probability of at most $\alpha n$~heads is at most
\begin{equation*}
    \frac{1 - \alpha}{1 - \alpha/p}
\end{equation*}
times the probability of exactly $\alpha n$~heads. For our scenario,
where $p = 1/2$ and $\alpha = 1/4$,
\begin{equation*}
\frac{1 - \alpha}{1 - \alpha/p}
    = \frac{3/4}{1/2} % \\
    = \frac{3}{2}.
\end{equation*}
Plugging $n = 100$, \ $\alpha = 1/4$, and $p = 1/2$ into
Equation~\ref{eqn:17A4}, we find that the probability of at most
25~heads in 100~coin flips is
\begin{equation*}
F_{100, 1/2}(25)
    < \frac{3}{2} \cdot
        \frac{  \displaystyle
                2^{100 \left( \frac{1}{4} \log(2)
                     + \frac{3}{4} \log\paren{\frac{2}{3}} \right) }
             }
             { \sqrt{75 \pi /2} } % \\[3pt]
    \le 3 \cdot 10^{-7}.
\end{equation*}

This says that flipping 25 or fewer heads is extremely unlikely, which
is consistent with our earlier claim that the tails of the binomial
distribution are very small.  In fact, notice that the probability of
flipping \emph{25 or fewer} heads is only 50\% more than the
probability of flipping \emph{exactly 25} heads.  Thus, flipping
exactly 25 heads is twice as likely as flipping any number between 0
and 24!

\begin{caveat}
The upper bound on $F_{n, p}(\alpha n)$ in Equation~\ref{eqn:16F7}
holds only if $\alpha < p$.  If this is not the case in your problem,
then try thinking in complementary terms; that is, look at the number
of tails flipped instead of the number of heads.  In fact, this is
precisely what we will do in the next example.
\end{caveat}

\subsection{Noisy Channels}

Suppose you are sending packets of data across a communication channel
and that each packet is lost with probability~$p = .01$.  Also suppose
that packet losses are independent.  You need to figure out how much
redundancy (or error correction) to build into your communication
protocol.  Since redundancy is expensive overheard, you would like to
use as little as possible.  On the other hand, you never want to be
caught short.  Would it be safe for you to assume that in any batch
of 10,000~packets, only 200 (or~2\%) are lost?  Let's find out.

The noisy channel is analogous to flipping $n = 10{,}000$ independent
coins, each with probability~$p = .01$ of coming up heads, and asking
for the probability that there are at least $\alpha n$~heads
where~$\alpha = .02$.  Since $\alpha > p$, we cannot use
Equation~\ref{eqn:16F7}.  So we need to recast the problem by looking
at the numbers of tails.  In this case, the probability of tails is~$p
= .99$ and we are asking for the probability of at most $\alpha
n$~tails where~$\alpha = .98$.

Now we can use Equations \ref{eqn:17A4} and~\ref{eqn:16F7} to find
that the probability of losing~2\% or more of the 10,000~packets is at
most
\begin{equation*}
    \paren{\frac{1 - .98}{1 - .98/.99}}
    \frac{ 2^{10000\paren{.98 \log\paren{\frac{.99}{.98}}
                        + .02 \log\paren{\frac{.01}{.02}}} } }
         {\sqrt{2\pi (.98)(1 - .98) 10000}}
    < 2^{-60}.
\end{equation*}
This is good news.  It says that planning on at most 2\%~packet loss
in a batch of 10,000~packets should be very safe, at least for the
next few millennia.

\subsection{Estimation by Sampling}\label{sec:sampling}

Sampling is a very common technique for estimating the fraction of
elements in a set that have a certain property.  For example, suppose
that you would like to know how many Americans plan to vote for the
Republican candidate in the next presidential election.  It is
infeasible to ask every American how they intend to vote, so pollsters
will typically contact $n$~Americans selected at random and then
compute the fraction of \emph{those} Americans that will vote
Republican.  This value is then used as the \emph{estimate} of the
number of all Americans that will vote Republican.  For example, if
45\% of the $n$~contacted voters report that they will vote
Republican, the pollster reports that 45\% of all Americans will vote
Republican.  In addition, the pollster will usually also provide some
sort of qualifying statement such as
\begin{quote}
``There is a 95\% probability that the poll is accurate to within $\pm
  4$~percentage points.''
\end{quote}

The qualifying statement is often the source of confusion and
misinterpretation.  For example, many people interpret the qualifying
statement to mean that there is a 95\%~chance that between 41\%
and~49\% of Americans intend to vote Republican.  But this is wrong!
The fraction of Americans that intend to vote Republican is a fixed
(and unknown) value~$p$ that is \emph{not} a random variable.  Since
$p$~is not a random variable, we cannot say anything about the
probability that $.41 \le p \le .49$.

To obtain a correct interpretation of the qualifying statement and the
results of the poll, it is helpful to introduce some notation.

Define~$R_i$ to be the indicator random variable for the $i$th
contacted American in the sample.  In particular, set $R_i = 1$ if the
$i$th contacted American intends to vote Republican and $R_i = 0$
otherwise.  For the purposes of the analysis, we will assume that the
$i$th contacted American is selected uniformly at random (with
replacement) from the set of all Americans.\footnote{This means that
someone could be contacted multiple times.}  We will also assume
that every contacted person responds honestly about whether or not
they intend to vote Republican and that there are only two
options---each American intends to vote Republican or they don't.
Thus,
\begin{equation}
    \prob{R_i = 1} = p
\end{equation}
where $p$~is the (unknown) fraction of Americans that intend to vote
Republican.

We next define
\begin{equation*}
    T = R_1 + R_2 + \dots + R_n
\end{equation*}
to be the number of contacted Americans who intend to vote
Republican.  Then $T/n$~is a random variable that is the estimate of
the fraction of Americans that intend to vote Republican.

We are now ready to provide the correct interpretation of the
qualifying statement.  The poll results mean that
\begin{equation}\label{eqn:17CA}
    \Prob{\strut \abs{T/n - p} \le .04} \ge .95.
\end{equation}
In other words, there is a 95\%~chance that the sample group will
produce an estimate that is within $\pm 4$~percentage points of the
correct value for the overall population.  So either we were
``unlucky'' in selecting the people to poll or the results of the poll
will be correct to within $\pm 4$~points.

\subsubsection{How Many People Do We Need to Contact?}

There remains an important question: how many people~$n$ do we need to
contact to make sure that Equation~\ref{eqn:17CA} is true?  In
general, we would like $n$~to be as small as possible in order to
minimize the cost of the poll.

Surprisingly, the answer depends only on the desired \emph{accuracy}
and \emph{confidence} of the poll and not on the number of items in
the set being sampled.  In this case, the desired accuracy is~.04, the
desired confidence is~.95, and the set being sampled is the set of
Americans.  It's a good thing that $n$~won't depend on the size of the
set being sampled---there are over 300 million~Americans!

The task of finding an~$n$ that satisfies Equation~\ref{eqn:17CA} is
made tractable by observing that $T$~has a general binomial
distribution with parameters $n$ and~$p$ and then applying Equations
\ref{eqn:17A4} and~\ref{eqn:16F7}.  Let's see how this works.

Since we will be using bounds on the tails of the binomial
distribution, we first do the standard conversion
\begin{equation*}
\Prob{\strut\abs{T/n - p} \le .04}
    \,=\, 1 - \Prob{\strut \abs{T/n - p} > .04}.
\end{equation*}
We then proceed to upper bound
\begin{align}
\Prob{\abs{T/n - p} > .04}
    & = \prob{T < (p - .04) n} + \prob{T > (p + .04) n} \notag\\
    &= F_{n, p}((p - 0.4)n) + F_{n, 1-p}((1 - p - .04) n).
        \label{eqn:17CB}
\end{align}
We don't know the true value of~$p$, but it turns out that the
expression on the righthand side of Equation~\ref{eqn:17CB} is
maximized when~$p = 1/2$ and so
\begingroup
\openup\jot
\begin{align}
\Prob{\strut \abs{T/n - p} > .04}
    &\le 2 F_{n, 1/2}(.46n) \notag\\
    &<   2 \paren{\frac{1 - .46}{1 - (.46/.5)}} f_{n, 1/2}(.46n)
        \notag\\
    &< 13.5 \cdot 
        \frac{ 2^{n \paren{.46 \log\paren{\frac{.5}{.46}}
                         + .54 \log\paren{\frac{.5}{.54}} } } }
             {\sqrt{2\pi \cdot 0.46 \cdot 0.54 \cdot n}} \notag\\
    & < \frac{ 10.81 \cdot 2^{-.00462 n} }{ \sqrt{n} }.
        \label{eqn:17CD}
\end{align}
\endgroup
The second line comes from Equation~\ref{eqn:16F7} using~$\alpha =
.46$.  The third line comes from Equation~\ref{eqn:17A4}.

Equation~\ref{eqn:17CD} provides bounds on the confidence of the poll
for different values of~$n$.  For example, if~$n = 665$, the bound in
Equation~\ref{eqn:17CD} evaluates to~$.04978\dots$.  Hence, if the
pollster contacts 665~Americans, the poll will be accurate to within
$\pm 4$~percentage points with at least 95\%~probability.

Since the bound in Equation~\ref{eqn:17CD} is exponential in~$n$, the
confidence increases greatly as $n$~increases.  For example, if $n =
6{,}650$ Americans are contacted, the poll will be accurate to within
$\pm 4$~points with probability at least~$1 - 10^{-10}$.  Of
course, most pollsters are not willing to pay the added cost of
polling 10~times as many people when they already have a confidence
level of~95\% from polling 665~people.

\problemsection

\endinput


%% The following were originally sections 5 and 6 of ``Deviations''.

\section{Estimation by Random Sampling}


\subsubsection{Polling again}
\begin{editingnotes}

\textcolor{blue}{This paragraph reflects an alternative exposition
  where polling estimation and confidence were based only on binomial
  distribution properties, even before expectation was introduced.}

In Chapter~[none], we used bounds on the binomial distribution to determine
confidence levels for a poll of voter preferences of Franken vs.\ Coleman.
Now that we know the variance of the binomial distribution, we can use
Chebyshev's Theorem as an alternative approach to calculate poll size.

The setup is the same as in Chapter~[none]
\end{editingnotes}

Suppose we had wanted an advance estimate of the fraction of the
Massachusetts voters who favored Scott Brown over everyone else in the
recent Democratic primary election to fill Senator Edward Kennedy's seat.

\iffalse
\footnote{We can only keep our fingers crossed for this race to
  happen---when they ran against each other for the U.S. Senate in
  2000, they generated some of the best entertainment in TV history.}
\fi

Let $p$ be this unknown fraction, and let's suppose we have some random
process---say throwing darts at voter registration lists---which will
select each voter with equal probability.  We can define a Bernoulli
variable, $K$, by the rule that $K=1$ if the random voter most prefers
Brown, and $K=0$ otherwise.

Now to estimate $p$, we take a large number, $n$, of random choices of
voters\footnote{We're choosing a random voter $n$ times \emph{with
    replacement}.  That is, we don't remove a chosen voter from the set of
  voters eligible to be chosen later; so we might choose the same voter
  more than once in $n$ tries!  We would get a slightly better estimate if
  we required $n$ \emph{different} people to be chosen, but doing so
  complicates both the selection process and its analysis, with little gain
  in accuracy.}  and count the fraction who favor Brown.  That is, we
define variables $K_1, K_2, \dots$, where $K_i$ is interpreted to be the
indicator variable for the event that the $i$th chosen voter prefers
Brown.  Since our choices are made independently, the $K_i$'s are
independent.  So formally, we model our estimation process by simply
assuming we have mutually independent Bernoulli variables $K_1, K_2,
\dots,$ each with the same probability, $p$, of being equal to 1.  Now let
$S_n$ be their sum, that is,
\begin{equation}\label{LN12:Sn}
S_n \eqdef \sum_{i=1}^n K_i.
\end{equation}
So $S_n$ has the binomial distribution with parameter $n$, which we can
choose, and unknown parameter $p$.

The variable $S_n/n$ describes the fraction of voters we will sample
who favor Scott Brown.  Most people intuitively expect this sample
fraction to give a useful approximation to the unknown fraction,
$p$---and they would be right.  
\iffalse Note that
\[
\expect{\frac{S_n}{n}} = \sum_{i=1}^n \expect{K_i} = pn.
\]
\fi
So we will use the sample value, $S_n/n$, as our \emph{statistical
  estimate} of $p$ and use the Pairwise Independent Sampling
Theorem~\ref{th:pairwise-sampling} to work out how good an estimate
this is.

\subsection{Sampling}
Suppose we want our estimate to be within $0.04$ of the Brown favoring
fraction, $p$, at least 95\% of the time.  This means we want
\begin{equation}\label{pollsizeinequality}
\pr{\abs{\frac{S_n}{n} - p} \leq 0.04} \geq 0.95\ .
\end{equation}
So we better determine the number, $n$, of times we must poll voters so
that inequality~\eqref{pollsizeinequality} will hold.

\begin{editingnotes}
the value, $S_n/n$, of our estimate will, with probability at least
$1 -\delta$, be within $\epsilon$ of the actual fraction in the nation
favoring Brown.

We let $\epsilon$ be the margin of error we can tolerate, and let $\delta$
be the probability that our result lies outside this margin, so in this
case we'd have $\epsilon = 0.04$ and $\delta \le 0.05$.

We want to determine the number, $n$, of times we must poll voters so that
the value, $S_n/n$, of our estimate will, with probability at least
$1 -\delta$, be within $\epsilon$ of the actual fraction in the nation
favoring Brown.
\end{editingnotes}

Now $S_n$ is binomially distributed, so from~\eqref{p1p} we have
\[
\variance{S_n}  = n(p(1-p)) \leq n \cdot \frac{1}{4} = \frac{n}{4}\label{n4}
\]
The bound of 1/4 follows from the fact that $p(1-p)$ is maximized when $p
= 1-p$, that is, when $p=1/2$ (check this yourself!).

Next, we bound the variance of $S_n/n$:
\begin{align}
\variance{\frac{S_n}{n}}
       & = \paren{\frac{1}{n}}^2 \variance{S_n}
                     & \text{(by~\eqref{a2R})}\notag\\
       & \leq \paren{\frac{1}{n}}^2 \frac{n}{4} & \text{(by~\eqref{n4})}\notag\\
       & = \frac{1}{4n}\label{1/4n}
\end{align}
Now from Chebyshev and~\eqref{1/4n} we have:
\begin{equation}\label{CK}
\pr{\abs{\frac{S_n}{n} - p} \geq 0.04}
    \leq \frac{\variance{S_n/n}}{(0.04)^2}
       = \frac{1}{4n(0.04)^2} = \frac{156.25}{n}
\end{equation}

To make our our estimate with  95\% confidence, we want the righthand
side of~\eqref{CK} to be at most 1/20.  So we choose $n$ so that
\[
\frac{156.25}{n} \leq \frac{1}{20},
\]
that is,
\[
n \geq 3,125.
\]

A more exact calculation of the tail of this binomial distribution
shows that the above sample size is about four times larger than
necessary, but it is still a feasible size to sample.  The fact that
the sample size derived using \idx{Chebyshev's Theorem} was unduly
pessimistic should not be surprising.  After all, in applying the
Chebyshev Theorem, we only used the variance of $S_n$.  It makes sense
that more detailed information about the distribution leads to better
bounds.  But working through this example using only the
\idx{variance} has the virtue of illustrating an approach to
estimation that is applicable to arbitrary random variables, not just
binomial variables.

\subsection{Matching Birthdays}\label{bday_deviation_subsec}

There are important cases where the relevant distributions are not
binomial because the mutual independence properties of the voter
preference example do not hold.  In these cases, estimation methods
based on the Chebyshev bound may be the best approach.  Birthday
Matching is an example.  We already saw in
Section~\ref{birthday_principle_sec} that in a class of 85 students it
is virtually certain that two or more students will have the same
birthday.  This suggests that quite a few pairs of students are likely
to have the same birthday.  How many?

So as before, suppose there are $n$ students and $d$ days in the year, and
let $D$ be the number of pairs of students with the same birthday.  Now it
will be easy to calculate the expected number of pairs of students with
matching birthdays.  Then we can take the same approach as we did in
estimating voter preferences to get an estimate of the probability of
getting a number of pairs close to the expected number.

Unlike the situation with voter preferences, having \idx{matching
  birthdays} for different pairs of students are not \idx{mutually
  independent} events, but the matchings are \emph{\idx{pairwise
    independent}}, as explained in
Section~\ref{birthday_principle_sec}.
%
\iffalse For example, knowing that Alice and Bob have matching
birthdays, and also that Ted and Alice have matching birthdays
obviously implies that Bob and Ted have matching birthdays.  On the
other hand, knowing that Alice and Bob have matching birthdays tells
us nothing about whether Alice and Carol have matching birthdays,
namely, these two events really are independent.  So even though the
events that various pairs of students have matching birthdays are not
mutually independent, indeed not even three-way independent, they are
\index{pairwise independent} \emph{pairwise} independent.  \fi
% This will allow us to apply the same reasoning to Birthday Matching
as we did for voter preference.  Namely, let $B_1,B_2,\dots,B_n$ be
the birthdays of $n$ independently chosen people, and let $E_{i,j}$ be
the indicator variable for the event that the $i$th and $j$th people
chosen have the same birthdays, that is, the event $[B_i = B_j]$.  So
our probability model, the $B_i$'s are mutually independent variables,
the $E_{i,j}$'s are pairwise independent.  Also, the expectations of
$E_{i,j}$ for $i \neq j$ equals the probability that $B_i = B_j$,
namely, $1/d$.

Now, $D$, the number of matching pairs of birthdays among the $n$
choices is simply the sum of the $E_{i,j}$'s:
\begin{equation}\label{Vn}
D \eqdef \sum_{1\le i < j \le n} E_{i,j}.
\end{equation}
So by linearity of expectation
\[
\expect{D} = \expect{\sum_{1\le i < j \le n} E_{i,j}} =
               \sum_{1\le i < j \le n} \expect{E_{i,j}} =
               \binom{n}{2}\cdot \frac{1}{d}.
\]
Similarly,
\begin{align*}
\variance{D}
   & = \variance{\sum_{1\le i < j \le n} E_{i,j}}\\
   & = \sum_{1\le i < j \le n} \variance{E_{i,j}}
           & \text{(by Theorem~\ref{th:varsum})}\\
   & = \binom{n}{2} \cdot \frac{1}{d}\paren{1-\frac{1}{d}}.
           & (by Lemma~\ref{bernoulli-variance})
\end{align*}

In particular, for a class of $n= 85$ students with $d=365$ possible
birthdays, we have $\expect{D} \approx 9.7$ and $\variance{D} < 9.7 (1-
1/365) < 9.7$.  So by Chebyshev's Theorem
\[
\pr{\abs{D - 9.7} \geq x} < \frac{9.7}{x^2}.
\]

Letting $x=5$, we conclude that there is a better than 50\% chance that in
a class of 85 students, the number of pairs of students with the same
birthday will be between 5 and 14.

%In fact, there turned out to be
%\emph{exactly} the 16 matches expected in the class this term!


\subsection{Pairwise Independent Sampling}\label{sec:pairwise_ind_samp}

The reasoning we used above to analyze voter polling and matching
birthdays is very similar.  We summarize it in slightly more general form
with a basic result we call the \idx{Pairwise Independent Sampling}
Theorem.  In particular, we do not need to restrict ourselves to sums of
zero-one valued variables, or to variables with the same distribution.
For simplicity, we state the Theorem for pairwise independent variables
with possibly different distributions but with the same mean and variance.

\begin{theorem}[Pairwise Independent Sampling]\label{th:pairwise-sampling}
Let $G_1, \dots, G_n$ be pairwise independent variables with the same
mean, $\mu$, and deviation, $\sigma$.  Define
\begin{equation}\label{ln14.Sn}
S_n \eqdef \sum_{i=1}^n G_i.
\end{equation}
Then
\[
\pr{\abs{\frac{S_n}{n} - \mu} \geq x}
    \leq \frac{1}{n} \paren{\frac{\sigma}{x}}^2.
\]
\end{theorem}

\begin{proof}
We observe first that the expectation of $S_n/n$ is $\mu$:
\begin{align*}
\expect{\frac{S_n}{n}} & = \expect{\frac{\sum_{i=1}^n G_i}{n}}
         & \text{(def of $S_n$)}\\
 & = \frac{\sum_{i=1}^n \expect{G_i}}{n}
     & \text{(linearity of expectation)}\\
 & = \frac{\sum_{i=1}^n \mu}{n}\\
 & = \frac{n\mu}{n} = \mu.
\end{align*}

The second important property of $S_n/n$ is that its variance is the
variance of $G_i$ divided by $n$:
\begin{align}
\variance{\frac{S_n}{n}} & =  \paren{\frac{1}{n}}^2 \variance{S_n}
          & \mbox{(by~\eqref{a2R})}\notag\\
 & =  \frac{1}{n^2} \variance{\sum_{i=1}^n G_i}
          & \text{(def of $S_n$)}\notag\\
 & =  \frac{1}{n^2} \sum_{i=1}^n \variance{G_i}
        & \text{(pairwise independent additivity)}\notag\\
 & =  \frac{1}{n^2}\cdot n\sigma^2 =  \frac{\sigma^2}{n}.\label{Snu}
\end{align}

This is enough to apply \idx{Chebyshev's Theorem} and conclude:
\begin{align*}
\pr{\abs{\frac{S_n}{n} - \mu} \geq x} & \leq \frac{\variance{S_n/n}}{x^2}.
       & \text{(Chebyshev's bound)}\\
    & = \frac{\sigma^2/n}{x^2} & \text{(by~\eqref{Snu})}\\
    & = \frac{1}{n} \paren{\frac{\sigma}{x}}^2.
\end{align*}

\end{proof}

The Pairwise Independent Sampling Theorem provides a precise general
statement about how the average of independent samples of a random
variable approaches the mean.  In particular, it proves what is known as
the \idx{Law of Large Numbers}\footnote{This is the \index{Weak Law of
    Large Numbers} \emph{Weak} Law of Large Numbers.  As you might
  suppose, there is also a Strong Law, but it's outside the scope of
  this text.} : by choosing a large enough sample size, we can get arbitrarily
accurate estimates of the mean with confidence arbitrarily close to 100\%.

\begin{corollary}\label{weaklaw}[Weak Law of Large Numbers]
  Let $G_1, \dots, G_n$ be pairwise independent variables with the same
  mean, $\mu$, and the same finite deviation, and let
\[
S_n \eqdef \frac{\sum_{i=1}^n G_i}{n}.
\]
Then for every $\epsilon > 0$,
\[
\lim_{n \rightarrow \infty}
        \pr{\abs{S_n - \mu}  \leq \epsilon} = 1.
\]
\end{corollary}

\section{Confidence versus Probability}

So Chebyshev's Bound implies that sampling 3,125 voters will yield a
fraction that, 95\% of the time, is within 0.04 of the actual fraction
of the voting population who prefer Brown.
\begin{editingnotes}
  Estimates of the binomial distribution show that a sample size
  around 664 would do.
\end{editingnotes}

Notice that the actual size of the voting population was never
considered because \emph{it did not matter}.  People who have not
studied probability theory often insist that the \idx{population size}
should matter.  But our analysis shows that polling a little over 3000
people people is always sufficient, whether there are ten thousand, or
million, or billion \dots voters.  You should think about an intuitive
explanation that might persuade someone who thinks population size
matters.

Now suppose a pollster actually takes a sample of 3,125 random voters to
estimate the fraction of voters who prefer Brown, and the pollster finds
that 1250 of them prefer Brown.  It's tempting, \textbf{but sloppy}, to
say that this means:
\begin{falseclm*}
  With probability 0.95, the fraction, $p$, of voters who prefer Brown
  is $1250/3125 \pm 0.04$.  Since $1250/3125 -0.04 > 1/3$, there is a 95\%
  chance that more than a third of the voters prefer Brown to all other
  candidates.
\end{falseclm*}
What's objectionable about this statement is that it talks about the
probability or ``chance'' that a real world fact is true, namely that the
actual fraction, $p$, of voters favoring Brown is more than 1/3.  But $p$
is what it is, and it simply makes no sense to talk about the probability
that it is something else.  For example, suppose $p$ is actually 0.3;
then it's nonsense to ask about the probability that it is within 0.04 of
1250/3125---it simply isn't.

This example of voter preference is typical: we want to estimate a fixed,
unknown real-world quantity.  But \emph{being unknown does not make this
  quantity a random variable}, so it makes no sense to talk about the
probability that it has some property.

A more careful summary of what we have accomplished goes this way:
\begin{quote}
We have described a probabilistic procedure for estimating the value of
the actual fraction, $p$.  The probability that \emph{our estimation
procedure} will yield a value within 0.04 of $p$ is 0.95.
\end{quote}
This is a bit of a mouthful, so special phrasing closer to the sloppy
language is commonly used.  The pollster would describe his conclusion by
saying that
\begin{quote}
At the 95\% \term{confidence level}, the fraction of voters
who prefer Brown is $1250/3125 \pm 0.04$.
\end{quote}

So confidence levels refer to the results of estimation procedures for
real-world quantities.  The phrase ``confidence level'' should be heard as
a reminder that some statistical procedure was used to obtain an estimate,
and in judging the credibility of the estimate, it may be important to
learn just what this procedure was.

\begin{editingnotes}
Maybe include example from CP\_drug\_confidence here.
\end{editingnotes}

\begin{problems}
\practiceproblems
\pinput{FP_random_sampling}

\classproblems
\pinput{CP_gallup_poll}
\pinput{CP_birthday-deviation}
\pinput{CP_size_of_sample_vs_population}
\pinput{CP_pairwise_independent_theorem}
\pinput{CP_drug_confidence}

\examproblems
\pinput{FP_sampling_concepts}
\end{problems}


\section{Continuous Distributions}

You may have noticed that all of the distributions we have discussed
thus far are for finite sample spaces.  That's because finite
distributions are the most common in computer science.  They are also
the easiest to work with.

More generally, there are important distributions on infinite sample
spaces.  We will briefly mention some of the most important in the
following subsections.  For the most part in this text, however, our
focus will continue to be on finite probability spaces.

\subsection{Continuous uniform Distributions}

We have already talked about the uniform distribution on a finite
sample space~$\set{1, 2, \dots, n}$.  The uniform distribution can
also be defined on the infinite sample space~$[0, n]$.  In this case,
the pdf is
\begin{equation*}
    f_n: [0, n] \to [0, 1]
\end{equation*}
where
\begin{equation*}
    f_n(x) = \frac{1}{n}
\end{equation*}
and the cdf is
\begin{equation*}
    F_n(x) = \frac{x}{n}.
\end{equation*}

The difference between the continuous and discrete uniform
distributions is that the pdf for the continuous uniform distribution
is nonzero for any real $x \in [0, n]$ whereas the pdf for the
discrete uniform distribution is nonzero only for integer~$x \in [1,
  n]$.

\subsection{Normal Distributions}

The \term{standard normal distribution} is defined by the pdf
\begin{equation*}
    f: \reals \to [0, 1]
\end{equation*}
where
\begin{equation*}
    f(x) = \frac{ e^{-x^2/2} }{ \sqrt{2\pi} }.
\end{equation*}
A graph of~$f(x)$ is shown in Figure~\ref{fig:16L1}.

\begin{figure}

\graphic{Fig_16L1}

\caption{The plot of the pdf for the standard normal distribution.}

\label{fig:16L1}

\end{figure}

The cumulative distribution function for the standard normal is
\begin{equation*}
    F(x) = \int_{-\infty}^x \frac{ e^{-z^2/2} \, dz }{\sqrt{2\pi}}.
\end{equation*}

The general normal distribution is defined based on two parameters:
$\mu$ (the mean) and~$\sigma^2$ (the variance).  It's pdf is the
function
\begin{equation*}
    f_{\mu, \sigma^2} : \reals \to [0, 1]
\end{equation*}
where
\begin{equation}\label{eqn:16N1}
    f_{\mu, \sigma^2} = \frac{ e^{ - (x - \mu)^2 / 2 \sigma^2 } }
                             { \sqrt{2 \pi \sigma^2 } }.
\end{equation}

The normal distribution is similar to the binomial distribution in
some respects.  For example, if we set $\mu = n/2$, \ $\sigma^2 =
n/4$, and~$x = \alpha n$ in Equation~\ref{eqn:16N1}, the resulting pdf
is exponentially small in~$n$, which is similar to the behavior of
Equation~\ref{eqn:16F5} when $p = 1/2$.  We'll talk further about the
relationship in Chapter~\ref{chap:deviations}, where the reasons for
the choices of $\mu$, $\sigma^2$, and~$x$ above will become apparent.

\endinput
