\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{PS_conditional_space}
  \pcomment{from: new S10.ps11 by Rich}
\end{pcomments}

\pkeywords{
  probability
  sample_space
  conditional_probability
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\prb}[1]{\prsub{#1}{B}} %\mathop{\textup{Pr}_B}\nolimits\left\{#1\right\}}

%\newcommand{\prb}[1]{\mathop{\textup{Pr}}_B\nolimits\left\[#1\right\]}

\newcommand{\prb}[1]{\text{Pr}_B[#1]}

\begin{problem}
  Suppose $\pr{\cdot}: \sspace\to [0,1]$ is a \idx{probability function} on
  a sample space $\sspace$ and let $B$ be an event such that $\pr{B}
  > 0$.  Define a function $\prb{\cdot}$ on outcomes $\omega
  \in \sspace$ by the rule:
\begin{equation}\label{prsubbdef}
  \prb{\omega} \eqdef \begin{cases} \pr{\omega}/\pr{B} &\text{ if } \omega \in B,\\
                               0 & \text{ if } \omega \notin B.
                  \end{cases}
\end{equation}

\bparts

\ppart Prove that $\prb{\cdot}$ is also a probability function on
$\sspace$ according to Definition~\bref{LN12:probsp}.

\begin{solution}
  We must show that $\prb{\omega} \geq 0$ for all outcomes $\omega \in \sspace$,
  and
\begin{equation}\label{prbss=1}
  \sum_{\omega \in \sspace} \prb{\omega} = 1.
\end{equation}

  But $\prb{\omega} \geq 0$ since both the numerator $\pr{\omega}$,
  and the denominator $\pr{B}$ in~\eqref{prsubbdef} are nonnegative.
  Also~\eqref{prbss=1} holds because
  \begin{align*}
    \sum_{\omega \in \sspace} \prb{\omega}
       & = \sum_{\omega \in B} \prb{\omega} + \sum_{\omega \notin B} \prb{\omega}\\
       & = \sum_{\omega \in B} \frac{\pr{\omega}}{\pr{B}} + \sum_{\omega \notin B} 0\\
       & = \frac{\pr{B}}{\pr{B}} + 0 = 1.
  \end{align*}

\end{solution}

\ppart\label{prbAfrac} Prove that
\[
\prb{A} = \frac{\pr{A \intersect B}}{\pr{B}}
\]
for all $A \subseteq \sspace$.

\begin{solution}

\begin{align*}
\prb{A}
   & \eqdef \sum_{\omega \in A} \frac{\pr{\omega}}{\pr{B}}\\
   & = \sum_{\omega \in A \intersect B} \prb{\omega} + \sum_{\omega \in A - B} \prb{\omega}\\
   & = \sum_{\omega \in A \intersect B} \frac{\pr{\omega}}{\pr{B}} + \sum_{\omega \in A - B} \frac{\pr{\omega}}{\pr{B}}\\
   & = \frac{\sum_{\omega \in A \intersect B} \pr{\omega}}{\pr{B}} + \sum_{\omega \in A - B} 0\\
   & = \frac{\pr{A \intersect B}}{\pr{B}}.
\end{align*}

\end{solution}

\ppart Explain why the Disjoint Sum Rule carries over for conditional
probabilities, namely,
\[
\prcond{C \union D}{B} = \prcond{C}{B} + \prcond{D}{B} \qquad (C,D
\text{ disjoint}).
\]
Give examples of several further such rules.

\begin{solution}
Note that $\prb{A} = \prcond{A}{B}$.  So part~\eqref{prbAfrac} says
that with $B$ fixed, $\prcond{A}{B}$ is a probability measure, and so
satisfies all the properties of such measures.  For example, Total
Probability carries over as follows: for pairwise disjoint
$B_1,B_2,B_3$ such that $A \subseteq B_1 \union B_2 \union B_3$,
\begin{align*}
\prcond{A}{B} = & \prcond{A\intersect B_1}{B}\prcond{B_1}{B} +\\
                & \prcond{A\intersect B_2}{B}\prcond{B_2}{B} +\\
                & \prcond{A\intersect B_3}{B}\prcond{B_3}{B}.
\end{align*}
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
