\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{TP_sampling_perturbed}
  \pcomment{variant of FP_sampling_concepts, similar to FP_random_sampling}
\end{pcomments}

\pkeywords{
  random_variable
  independence
  sampling
  confidence
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  Yesterday, the local bakers produced a huge batch of cookies.  To
  estimate the fraction $c$ of cookies in this batch that got
  overdone, they will examine a small \idx{sample} of cookies chosen
  \emph{randomly and independently}.  The factory statistician can then
  calculate a value $n$ for a number of cookies to sample which
  ensures that with 97\% confidence, the fraction of overdone
  cookies in a sample of size $n$ will be within 0.006 of the actual
  fraction $c$ of overdone cookies in the whole batch.

  Mathematically, the \emph{batch} is an actual outcome that already
  happened.  The \emph{fraction} of overdone cookies in a random sample
  from the batch is a random variable.  The justification for the
  statistician's \idx{confidence} depends on some properties of the
  batch and how the sample of $n$ cookies from the batch are chosen.
  These properties are described in some of the following statements.
  \inbook{Indicate}\inhandout{Circle} the \True\ statements:

\bparts

\ppart The probability that the ninth cookie in the
\emph{batch} is overdone is $c$.

\begin{solution}
\textbf{False.}

The batch has already been baked, so there's nothing probabilistic
about the ninth (or any other) cookie being overdone: either it is
or it isn't overdone, though we don't know which.  You could argue
that this means it is overdone with probability zero or one, but in
any case, it certainly isn't $c$.
\end{solution}

\ppart The probability that the ninth cookie chosen for the
  \emph{sample} is overdone, is $c$.

\begin{solution} \textbf{True.}

The ninth cookie sampled is equally likely to be any cookie in the
batch, so the probability it is overdone is the same as the fraction $c$
of overdone cookies in the program.
\end{solution}

\ppart All cookies in the batch are equally likely to be the
third cookie chosen in the \emph{sample}.

\begin{solution} \textbf{True.}

The meaning of choosing a cookie ``randomly'' is that every cookie is
equally likely to be the next one chosen.
\end{solution}


\ppart Given that the first cookie chosen for the \emph{sample} is overdone,
the probability that the second cookie chosen will also be overdone is greater
than~$c$. 

\begin{solution}
\textbf{False.}

  The meaning of ``\emph{randomly and independently}'' is precisely
  that at each of the $n$ choices in the sample, in particular at the
  second choice, each cookie in the batch is equally likely to be
  chosen, independent of what the first or any other choice happened
  to be.
\end{solution}

\ppart  Given that the last cookie in the \emph{batch} is overdone, the
  probability that the next-to-last cookie in the batch will also be
  overdone is greater than~$c$. 

\begin{solution}
\textbf{False.}

  As noted above, it's zero or one.
\end{solution}

\ppart Given that the first two cookies selected in the \emph{sample}
  are the same kind of cookie---they might both be chocolate or both
  be ginger, for example---the probability that the first cookie is
  overdone may be greater than $c$.


\begin{solution}
\textbf{True.}

  We don't know how prone to being overdone different kinds of
  cookies may be.  It could be for example, that chocolate cookies are
  more prone being overdone than other kinds of cookies, and that
  there are more chocolate cookies than any other kind of cookie in
  the batch.  Then given that two randomly chosen cookies in the
  sample are the same kind, they are more likely to be chocolate,
  which makes them more prone to being overdone.  That is, the
  conditional probability that they will be overdone would be
  greater than $c$.
\end{solution}

\ppart  The expectation of the indicator variable for the last cookie in
  the \emph{sample} being \text{overdone} is~$c$.



\begin{solution}
\textbf{True.}

  The expectation of the indicator variable is the same as the probability
  that it is 1, namely, it is the probability that the $n$th cookie chosen
  is overdone, which is $c$, by the reasoning above.
\end{solution}

\ppart The statistician's calculation of $n$ does not depend on the size of the batch.


\begin{solution}
\textbf{True.}

As suggested in Problem~\bref{CP_size_of_sample_vs_population}, you
can think about sampling a well-stirred pot of soup:
\begin{quote}
\emph{ You can sip a teaspoon to see if it's to salty.  Whether you
  have a small pot to serve two, or a large vat to serve a banquet,
  all you need sip is a teaspoon.  You don't need need to sip a whole
  ladle or a cup just because your pot of soup is large.  The same
  applies to sampling from a batch: we sample the same
  ``teaspoon'' amount no matter how big the batch.  }
\end{quote}

\end{solution}

\ppart As the size of the batch grows, the probability that all the
cookies in the \emph{sample} are different approaches one.

\begin{solution}
\textbf{True.}

  For a batch of size $k$, the probability that all the cookies in
  a sample of size $n$ are different is
  \[
  \frac{k}{k}\cdot \frac{k-1}{k}\cdot \frac{k-2}{k} \cdots \frac{k-(n-1)}{k}
  \]
  For fixed $n$, each of the $n$ terms in the product approaches one
  as $k$ approaches infinity, and therefore so does the whole product.
\end{solution}

\eparts

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
